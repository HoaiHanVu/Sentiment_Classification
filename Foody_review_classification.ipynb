{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e4b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /Users/vuhan/Desktop/JOHN/10. Capstone Project/Week3/Lib/Functions.ipynb\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "from pyvi import ViPosTagger, ViTokenizer\n",
    "import import_ipynb\n",
    "import Lib.Functions as fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcf3c5",
   "metadata": {},
   "source": [
    "- ƒê·ªçc d·ªØ li·ªáu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f4c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_Foody.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2117fdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good Morning Restaurant</td>\n",
       "      <td>Pizza phong c√°ch √ù. Ng√°n h·∫£i s·∫£n n√™n c·∫£ nh√† gh...</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>H·∫°t D·∫ª Tr√πng Kh√°nh</td>\n",
       "      <td>- V·ªã tr√≠: ch·ªâ l√† 1 chi·∫øc xe nho nh·ªè n·∫±m ·ªü khu ...</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B·ªôt - Healthy &amp; Weight Loss Food - Shop Online</td>\n",
       "      <td>Nay lang thang tr√™n BM th·∫•y ƒëang khuy·∫øn m√£i xo...</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B√°nh Gi√≤ Ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©</td>\n",
       "      <td>Qu√°n n·∫±m trong ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©, c≈©ng d·ªÖ t√¨...</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Qu√°n Qu·∫£ng - B√∫n Qu·∫£ng</td>\n",
       "      <td>Ng√£i heo v·ªõi heo thi·ªáttttt üê∑üê∑üê∑\\nü§§ü§§ b√∫n nem ch·∫£...</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      restaurant  \\\n",
       "0           0                         Good Morning Restaurant   \n",
       "1           1                              H·∫°t D·∫ª Tr√πng Kh√°nh   \n",
       "2           2  B·ªôt - Healthy & Weight Loss Food - Shop Online   \n",
       "3           3                    B√°nh Gi√≤ Ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©   \n",
       "4           4                          Qu√°n Qu·∫£ng - B√∫n Qu·∫£ng   \n",
       "\n",
       "                                         review_text  review_score  \n",
       "0  Pizza phong c√°ch √ù. Ng√°n h·∫£i s·∫£n n√™n c·∫£ nh√† gh...          8.20  \n",
       "1  - V·ªã tr√≠: ch·ªâ l√† 1 chi·∫øc xe nho nh·ªè n·∫±m ·ªü khu ...          8.00  \n",
       "2  Nay lang thang tr√™n BM th·∫•y ƒëang khuy·∫øn m√£i xo...          8.20  \n",
       "3  Qu√°n n·∫±m trong ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©, c≈©ng d·ªÖ t√¨...          8.20  \n",
       "4  Ng√£i heo v·ªõi heo thi·ªáttttt üê∑üê∑üê∑\\nü§§ü§§ b√∫n nem ch·∫£...          9.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77081f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39925 entries, 0 to 39924\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    39925 non-null  int64  \n",
      " 1   restaurant    39925 non-null  object \n",
      " 2   review_text   39925 non-null  object \n",
      " 3   review_score  39925 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274be3f",
   "metadata": {},
   "source": [
    "- Ta s·∫Ω xem qua ph·ªï ƒëi·ªÉm ƒë√°nh gi√° c·ªßa kh√°ch h√†ng trong dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f05ffc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = data['review_score'].value_counts()\n",
    "score = pd.DataFrame(score).sort_values(by = 'review_score', ascending = False)\n",
    "\n",
    "plt.figure(figsize = (20, 6))\n",
    "sb.barplot(score.index, score['review_score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa471b",
   "metadata": {},
   "source": [
    "- D·ªÖ d√†ng nh·∫≠n th·∫•y ƒëi·ªÉm s·ªë t·ª´ 7.0 tr·ªü l√™n chi·∫øm s·ªë l∆∞·ª£ng kh√° l·ªõn, d·ª±a tr√™n s·ªë ƒëi·ªÉm c√≥ th·ªÉ ph·ªèng ƒëo√°n c√°c ƒë√°nh gi√° th·ª±c s·ª± ch√™ ho·∫∑c nh·∫≠n x√©t kh√¥ng t·ªët v·ªÅ d·ªãch v·ª• chi·∫øm s·ªë l∆∞·ª£ng nh·ªè h∆°n c√°c ƒë√°nh gi√° t√≠ch c·ª±c kh√° nhi·ªÅu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f1e14",
   "metadata": {},
   "source": [
    "- ƒê·ªÉ x·ª≠ l√Ω vƒÉn b·∫£n Ti·∫øng Vi·ªát, ta s·∫Ω load m·ªôt s·ªë file d·ªØ li·ªáu c·∫ßn thi·∫øt ƒë·ªÉ l√†m s·∫°ch ho·∫∑c thay th·∫ø c√°c t·ª´ kh√¥ng ph·∫£i ti·∫øng Vi·ªát trong c√¢u: c√°c icon c·∫£m x√∫c, teencode, c√°c t·ª´ d·ªÖ nh·∫ßm l·∫´n v√† stopwords trong ti·∫øng Vi·ªát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ca5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMOJICON\n",
    "file = open('files/emojicon.txt', 'r', encoding=\"utf8\")\n",
    "emoji_lst = file.read().split('\\n')\n",
    "emoji_dict = {}\n",
    "for line in emoji_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    emoji_dict[key] = str(value)\n",
    "file.close()\n",
    "\n",
    "# TEENCODE\n",
    "file = open('files/teencode.txt', 'r', encoding=\"utf8\")\n",
    "teen_lst = file.read().split('\\n')\n",
    "teen_dict = {}\n",
    "for line in teen_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    teen_dict[key] = str(value)\n",
    "file.close()\n",
    "\n",
    "# TRANSLATE ENGLISH -> VNMESE\n",
    "file = open('files/english-vnmese.txt', 'r', encoding=\"utf8\")\n",
    "english_lst = file.read().split('\\n')\n",
    "english_dict = {}\n",
    "for line in english_lst:\n",
    "    key, value = line.split('\\t')\n",
    "    english_dict[key] = str(value)\n",
    "file.close()\n",
    "\n",
    "# WRONG WORDS\n",
    "file = open('files/wrong-word.txt', 'r', encoding=\"utf8\")\n",
    "wrong_lst = file.read().split('\\n')\n",
    "file.close()\n",
    "\n",
    "# STOPWORDS\n",
    "file = open('files/vietnamese-stopwords.txt', 'r', encoding=\"utf8\")\n",
    "stopwords_lst = file.read().split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a5a982",
   "metadata": {},
   "source": [
    "- X·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d2c88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text took 16.36 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "final_text = data['review_text'].apply(lambda x: fc.clean_text(x, emoji_dict, teen_dict, wrong_lst, stopwords_lst))\n",
    "t2 = time.time()\n",
    "\n",
    "print('Cleaning text took {:.2f} minutes.'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15a785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad9de60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_score</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good Morning Restaurant</td>\n",
       "      <td>Pizza phong c√°ch √ù. Ng√°n h·∫£i s·∫£n n√™n c·∫£ nh√† gh...</td>\n",
       "      <td>8.20</td>\n",
       "      <td>ng√°n h·∫£i s·∫£n gh√© ƒÉn. gi√° r·∫ª m√≥n tr√¨nh b√†y ƒë·∫πp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>H·∫°t D·∫ª Tr√πng Kh√°nh</td>\n",
       "      <td>- V·ªã tr√≠: ch·ªâ l√† 1 chi·∫øc xe nho nh·ªè n·∫±m ·ªü khu ...</td>\n",
       "      <td>8.00</td>\n",
       "      <td>v·ªã tr√≠ ng√£ s√¢n c√°t qu√°n ph·ªü ho√† ƒë√¥ng ƒë·ªëi di·ªán ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B·ªôt - Healthy &amp; Weight Loss Food - Shop Online</td>\n",
       "      <td>Nay lang thang tr√™n BM th·∫•y ƒëang khuy·∫øn m√£i xo...</td>\n",
       "      <td>8.20</td>\n",
       "      <td>khuy·∫øn m√£i ƒë·ªçc review th·ª≠ c·∫£m v·ªã ƒë·ªì ƒëa ƒë·ªì si√™u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B√°nh Gi√≤ Ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©</td>\n",
       "      <td>Qu√°n n·∫±m trong ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©, c≈©ng d·ªÖ t√¨...</td>\n",
       "      <td>8.20</td>\n",
       "      <td>qu√°n ch·ª£ nguy·ªÖn c√¥ng tr·ª© th·∫≥ng ch·ª£ t·ªõi. qu√°n t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Qu√°n Qu·∫£ng - B√∫n Qu·∫£ng</td>\n",
       "      <td>Ng√£i heo v·ªõi heo thi·ªáttttt üê∑üê∑üê∑\\nü§§ü§§ b√∫n nem ch·∫£...</td>\n",
       "      <td>9.00</td>\n",
       "      <td>ng√£i thi·ªáttttt b√∫n ch·∫£ qu·∫£ng th∆°m qu√°n tr·∫ßn vƒÉ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      restaurant  \\\n",
       "0           0                         Good Morning Restaurant   \n",
       "1           1                              H·∫°t D·∫ª Tr√πng Kh√°nh   \n",
       "2           2  B·ªôt - Healthy & Weight Loss Food - Shop Online   \n",
       "3           3                    B√°nh Gi√≤ Ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©   \n",
       "4           4                          Qu√°n Qu·∫£ng - B√∫n Qu·∫£ng   \n",
       "\n",
       "                                         review_text  review_score  \\\n",
       "0  Pizza phong c√°ch √ù. Ng√°n h·∫£i s·∫£n n√™n c·∫£ nh√† gh...          8.20   \n",
       "1  - V·ªã tr√≠: ch·ªâ l√† 1 chi·∫øc xe nho nh·ªè n·∫±m ·ªü khu ...          8.00   \n",
       "2  Nay lang thang tr√™n BM th·∫•y ƒëang khuy·∫øn m√£i xo...          8.20   \n",
       "3  Qu√°n n·∫±m trong ch·ª£ Nguy·ªÖn C√¥ng Tr·ª©, c≈©ng d·ªÖ t√¨...          8.20   \n",
       "4  Ng√£i heo v·ªõi heo thi·ªáttttt üê∑üê∑üê∑\\nü§§ü§§ b√∫n nem ch·∫£...          9.00   \n",
       "\n",
       "                                          clean_text  \n",
       "0  ng√°n h·∫£i s·∫£n gh√© ƒÉn. gi√° r·∫ª m√≥n tr√¨nh b√†y ƒë·∫πp ...  \n",
       "1  v·ªã tr√≠ ng√£ s√¢n c√°t qu√°n ph·ªü ho√† ƒë√¥ng ƒë·ªëi di·ªán ...  \n",
       "2  khuy·∫øn m√£i ƒë·ªçc review th·ª≠ c·∫£m v·ªã ƒë·ªì ƒëa ƒë·ªì si√™u...  \n",
       "3  qu√°n ch·ª£ nguy·ªÖn c√¥ng tr·ª© th·∫≥ng ch·ª£ t·ªõi. qu√°n t...  \n",
       "4  ng√£i thi·ªáttttt b√∫n ch·∫£ qu·∫£ng th∆°m qu√°n tr·∫ßn vƒÉ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3d33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['clean_text', 'review_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "261056f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39925 entries, 0 to 39924\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   clean_text    39925 non-null  object \n",
      " 1   review_score  39925 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 624.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c55c2",
   "metadata": {},
   "source": [
    "- Ki·ªÉm tra, lo·∫°i b·ªè d·ªØ li·ªáu tr√πng c≈©ng nh∆∞ c√°c d√≤ng b·ªã r·ªóng sau khi x·ª≠ l√Ω v√† l√†m s·∫°ch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489b62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicates: 39925 rows.\n",
      "After dropping duplicates: 39639 rows.\n"
     ]
    }
   ],
   "source": [
    "dup_val = len(df) - len(df.drop_duplicates())\n",
    "\n",
    "if dup_val > 0:\n",
    "    print('Before dropping duplicates: {} rows.'.format(len(df)))\n",
    "    df = df.drop_duplicates()\n",
    "    print('After dropping duplicates: {} rows.'.format(len(df)))\n",
    "else:\n",
    "    print('No duplicate values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b362e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['clean_text'] == ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513c0b07",
   "metadata": {},
   "source": [
    "- Vi·ªác ƒë√°nh gi√° v√† cho ƒëi·ªÉm c·ªßa kh√°ch h√†ng d·ª±a kh√° nhi·ªÅu v√†o c·∫£m x√∫c c≈©ng nh∆∞ nhi·ªÅu y·∫øu t·ªë kh√°c nhau c·ªông h∆∞·ªüng ƒë·∫øn tr·∫£i nghi·ªám d·ªãch v·ª•. Th·ª±c t·∫ø t·ª´ d·ªØ li·ªáu `review_text` v√† `score` cho th·∫•y, vi·ªác khen ch√™ trong c√πng m·ªôt post ƒë√°nh gi√° (review) kh√° ph·ªï bi·∫øn, v√¨ nh∆∞ gi·∫£i th√≠ch ·ªü tr√™n, c√≥ kh√° nhi·ªÅu y·∫øu t·ªë t√°c ƒë·ªông ƒë·∫øn tr·∫£i nghi·ªám c·ªßa kh√°ch h√†ng s·ª≠ d·ª•ng d·ªãch v·ª• nh∆∞: gi√° c·∫£, ch·∫•t l∆∞·ª£ng, v·ªã tr√≠, ph·ª•c v·ª•, th√°i ƒë·ªô nh√¢n vi√™n, kh·∫©u v·ªã, ... . V√¨ v·∫≠y, trong ƒëa s·ªë tr∆∞·ªùng h·ª£p, vi·ªác m·ªôt b√¨nh lu·∫≠n c·ªßa kh√°ch h√†ng kh√¥ng h·∫≥n kh·ªõp v·ªõi m·ª©c ƒëi·ªÉm ƒë√°nh gi√° c√≥ th·ªÉ hi·ªÉu ƒë∆∞·ª£c b·∫±ng vi·ªác kh√°ch h√†ng th√≠ch ƒëi·ªÉm n√†y nh∆∞ng kh√¥ng th√≠ch ƒëi·ªÉm kia c·ªßa nh√† h√†ng. H∆°n n·ªØa, v·ªõi nh·ªØng kh√°ch h√†ng kh√°c nhau s·∫Ω c√≥ nh·ªØng c·∫£m nh·∫≠n kh√°c nhau, c√°ch cho ƒëi·ªÉm ƒë·ªëi v·ªõi t·ª´ng y·∫øu t·ªë c·ª• th·ªÉ gi·ªØa hai ng∆∞·ªùi c≈©ng s·∫Ω kh√°c nhau.\n",
    "\n",
    "\n",
    "- T·ª´ nh·ªØng gi·∫£ ƒë·ªãnh tr√™n, ta s·∫Ω ch·ªçn ra m·ªôt ng∆∞·ª°ng ƒëi·ªÉm ƒë·ªÉ ph√¢n lo·∫°i c√°c ƒë√°nh gi√° v√† b√¨nh lu·∫≠n. Ng∆∞·ª°ng ƒëi·ªÉm n√†y s·∫Ω kh√¥ng qu√° cao tr√™n ph·ªï ƒëi·ªÉm t·ª´ 1 - 10, d·ª±a tr√™n nh·ªØng l·∫≠p lu·∫≠n ·ªü tr√™n. V·ªõi c√°c s·ªë ƒëi·ªÉm v∆∞·ª£t tr√™n ng∆∞·ª°ng, ta c√≥ th·ªÉ xem nh√† h√†ng ƒë∆∞·ª£c ƒë√°nh gi√° c√≥ ch·∫•t l∆∞·ª£ng ·ªü m·ª©c ·ªïn ƒë·∫øn t·ªët, c√≥ th·ªÉ t·ªìn t·∫°i c·∫£ ƒëi·ªÉm h√†i l√≤ng v√† ch∆∞a h√†i l√≤ng nh∆∞ng nh√¨n chung l√† ƒë√°nh gi√° ·ªïn. Ng∆∞·ª£c l·∫°i, v·ªõi ƒëi·ªÉm d∆∞·ªõi ng∆∞·ª°ng, c√≥ th·ªÉ xem nh√† h√†ng nh·∫≠n ƒë√°nh gi√° kh√° ti√™u c·ª±c v√† c·∫ßn nh√¨n nh·∫≠n l·∫°i c√°ch cung c·∫•p d·ªãch v·ª• n√≥i chung.\n",
    "\n",
    "\n",
    "- Ta s·∫Ω ch·ªçn ng∆∞·ª°ng ƒëi·ªÉm l√† `6` ƒë·ªÉ ph√¢n lo·∫°i c√°c b√¨nh lu·∫≠n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a1bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score(score):\n",
    "    if score >= 6.0:\n",
    "        return 'Good'\n",
    "    else:\n",
    "        return 'Bad'\n",
    "    \n",
    "df['class'] = df.apply(lambda x: convert_score(x['review_score']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b3473eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good    32896\n",
       "Bad      6743\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5bc44",
   "metadata": {},
   "source": [
    "- C√°c b√¨nh lu·∫≠n 't√≠ch c·ª±c' chi·∫øm s·ªë l∆∞·ª£ng kh√° l·ªõn, g·∫ßn g·∫•p 5 l·∫ßn c√°c ƒë√°nh gi√° ti√™u c·ª±c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67bff0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "df['labels'] = encoder.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94e358d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32896\n",
       "0     6743\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b115b",
   "metadata": {},
   "source": [
    "- Ta s·∫Ω chu·∫©n b·ªã d·ªØ li·ªáu cho vi·ªác x√¢y d·ª±ng m√¥ h√¨nh ph√¢n lo·∫°i ƒë√°nh gi√° d·ªãch v·ª•:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ca16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1396dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc5a80",
   "metadata": {},
   "source": [
    "X·ª≠ l√Ω d·ªØ li·ªáu vƒÉn b·∫£n b·∫±ng l·ªõp `CountVectorizer` c·ªßa Sklearn v√† kh·ªõp v·ªõi t·∫≠p train, test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4229a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f13b5a",
   "metadata": {},
   "source": [
    "Ta s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi thu·∫≠t to√°n `MultinomialNB` v√† `BernoulliNB` c·ªßa l·ªõp `naive_bayes`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a0d0f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9252171405917757\n",
      "Test score : 0.9220484359233098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multiNB = MultinomialNB()\n",
    "multiNB.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train score : {}'.format(multiNB.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(multiNB.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d00dace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9123512750450938"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "multiNB_score = cross_val_score(multiNB, X_train_cv, y_train, cv=5)\n",
    "multiNB_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaafacd",
   "metadata": {},
   "source": [
    "Trung b√¨nh ki·ªÉm ƒë·ªãnh ch√©o kh√¥ng kh√°c bi·ªát qu√° l·ªõn. Ti·∫øp theo, ta s·∫Ω ƒë√°nh gi√° m√¥ h√¨nh b·∫±ng t·∫≠p test, ƒë·ªìng th·ªùi hi·ªÉn th·ªã c√°c th√¥ng s·ªë quan tr·ªçng trong vi·ªác ƒë√°nh gi√° b√†i to√°n ph√¢n lo·∫°i nh∆∞ \n",
    "\n",
    "_confusion matrix, precision_ v√† _recall_ :\n",
    "\n",
    "\n",
    "H√†m `eval_clf_testset` ƒë√£ ƒë∆∞·ª£c vi·∫øt s·∫µn trong th∆∞ vi·ªán Lib, h√†m n√†y tr·∫£ v·ªÅ ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh tr√™n t·∫≠p test, ma tr·∫≠n nh·∫ßm l·∫´n, c√°c gi√° tr·ªã precision, recall v√† f1-score c·ªßa t·ª´ng l·ªõp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3297c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.922\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1448  527]\n",
      " [ 400 9517]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1975\n",
      "           1       0.95      0.96      0.95      9917\n",
      "\n",
      "    accuracy                           0.92     11892\n",
      "   macro avg       0.87      0.85      0.86     11892\n",
      "weighted avg       0.92      0.92      0.92     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(multiNB, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b6b48ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9075215338595164\n",
      "Test score : 0.9047258661284897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "ber_nb = BernoulliNB()\n",
    "ber_nb.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train score : {}'.format(ber_nb.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(ber_nb.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a82651f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9047\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1603  372]\n",
      " [ 761 9156]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74      1975\n",
      "           1       0.96      0.92      0.94      9917\n",
      "\n",
      "    accuracy                           0.90     11892\n",
      "   macro avg       0.82      0.87      0.84     11892\n",
      "weighted avg       0.91      0.90      0.91     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(ber_nb, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a8503ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034495169164479"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber_score = cross_val_score(ber_nb, X_train_cv, y_train, cv = 5)\n",
    "ber_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8667326",
   "metadata": {},
   "source": [
    "Ta s·∫Ω th·ª≠ ph√¢n lo·∫°i v·ªõi m·ªôt thu·∫≠t to√°n ph·ªï bi·∫øn kh√°c s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p x√°c su·∫•t ƒë·ªÉ ph√¢n lo·∫°i c√°c l·ªõp,\n",
    "\n",
    "`Logistic Regression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c5322a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9584099181893538\n",
      "Test score : 0.9273461150353178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(random_state = 42)\n",
    "logit.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train score : {}'.format(logit.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(logit.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c66e351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9212171075382465"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_score = cross_val_score(logit, X_train_cv, y_train, cv=5)\n",
    "logit_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fec2e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9273\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1441  534]\n",
      " [ 330 9587]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1975\n",
      "           1       0.95      0.97      0.96      9917\n",
      "\n",
      "    accuracy                           0.93     11892\n",
      "   macro avg       0.88      0.85      0.86     11892\n",
      "weighted avg       0.93      0.93      0.93     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(logit, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7824e20",
   "metadata": {},
   "source": [
    "- T∆∞∆°ng t·ª± nh∆∞ `MultinomialNB` v√† `BernoulliNB`, m√¥ h√¨nh `Logistic Regression` c√≥ ƒëi·ªÉm `precision, recall v√† f1-score` c·ªßa l·ªõp 0 kh√° th·∫•p so v·ªõi l·ªõp 1, ƒëi·ªÅu n√†y c√≥ th·ªÉ do d·ªØ li·ªáu b·ªã l·ªách gi·ªØa 2 class d·∫´n ƒë·∫øn b·ªô ph√¢n lo·∫°i c√≥ hi·ªáu su·∫•t ko t·ªët ·ªü l·ªõp 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a29018",
   "metadata": {},
   "source": [
    "C√°c b·ªô ph√¢n lo·∫°i t·ª´ ƒë·∫ßu ƒë·∫øn gi·ªù ƒë·ªÅu c√≥ m·ªôt ƒëi·ªÉm chung l√† c√≥ th·ªÉ ∆∞·ªõc t√≠nh x√°c su·∫•t c·ªßa t·ª´ng l·ªõp, b√¢y gi·ªù ta s·∫Ω hu·∫•n luy·ªán v·ªõi m·ªôt m√¥ h√¨nh m·∫°nh m·∫Ω kh√°c s·ª≠ d·ª•ng c√°c ranh gi·ªõi ƒë·ªÉ ph√¢n lo·∫°i: `Support Vector Machine`.\n",
    "\n",
    "Ta s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi `SVC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fac7317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9556708833387393\n",
      "Test score : 0.925748402287252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(random_state = 42)\n",
    "svc.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train score : {}'.format(svc.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(svc.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1029c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC cross validation took 2.61 minutes.\n",
      "0.9179374905631889\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "svc_score = cross_val_score(svc, X_train_cv, y_train, cv=5, n_jobs = -1)\n",
    "t2 = time.time()\n",
    "\n",
    "print('SVC cross validation took {:.2f} minutes.'.format((t2 - t1) / 60))\n",
    "print(svc_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14e352fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9257\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1280  695]\n",
      " [ 188 9729]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.65      0.74      1975\n",
      "           1       0.93      0.98      0.96      9917\n",
      "\n",
      "    accuracy                           0.93     11892\n",
      "   macro avg       0.90      0.81      0.85     11892\n",
      "weighted avg       0.92      0.93      0.92     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(svc, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad98ac",
   "metadata": {},
   "source": [
    "Ta s·∫Ω th·ª≠ th√™m m·ªôt m√¥ h√¨nh SVM kh√°c cho t√°c v·ª• ph√¢n lo·∫°i, l·∫ßn n√†y l√† `LinearSVC`, ta c≈©ng s·∫Ω b·∫Øt ƒë·∫ßu v·ªõi c√°c tham s·ªë m·∫∑c ƒë·ªãnh: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7ad6bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9726456914261001\n",
      "Test score : 0.9129667003027245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lin_svc = LinearSVC(random_state = 42)\n",
    "lin_svc.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train score : {}'.format(lin_svc.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(lin_svc.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5508f502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066928900426827"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svc_score = cross_val_score(lin_svc, X_train_cv, y_train, cv=5)\n",
    "lin_svc_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efba193b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.913\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1418  557]\n",
      " [ 478 9439]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73      1975\n",
      "           1       0.94      0.95      0.95      9917\n",
      "\n",
      "    accuracy                           0.91     11892\n",
      "   macro avg       0.85      0.83      0.84     11892\n",
      "weighted avg       0.91      0.91      0.91     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(lin_svc, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d442f8",
   "metadata": {},
   "source": [
    "Ta s·∫Ω th·ª≠ t√¨m ki·∫øm d·∫°ng l∆∞·ªõi v·ªõi m√¥ h√¨nh n√†y v·ªõi hy v·ªçng s·∫Ω c·∫£i thi·ªán ƒë∆∞·ª£c c√°c ƒëi·ªÉm s·ªë ƒë√°nh gi√° m√† ta quan t√¢m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59a629bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for LinearSVC took 1.23 minutes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_lin_svc = [{'loss': ['hinge', 'squared-hinge'], \n",
    "                   'C': [1, 10, 100, 1000], \n",
    "                   'max_iter': [1000, 5000, 10000],\n",
    "                   'dual': [True, False]}]\n",
    "\n",
    "grid_search_lin_svc = GridSearchCV(LinearSVC(random_state = 42), \n",
    "                                   params_lin_svc, cv=4, n_jobs = -1)\n",
    "t1 = time.time()\n",
    "grid_search_lin_svc.fit(X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print('Grid Search for LinearSVC took {:.2f} minutes.'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15c50738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'dual': True, 'loss': 'hinge', 'max_iter': 1000}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lin_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "554774d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9674199012505856\n",
      "Test score : 0.9203666330306088\n"
     ]
    }
   ],
   "source": [
    "print('Train score : {}'.format(grid_search_lin_svc.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(grid_search_lin_svc.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee3e838d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133242869829642"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svc_gr = cross_val_score(grid_search_lin_svc, X_train_cv, y_train)\n",
    "lin_svc_gr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dcaa3c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9204\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1431  544]\n",
      " [ 403 9514]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75      1975\n",
      "           1       0.95      0.96      0.95      9917\n",
      "\n",
      "    accuracy                           0.92     11892\n",
      "   macro avg       0.86      0.84      0.85     11892\n",
      "weighted avg       0.92      0.92      0.92     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(grid_search_lin_svc, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a8de8",
   "metadata": {},
   "source": [
    "K·∫øt qu·∫£ t∆∞∆°ng t·ª± nh∆∞ c√°c tham s·ªë m·∫∑c ƒë·ªãnh, kh√°c bi·ªát nh·ªè ·ªü ƒë√¢y l√† T√¨m ki·∫øm d·∫°ng l∆∞·ªõi cho th·∫•y h√†m loss trong `LinearSVC` l√† __hinge__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf35a3",
   "metadata": {},
   "source": [
    "C√°c m√¥ h√¨nh ƒë·ªôc l·∫≠p ho·∫°t ƒë·ªông t∆∞∆°ng ƒë·ªëi t·ªët tr√™n d·ªØ li·ªáu, b√¢y gi·ªù ta s·∫Ω xem c√°c m√¥ h√¨nh h·ªçc _ensemble_ ho·∫°t ƒë·ªông ra sao.\n",
    "\n",
    "Kh·ªüi ƒë·∫ßu v·ªõi `RandomForestClassifier` v√† c√°c tham s·ªë m·∫∑c ƒë·ªãnh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "313f9fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier training took 0.447 minutes.\n",
      "Train score : 0.9991710815583666\n",
      "Test score : 0.9159098553649512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state = 42)\n",
    "t1 = time.time()\n",
    "forest.fit(X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print('RandomForestClassifier training took {:.3f} minutes.'.format((t2 - t1) / 60))\n",
    "print('Train score : {}'.format(forest.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(forest.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff0ef631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9071615987946858"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_score = cross_val_score(forest, X_train_cv, y_train, cv=5)\n",
    "forest_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef60dd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9159\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1090  885]\n",
      " [ 115 9802]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.55      0.69      1975\n",
      "           1       0.92      0.99      0.95      9917\n",
      "\n",
      "    accuracy                           0.92     11892\n",
      "   macro avg       0.91      0.77      0.82     11892\n",
      "weighted avg       0.92      0.92      0.91     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(forest, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea0532",
   "metadata": {},
   "source": [
    "M√¥ h√¨nh b·ªã overfitting nh·∫π v√† c√°c ƒëi·ªÉm s·ªë ƒë√°nh gi√° c√≥ v·∫ª kh√° th·∫•p n·∫øu so v·ªõi c√°c k·∫øt qu·∫£ c√≥ ƒë∆∞·ª£c t·ª´ c√°c m√¥ h√¨nh ph√≠a tr√™n. \n",
    "\n",
    "Ta s·∫Ω d√πng T√¨m ki·∫øm d·∫°ng l∆∞·ªõi ƒë·ªÉ tinh ch·ªânh c√°c Si√™u tham s·ªë v·ªõi hy v·ªçng m√¥ h√¨nh s·∫Ω ho·∫°t ƒë·ªông t·ªët h∆°n: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5b51c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search RandomForestClassifier took 20.38 minutes.\n"
     ]
    }
   ],
   "source": [
    "params_forest = {'n_estimators': [90, 120, 150],\n",
    "                'bootstrap': [True, False], \n",
    "                'max_depth': [1, 3, 5, 7, None]}\n",
    "\n",
    "grid_search_forest = GridSearchCV(RandomForestClassifier(random_state = 42), params_forest, cv=4)\n",
    "t1 = time.time()\n",
    "grid_search_forest.fit(X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print('Grid Search RandomForestClassifier took {:.2f} minutes.'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "836146ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_depth': None, 'n_estimators': 150}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e501d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9991710815583666\n",
      "Test score : 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Train score : {}'.format(grid_search_forest.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(grid_search_forest.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d907c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9167\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1126  849]\n",
      " [ 142 9775]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.69      1975\n",
      "           1       0.92      0.99      0.95      9917\n",
      "\n",
      "    accuracy                           0.92     11892\n",
      "   macro avg       0.90      0.78      0.82     11892\n",
      "weighted avg       0.91      0.92      0.91     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(grid_search_forest, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985102db",
   "metadata": {},
   "source": [
    "K·∫øt qu·∫£ c√≥ v·∫ª kh√¥ng kh·∫£ quan h∆°n so v·ªõi c√°c tham s·ªë m·∫∑c ƒë·ªãnh.\n",
    "\n",
    "M·ªôt l·ª±a ch·ªçn kh√°c cho vi·ªác s·ª≠ d·ª•ng C√¢y Quy·∫øt ƒë·ªãnh trong l·ªõp _ensemble_ c·ªßa Sklearn l√† m√¥ h√¨nh C√¢y Si√™u ng·∫´u nhi√™n `ExtraTreesClassifier`\n",
    "\n",
    "`ExtraTreesClassifier` s·ª≠ d·ª•ng ng∆∞·ª°ng ng·∫´u nhi√™n ƒë·ªëi v·ªõi t·ª´ng ƒë·∫∑c tr∆∞ng thay v√¨ t√¨m ki·∫øm c√°c ng∆∞·ª°ng t·ªët nh·∫•t n√™n th·ªùi gian ch·∫°y thu·∫≠t to√°n s·∫Ω r√∫t ng·∫Øn so v·ªõi `Decision Tree`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9328c74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier training took 3.81 minutes.\n",
      "Train score : 0.9991710815583666\n",
      "Test score : 0.9162462159434914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "trees = ExtraTreesClassifier(n_estimators = 120, random_state = 42)\n",
    "t1 = time.time()\n",
    "trees.fit(X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print('ExtraTreesClassifier training took {:.2f} minutes.'.format((t2 - t1) / 60))\n",
    "print('Train score : {}'.format(trees.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(trees.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14ed8edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9074858711658136"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_score = cross_val_score(trees, X_train_cv, y_train, cv=5)\n",
    "trees_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e62b8083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9162\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1110  865]\n",
      " [ 131 9786]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.56      0.69      1975\n",
      "           1       0.92      0.99      0.95      9917\n",
      "\n",
      "    accuracy                           0.92     11892\n",
      "   macro avg       0.91      0.77      0.82     11892\n",
      "weighted avg       0.91      0.92      0.91     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(trees, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317056ce",
   "metadata": {},
   "source": [
    "- Hi·ªáu su·∫•t c·ªßa C√¢y si√™u ng·∫´u nhi√™n kh√° t∆∞∆°ng ƒë·ªìng v·ªõi R·ª´ng ng·∫´u nhi√™n: ph√¢n lo·∫°i kh√° k√©m ·ªü l·ªõp 0.\n",
    "\n",
    "\n",
    "\n",
    "- Ta s·∫Ω th·ª≠ m·ªôt thu·∫≠t to√°n kh√°c trong l·ªõp _ensemble_: `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4961f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.9526074890979205\n",
      "Test score : 0.9289438277833838\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(random_state = 42)\n",
    "xgb_clf.fit(X_train_cv, y_train)\n",
    "\n",
    "print('Train score : {}'.format(xgb_clf.score(X_train_cv, y_train)))\n",
    "print('Test score : {}'.format(xgb_clf.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "518e6dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197033797177967"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_score = cross_val_score(xgb_clf, X_train_cv, y_train)\n",
    "xgb_clf_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a2b3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9289\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1377  598]\n",
      " [ 247 9670]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77      1975\n",
      "           1       0.94      0.98      0.96      9917\n",
      "\n",
      "    accuracy                           0.93     11892\n",
      "   macro avg       0.89      0.84      0.86     11892\n",
      "weighted avg       0.93      0.93      0.93     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(xgb_clf, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459977f8",
   "metadata": {},
   "source": [
    "`XGBoost` kh·ªõp d·ªØ li·ªáu t∆∞∆°ng ƒë·ªëi t·ªët, c√°c ch·ªâ s·ªë metrics ·ªü l·ªõp 0 ƒë∆∞·ª£c c·∫£i thi·ªán t·ªët h∆°n so v·ªõi c√°c thu·∫≠t to√°n c√πng l·ªõp ph√≠a tr√™n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11dac576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot([1] * 5, multiNB_score, '.')\n",
    "plt.plot([2] * 5, logit_score, '.')\n",
    "plt.plot([3] * 5, svc_score, '.')\n",
    "plt.plot([4] * 5, lin_svc_gr, '.')\n",
    "plt.plot([5] * 5, forest_score, '.')\n",
    "plt.plot([6] * 5, trees_score, '.')\n",
    "plt.plot([7] * 5, xgb_clf_score, '.')\n",
    "plt.plot([8] * 5, ber_score, '.')\n",
    "\n",
    "plt.boxplot([multiNB_score, logit_score, svc_score, lin_svc_gr, \n",
    "             forest_score, trees_score, xgb_clf_score, ber_score],\n",
    "           labels = ['Multinomial', 'Logistic', 'SVC', 'LinearSVC', \n",
    "                     'Random Forest', 'Extra Trees', 'XGBoost', 'BernoulliNB'])\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.ylim([0.90, 0.95])\n",
    "plt.grid(True)\n",
    "plt.title('Classification Model Performance by Accuracy Score \\n', fontsize = 18, color = 'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c6c54",
   "metadata": {},
   "source": [
    "Bi·ªÉu ƒë·ªì tr√™n ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c tr√™n 5 fold ki·ªÉm ƒë·ªãnh ch√©o tr√™n t·∫≠p hu·∫•n luy·ªán.  Nh√¨n chung, c√°c b·ªô ph√¢n lo·∫°i m√† ta s·ª≠ d·ª•ng ho·∫°t ƒë·ªông kh√° t·ªët tr√™n t·∫≠p hu·∫•n luy·ªán, ƒë·ªô ch√≠nh x√°c >= 90%. C√≥ th·ªÉ th·∫•y c√°c b·ªô ph√¢n lo·∫°i ƒë∆°n l·∫ª ho·∫°t ƒë·ªông t·ªët h∆°n m·ªôt ch√∫t so v·ªõi c√°c b·ªô ph√¢n lo·∫°i k·∫øt h·ª£p.\n",
    "\n",
    "\n",
    "Vi·ªác ch·ªçn ra m·ªôt thu·∫≠t to√°n ph√¢n lo·∫°i t·ªët nh·∫•t cho t·∫≠p hu·∫•n luy·ªán tr√™n c√≥ v·∫ª h∆°i kh√≥ khƒÉn m·ªôt ch√∫t, v√¨ c√°c ch·ªâ s·ªë ƒë√°nh gi√° m·ªôt b·ªô ph√¢n lo·∫°i m√† ta quan t√¢m trong tr∆∞·ªùng h·ª£p n√†y kh√¥ng h·∫≥n ch·ªâ d·ª±a tr√™n _accuracy score_. Vi·ªác quan t√¢m ƒë·∫øn _precision, recall, f1-score_ tr√™n t·ª´ng l·ªõp s·∫Ω cho c√°i nh√¨n t·ªïng qu√°t h∆°n.\n",
    "\n",
    "\n",
    "M·ªôt c√°ch ti·∫øp c·∫≠n cho tr∆∞·ªùng h·ª£p n√†y l√† k·∫øt h·ª£p c√°c b·ªô ph√¢n lo·∫°i v·ªõi nhau th√†nh m·ªôt b·ªô ph√¢n lo·∫°i bi·ªÉu quy·∫øt. ƒêi·ªÅu n√†y c√≥ v·∫ª kh·∫£ thi v√¨ tr√™n c√πng m·ªôt b·ªô d·ªØ li·ªáu, ta ƒë√£ hu·∫•n luy·ªán 8 b·ªô ph√¢n lo·∫°i ƒë·ªôc l·∫≠p kh√°c nhau, ƒëi·ªÅu n√†y l√†m tƒÉng kh·∫£ nƒÉng c√°c b·ªô ph√¢n lo·∫°i n√†y m·∫Øc ph·∫£i nh·ªØng l·ªói r·∫•t kh√°c nhau. Vi·ªác k·∫øt h·ª£p c√°c b·ªô ph√¢n lo·∫°i n√†y th√†nh m·ªôt b·ªô ph√¢n lo·∫°i ___ensemble___ c√≥ th·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c v√† c√°c ch·ªâ s·ªë ƒë√°nh gi√° kh√°c.\n",
    "\n",
    "\n",
    "Ta s·∫Ω x√¢y d·ª±ng m·ªôt b·ªô ph√¢n lo·∫°i bi·ªÉu quy·∫øt v·ªõi c√°c m√¥ h√¨nh d·ª± ƒëo√°n ph√≠a tr√™n k√®m theo c√°c si√™u tham s·ªë ƒë√£ ƒë∆∞·ª£c tinh ch·ªânh c·ªßa ch√∫ng. ƒê·ªÉ r√∫t ng·∫Øn th·ªùi gian hu·∫•n luy·ªán v√† tƒÉng hi·ªáu qu·∫£ cho b·ªô ph√¢n lo·∫°i bi·ªÉu quy·∫øt, ta s·∫Ω ch·ªâ l·ª±a ch·ªçn c√°c b·ªô ph√¢n lo·∫°i c√≥ ƒë·ªô ch√≠nh x√°c tr√™n 5 fold ki·ªÉm ƒë·ªãnh ch√©o ƒë·ªÅu t·ª´ 0.91 tr·ªü l√™n: `Logistic Regression, SVC, XGBoost` ƒë∆∞·ª£c l·ª±a ch·ªçn.\n",
    "\n",
    "\n",
    "B·∫Øt ƒë·∫ßu v·ªõi `Voting Classifier` trong l·ªõp _ensemble_ c·ªßa Sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96a5f8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier training took 30.84 minutes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "multiNB = MultinomialNB()\n",
    "logit_clf = LogisticRegression(random_state = 42)\n",
    "svc = SVC(probability = True, random_state = 42)\n",
    "lin_svc = LinearSVC(loss = 'hinge', random_state = 42)\n",
    "forest_clf = RandomForestClassifier(random_state = 42)\n",
    "trees_clf = ExtraTreesClassifier(random_state = 42)\n",
    "xgb_clf = xgb.XGBClassifier(random_state = 42)\n",
    "\n",
    "named_estimators = [\n",
    "#                     ('multiNB', multiNB),\n",
    "                    ('logit_clf', logit_clf),\n",
    "                    ('svc', svc),\n",
    "#                     ('lin_svc', lin_svc),\n",
    "#                     ('forest_clf', forest_clf),\n",
    "#                     ('trees_clf', trees_clf),\n",
    "                    ('xgb_clf', xgb_clf)\n",
    "                    ]\n",
    "\n",
    "voting_clf = VotingClassifier(named_estimators)\n",
    "t1 = time.time()\n",
    "voting_clf.fit(X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print('Voting Classifier training took {:.2f} minutes.'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2751da6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581576386636393"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7adf7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Score: 0.925433817309831\n",
      "Voting Classifier cross-validation took 41.39 minutes.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "voting_clf_score = cross_val_score(voting_clf, X_train_cv, y_train, cv=5)\n",
    "t2 = time.time()\n",
    "\n",
    "print('Voting Score: {}'.format(voting_clf_score.mean()))\n",
    "print('Voting Classifier cross-validation took {:.2f} minutes.'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b66608",
   "metadata": {},
   "source": [
    "Trung b√¨nh ƒëi·ªÉm s·ªë ƒë√°nh gi√° tr√™n 5 fold cao h∆°n h·∫≥n so v·ªõi b·∫•t k·ª≥ b·ªô ph√¢n lo·∫°i n√†o tr∆∞·ªõc ƒë√≥.\n",
    "\n",
    "Ta s·∫Ω xem m√¥ h√¨nh ho·∫°t ƒë·ªông ra sao tr√™n t·∫≠p ki·ªÉm tra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b98ef0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9338\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1390  585]\n",
      " [ 202 9715]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.78      1975\n",
      "           1       0.94      0.98      0.96      9917\n",
      "\n",
      "    accuracy                           0.93     11892\n",
      "   macro avg       0.91      0.84      0.87     11892\n",
      "weighted avg       0.93      0.93      0.93     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(voting_clf, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a107a64",
   "metadata": {},
   "source": [
    "- C√°c ch·ªâ s·ªë ƒë√°nh gi√° tr√™n t·∫≠p ki·ªÉm tra c√≥ c·∫£i thi·ªán h∆°n so v·ªõi c√°c b·ªô ph√¢n lo·∫°i tr∆∞·ªõc ƒë√≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2e39ac9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot([1] * 5, multiNB_score, '.')\n",
    "plt.plot([2] * 5, logit_score, '.')\n",
    "plt.plot([3] * 5, svc_score, '.')\n",
    "plt.plot([4] * 5, lin_svc_gr, '.')\n",
    "plt.plot([5] * 5, forest_score, '.')\n",
    "plt.plot([6] * 5, trees_score, '.')\n",
    "plt.plot([7] * 5, xgb_clf_score, '.')\n",
    "plt.plot([8] * 5, ber_score, '.')\n",
    "plt.plot([9] * 5, voting_clf_score, '.')\n",
    "plt.boxplot([multiNB_score, logit_score, svc_score, lin_svc_gr, \n",
    "             forest_score, trees_score, xgb_clf_score, ber_score, voting_clf_score],\n",
    "           labels = ['Multinomial', 'Logistic', 'SVC', 'LinearSVC', \n",
    "                     'Random Forest', 'Extra Trees', 'XGBoost', 'BernoulliNB', 'VOTING'])\n",
    "plt.ylabel('Accuracy', fontsize = 15)\n",
    "plt.ylim([0.90, 0.95])\n",
    "plt.grid(True)\n",
    "plt.title('Classification Model Performance by Accuracy Score \\n', fontsize = 18, color = 'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8bed3",
   "metadata": {},
   "source": [
    "B·ªô ph√¢n lo·∫°i bi·ªÉu quy·∫øt c√≥ th·ªÉ l√† m√¥ h√¨nh ph√¢n lo·∫°i kh√° ·ªïn cho ƒë·∫øn th·ªùi ƒëi·ªÉm n√†y.\n",
    "\n",
    "B·ªô ph√¢n lo·∫°i bi·ªÉu quy·∫øt m√† ta ƒëang s·ª≠ d·ª•ng d·ª±a tr√™n bi·ªÉu quy·∫øt c·ª©ng _(hard voting)_. Ta s·∫Ω thay ƒë·ªïi th√†nh b·ªô bi·ªÉu quy·∫øt m·ªÅm _(soft voting)_ v·ªõi hy v·ªçng ƒë·ªô ch√≠nh x√°c s·∫Ω c·∫£i thi·ªán h∆°n:\n",
    "\n",
    "- _Soft voting_ th∆∞·ªùng ƒë·∫°t ch·∫•t l∆∞·ª£ng cao h∆°n v√¨ s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c ∆∞·ªõc t√≠nh x√°c su·∫•t c·ªßa t·ª´ng l·ªõp, ƒë·ªìng th·ªùi, c√°c bi·ªÉu quy·∫øt c√≥ ƒë·ªô tin c·∫≠y cao  s·∫Ω ƒë∆∞·ª£c g√°n tr·ªçng s·ªë l·ªõn h∆°n.\n",
    "- C√°c b·ªô ph√¢n lo·∫°i ta ƒë√£ s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh ƒë·ªÅu c√≥ ph∆∞∆°ng th·ª©c `predict_proba`, ngo·∫°i tr·ª´ `SVC`. ƒê·ªëi v·ªõi `SVC`, ta s·∫Ω ch·ªânh tham s·ªë `probability = True` ƒë·ªÉ c√≥ ph∆∞∆°ng th·ª©c ∆∞·ªõc t√≠nh x√°c su·∫•t c√°c l·ªõp, ƒë√°nh ƒë·ªïi b·∫±ng th·ªùi gian hu·∫•n luy·ªán l√¢u h∆°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45e16c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Modified training took 750.04s.\n"
     ]
    }
   ],
   "source": [
    "named_estimators1 = [\n",
    "#                     ('multiNB', multiNB),\n",
    "                    ('logit_clf', logit_clf),\n",
    "                    ('svc', svc),\n",
    "#                     ('lin_svc', lin_svc),\n",
    "#                     ('forest_clf', forest_clf),\n",
    "#                     ('trees_clf', trees_clf),\n",
    "                    ('xgb_clf', xgb_clf)\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "voting_modified = VotingClassifier(named_estimators1)\n",
    "t1 = time.time()\n",
    "voting_modified.fit(X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "\n",
    "print('Voting Modified training took {:.2f}s.'.format(t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcbcaf8",
   "metadata": {},
   "source": [
    "M√¥ h√¨nh bi·ªÉu quy·∫øt n√†y v·∫´n l√† ___hard voting___ , ta s·∫Ω so s√°nh v·ªõi ___soft voting___ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "787d22ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting score: 0.93\n",
      "Hard Voting time: 26.89 minutes.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "hard_score = cross_val_score(voting_modified, X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "print('Hard Voting score: {:.2f}'.format(hard_score.mean()))\n",
    "print('Hard Voting time: {:.2f} minutes.'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "648b7e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9338\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1390  585]\n",
      " [ 202 9715]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.78      1975\n",
      "           1       0.94      0.98      0.96      9917\n",
      "\n",
      "    accuracy                           0.93     11892\n",
      "   macro avg       0.91      0.84      0.87     11892\n",
      "weighted avg       0.93      0.93      0.93     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(voting_modified, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c50fb0",
   "metadata": {},
   "source": [
    "B√¢y gi·ªù ta s·∫Ω ƒë·ªïi th√†nh b·ªô ph√¢n lo·∫°i bi·ªÉu quy·∫øt ___soft voting___ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41d5d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_modified.voting = 'soft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "815dbc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting score: 0.93\n",
      "Soft Voting time: 20.14 minutes.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "soft_score = cross_val_score(voting_modified, X_train_cv, y_train)\n",
    "t2 = time.time()\n",
    "print('Soft Voting score: {:.2f}'.format(soft_score.mean()))\n",
    "print('Soft Voting time: {:.2f} minutes.'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da4e6f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASSIFICATION MODEL PREFOMANCE IN TEST SET-----\n",
      "* R-squared model of Test: 0.9342\n",
      "\n",
      "* Confusion Matrix of Test: \n",
      "[[1441  534]\n",
      " [ 249 9668]]\n",
      "\n",
      "* Classification Report of Test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79      1975\n",
      "           1       0.95      0.97      0.96      9917\n",
      "\n",
      "    accuracy                           0.93     11892\n",
      "   macro avg       0.90      0.85      0.87     11892\n",
      "weighted avg       0.93      0.93      0.93     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc.eval_clf_testset(voting_modified, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3056ab",
   "metadata": {},
   "source": [
    "Ki·ªÉm ƒë·ªãnh ch√©o v·ªõi ___soft voting___ cho k·∫øt qu·∫£ t∆∞∆°ng ƒë∆∞∆°ng so v·ªõi ___hard voting___, tuy nhi√™n th·ªùi gian x·ª≠ l√Ω ng·∫Øn h∆°n. Ta s·∫Ω d√πng b·ªô ph√¢n lo·∫°i bi·ªÉu quy·∫øt v·ªõi ph∆∞∆°ng th·ª©c `soft voting` ƒë·ªÉ l∆∞u model v√† ƒë√°nh gi√° tr√™n d·ªØ li·ªáu m·ªõi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714a0e5",
   "metadata": {},
   "source": [
    "Ta s·∫Ω d√πng m·ªôt c√°ch ti·∫øp c·∫≠n kh√°c cho vi·ªác ph√¢n lo·∫°i, ƒë√≥ l√† s·ª≠ d·ª•ng m·∫°ng `Neural Network` v·ªõi l·ªõp _Embedding_ cho vi·ªác x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n, m·∫°ng t√≠ch ch·∫≠p 1 chi·ªÅu v√† LSTM 2 chi·ªÅu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26d98766",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1200\n",
    "max_length = 150\n",
    "embedding_dim = 64\n",
    "oov_tok = '<OOV>'\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f8a902",
   "metadata": {},
   "source": [
    "- X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v·ªõi l·ªõp `Tokenizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6674a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequence = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequence, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
    "\n",
    "valid_sequence = tokenizer.texts_to_sequences(X_test)\n",
    "valid_padded = pad_sequences(valid_sequence, maxlen = max_length, padding = padding_type, truncating = trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ddb4c",
   "metadata": {},
   "source": [
    "B·∫Øt ƒë·∫ßu ph√¢n lo·∫°i v·ªõi l·ªõp `GlobalAveragePooling1D`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a006b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "868/868 - 2s - loss: 0.2769 - accuracy: 0.8912 - val_loss: 0.1949 - val_accuracy: 0.9250 - 2s/epoch - 2ms/step\n",
      "Epoch 2/150\n",
      "868/868 - 1s - loss: 0.1837 - accuracy: 0.9297 - val_loss: 0.1887 - val_accuracy: 0.9273 - 1s/epoch - 1ms/step\n",
      "Epoch 3/150\n",
      "868/868 - 1s - loss: 0.1755 - accuracy: 0.9331 - val_loss: 0.1809 - val_accuracy: 0.9318 - 1s/epoch - 1ms/step\n",
      "Epoch 4/150\n",
      "868/868 - 1s - loss: 0.1675 - accuracy: 0.9347 - val_loss: 0.1750 - val_accuracy: 0.9337 - 1s/epoch - 1ms/step\n",
      "Epoch 5/150\n",
      "868/868 - 1s - loss: 0.1620 - accuracy: 0.9375 - val_loss: 0.1842 - val_accuracy: 0.9288 - 1s/epoch - 1ms/step\n",
      "Epoch 6/150\n",
      "868/868 - 1s - loss: 0.1574 - accuracy: 0.9386 - val_loss: 0.1931 - val_accuracy: 0.9203 - 1s/epoch - 2ms/step\n",
      "Epoch 7/150\n",
      "868/868 - 2s - loss: 0.1545 - accuracy: 0.9397 - val_loss: 0.1813 - val_accuracy: 0.9325 - 2s/epoch - 2ms/step\n",
      "Epoch 8/150\n",
      "868/868 - 1s - loss: 0.1497 - accuracy: 0.9400 - val_loss: 0.1865 - val_accuracy: 0.9319 - 1s/epoch - 1ms/step\n",
      "Epoch 9/150\n",
      "868/868 - 1s - loss: 0.1455 - accuracy: 0.9428 - val_loss: 0.1843 - val_accuracy: 0.9336 - 1s/epoch - 1ms/step\n",
      "Epoch 10/150\n",
      "868/868 - 1s - loss: 0.1431 - accuracy: 0.9431 - val_loss: 0.1865 - val_accuracy: 0.9340 - 1s/epoch - 1ms/step\n",
      "Epoch 11/150\n",
      "868/868 - 1s - loss: 0.1404 - accuracy: 0.9439 - val_loss: 0.2083 - val_accuracy: 0.9220 - 1s/epoch - 1ms/step\n",
      "Epoch 12/150\n",
      "868/868 - 1s - loss: 0.1374 - accuracy: 0.9464 - val_loss: 0.2206 - val_accuracy: 0.9169 - 1s/epoch - 1ms/step\n",
      "Epoch 13/150\n",
      "868/868 - 1s - loss: 0.1364 - accuracy: 0.9448 - val_loss: 0.2050 - val_accuracy: 0.9324 - 1s/epoch - 2ms/step\n",
      "Epoch 14/150\n",
      "868/868 - 1s - loss: 0.1326 - accuracy: 0.9464 - val_loss: 0.2086 - val_accuracy: 0.9290 - 1s/epoch - 1ms/step\n",
      "Epoch 15/150\n",
      "868/868 - 1s - loss: 0.1321 - accuracy: 0.9473 - val_loss: 0.2144 - val_accuracy: 0.9316 - 1s/epoch - 1ms/step\n",
      "Epoch 16/150\n",
      "868/868 - 1s - loss: 0.1276 - accuracy: 0.9480 - val_loss: 0.2182 - val_accuracy: 0.9311 - 1s/epoch - 1ms/step\n",
      "Epoch 17/150\n",
      "868/868 - 1s - loss: 0.1239 - accuracy: 0.9491 - val_loss: 0.2268 - val_accuracy: 0.9300 - 1s/epoch - 1ms/step\n",
      "Epoch 18/150\n",
      "868/868 - 1s - loss: 0.1204 - accuracy: 0.9497 - val_loss: 0.2266 - val_accuracy: 0.9270 - 1s/epoch - 1ms/step\n",
      "Epoch 19/150\n",
      "868/868 - 1s - loss: 0.1177 - accuracy: 0.9512 - val_loss: 0.2437 - val_accuracy: 0.9274 - 1s/epoch - 1ms/step\n",
      "Epoch 20/150\n",
      "868/868 - 1s - loss: 0.1142 - accuracy: 0.9527 - val_loss: 0.2391 - val_accuracy: 0.9293 - 1s/epoch - 2ms/step\n",
      "Epoch 21/150\n",
      "868/868 - 2s - loss: 0.1106 - accuracy: 0.9525 - val_loss: 0.2527 - val_accuracy: 0.9278 - 2s/epoch - 2ms/step\n",
      "Epoch 22/150\n",
      "868/868 - 1s - loss: 0.1088 - accuracy: 0.9536 - val_loss: 0.2585 - val_accuracy: 0.9256 - 1s/epoch - 2ms/step\n",
      "Epoch 23/150\n",
      "868/868 - 1s - loss: 0.1033 - accuracy: 0.9578 - val_loss: 0.2952 - val_accuracy: 0.9273 - 1s/epoch - 1ms/step\n",
      "Epoch 24/150\n",
      "868/868 - 1s - loss: 0.1006 - accuracy: 0.9581 - val_loss: 0.3312 - val_accuracy: 0.9202 - 1s/epoch - 2ms/step\n",
      "Epoch 25/150\n",
      "868/868 - 1s - loss: 0.0967 - accuracy: 0.9604 - val_loss: 0.3057 - val_accuracy: 0.9224 - 1s/epoch - 1ms/step\n",
      "Epoch 26/150\n",
      "868/868 - 1s - loss: 0.0947 - accuracy: 0.9606 - val_loss: 0.3312 - val_accuracy: 0.9126 - 1s/epoch - 2ms/step\n",
      "Epoch 27/150\n",
      "868/868 - 1s - loss: 0.0938 - accuracy: 0.9625 - val_loss: 0.3271 - val_accuracy: 0.9189 - 1s/epoch - 1ms/step\n",
      "Epoch 28/150\n",
      "868/868 - 2s - loss: 0.0867 - accuracy: 0.9647 - val_loss: 0.3381 - val_accuracy: 0.9140 - 2s/epoch - 2ms/step\n",
      "Epoch 29/150\n",
      "868/868 - 1s - loss: 0.0863 - accuracy: 0.9657 - val_loss: 0.3652 - val_accuracy: 0.9190 - 1s/epoch - 2ms/step\n",
      "Epoch 30/150\n",
      "868/868 - 1s - loss: 0.0821 - accuracy: 0.9670 - val_loss: 0.3840 - val_accuracy: 0.9201 - 1s/epoch - 2ms/step\n",
      "Epoch 31/150\n",
      "868/868 - 1s - loss: 0.0799 - accuracy: 0.9670 - val_loss: 0.3770 - val_accuracy: 0.9191 - 1s/epoch - 2ms/step\n",
      "Epoch 32/150\n",
      "868/868 - 1s - loss: 0.0776 - accuracy: 0.9683 - val_loss: 0.4199 - val_accuracy: 0.9157 - 1s/epoch - 1ms/step\n",
      "Epoch 33/150\n",
      "868/868 - 1s - loss: 0.0724 - accuracy: 0.9708 - val_loss: 0.4157 - val_accuracy: 0.9142 - 1s/epoch - 1ms/step\n",
      "Epoch 34/150\n",
      "868/868 - 1s - loss: 0.0694 - accuracy: 0.9724 - val_loss: 0.4313 - val_accuracy: 0.9103 - 1s/epoch - 2ms/step\n",
      "Epoch 35/150\n",
      "868/868 - 1s - loss: 0.0657 - accuracy: 0.9729 - val_loss: 0.4536 - val_accuracy: 0.9119 - 1s/epoch - 1ms/step\n",
      "Epoch 36/150\n",
      "868/868 - 1s - loss: 0.0646 - accuracy: 0.9736 - val_loss: 0.5111 - val_accuracy: 0.9092 - 1s/epoch - 1ms/step\n",
      "Epoch 37/150\n",
      "868/868 - 1s - loss: 0.0630 - accuracy: 0.9753 - val_loss: 0.4926 - val_accuracy: 0.9057 - 1s/epoch - 2ms/step\n",
      "Epoch 38/150\n",
      "868/868 - 1s - loss: 0.0609 - accuracy: 0.9771 - val_loss: 0.5637 - val_accuracy: 0.9149 - 1s/epoch - 2ms/step\n",
      "Epoch 39/150\n",
      "868/868 - 1s - loss: 0.0577 - accuracy: 0.9765 - val_loss: 0.5562 - val_accuracy: 0.9108 - 1s/epoch - 2ms/step\n",
      "Epoch 40/150\n",
      "868/868 - 1s - loss: 0.0580 - accuracy: 0.9776 - val_loss: 0.5806 - val_accuracy: 0.9133 - 1s/epoch - 1ms/step\n",
      "Epoch 41/150\n",
      "868/868 - 1s - loss: 0.0539 - accuracy: 0.9783 - val_loss: 0.6564 - val_accuracy: 0.9208 - 1s/epoch - 2ms/step\n",
      "Epoch 42/150\n",
      "868/868 - 1s - loss: 0.0544 - accuracy: 0.9793 - val_loss: 0.5898 - val_accuracy: 0.9120 - 1s/epoch - 1ms/step\n",
      "Epoch 43/150\n",
      "868/868 - 1s - loss: 0.0527 - accuracy: 0.9801 - val_loss: 0.6973 - val_accuracy: 0.9117 - 1s/epoch - 1ms/step\n",
      "Epoch 44/150\n",
      "868/868 - 1s - loss: 0.0501 - accuracy: 0.9812 - val_loss: 0.6853 - val_accuracy: 0.9097 - 1s/epoch - 1ms/step\n",
      "Epoch 45/150\n",
      "868/868 - 1s - loss: 0.0484 - accuracy: 0.9813 - val_loss: 0.7027 - val_accuracy: 0.9094 - 1s/epoch - 1ms/step\n",
      "Epoch 46/150\n",
      "868/868 - 2s - loss: 0.0488 - accuracy: 0.9812 - val_loss: 0.6913 - val_accuracy: 0.9125 - 2s/epoch - 2ms/step\n",
      "Epoch 47/150\n",
      "868/868 - 1s - loss: 0.0446 - accuracy: 0.9818 - val_loss: 0.7114 - val_accuracy: 0.8977 - 1s/epoch - 2ms/step\n",
      "Epoch 48/150\n",
      "868/868 - 1s - loss: 0.0422 - accuracy: 0.9836 - val_loss: 0.7605 - val_accuracy: 0.9037 - 1s/epoch - 1ms/step\n",
      "Epoch 49/150\n",
      "868/868 - 1s - loss: 0.0411 - accuracy: 0.9840 - val_loss: 0.8218 - val_accuracy: 0.9146 - 1s/epoch - 1ms/step\n",
      "Epoch 50/150\n",
      "868/868 - 1s - loss: 0.0438 - accuracy: 0.9818 - val_loss: 0.8207 - val_accuracy: 0.9160 - 1s/epoch - 1ms/step\n",
      "Epoch 51/150\n",
      "868/868 - 1s - loss: 0.0417 - accuracy: 0.9837 - val_loss: 0.8099 - val_accuracy: 0.9108 - 1s/epoch - 1ms/step\n",
      "Epoch 52/150\n",
      "868/868 - 1s - loss: 0.0400 - accuracy: 0.9841 - val_loss: 0.8618 - val_accuracy: 0.9078 - 1s/epoch - 1ms/step\n",
      "Epoch 53/150\n",
      "868/868 - 1s - loss: 0.0403 - accuracy: 0.9841 - val_loss: 0.8439 - val_accuracy: 0.9136 - 1s/epoch - 1ms/step\n",
      "Epoch 54/150\n",
      "868/868 - 1s - loss: 0.0374 - accuracy: 0.9853 - val_loss: 0.8402 - val_accuracy: 0.9095 - 1s/epoch - 1ms/step\n",
      "Epoch 55/150\n",
      "868/868 - 1s - loss: 0.0388 - accuracy: 0.9844 - val_loss: 0.7894 - val_accuracy: 0.9104 - 1s/epoch - 1ms/step\n",
      "Epoch 56/150\n",
      "868/868 - 1s - loss: 0.0497 - accuracy: 0.9812 - val_loss: 0.9213 - val_accuracy: 0.9172 - 1s/epoch - 1ms/step\n",
      "Epoch 57/150\n",
      "868/868 - 1s - loss: 0.0342 - accuracy: 0.9868 - val_loss: 0.9554 - val_accuracy: 0.9098 - 1s/epoch - 1ms/step\n",
      "Epoch 58/150\n",
      "868/868 - 1s - loss: 0.0335 - accuracy: 0.9869 - val_loss: 0.9915 - val_accuracy: 0.9117 - 1s/epoch - 1ms/step\n",
      "Epoch 59/150\n",
      "868/868 - 1s - loss: 0.0326 - accuracy: 0.9872 - val_loss: 0.9986 - val_accuracy: 0.9157 - 1s/epoch - 1ms/step\n",
      "Epoch 60/150\n",
      "868/868 - 1s - loss: 0.0407 - accuracy: 0.9835 - val_loss: 0.9319 - val_accuracy: 0.9084 - 1s/epoch - 1ms/step\n",
      "Epoch 61/150\n",
      "868/868 - 1s - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.9384 - val_accuracy: 0.9083 - 1s/epoch - 1ms/step\n",
      "Epoch 62/150\n",
      "868/868 - 1s - loss: 0.0319 - accuracy: 0.9880 - val_loss: 1.0634 - val_accuracy: 0.9131 - 1s/epoch - 1ms/step\n",
      "Epoch 63/150\n",
      "868/868 - 1s - loss: 0.0327 - accuracy: 0.9872 - val_loss: 1.0027 - val_accuracy: 0.8882 - 1s/epoch - 1ms/step\n",
      "Epoch 64/150\n",
      "868/868 - 1s - loss: 0.0336 - accuracy: 0.9865 - val_loss: 1.0725 - val_accuracy: 0.9140 - 1s/epoch - 1ms/step\n",
      "Epoch 65/150\n",
      "868/868 - 1s - loss: 0.0319 - accuracy: 0.9878 - val_loss: 1.0441 - val_accuracy: 0.9109 - 1s/epoch - 1ms/step\n",
      "Epoch 66/150\n",
      "868/868 - 1s - loss: 0.0274 - accuracy: 0.9894 - val_loss: 1.0517 - val_accuracy: 0.9088 - 1s/epoch - 1ms/step\n",
      "Epoch 67/150\n",
      "868/868 - 1s - loss: 0.0318 - accuracy: 0.9879 - val_loss: 1.0634 - val_accuracy: 0.9136 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150\n",
      "868/868 - 1s - loss: 0.0330 - accuracy: 0.9875 - val_loss: 1.0536 - val_accuracy: 0.9132 - 1s/epoch - 1ms/step\n",
      "Epoch 69/150\n",
      "868/868 - 1s - loss: 0.0293 - accuracy: 0.9886 - val_loss: 1.0681 - val_accuracy: 0.9135 - 1s/epoch - 1ms/step\n",
      "Epoch 70/150\n",
      "868/868 - 1s - loss: 0.0291 - accuracy: 0.9890 - val_loss: 1.0094 - val_accuracy: 0.8962 - 1s/epoch - 1ms/step\n",
      "Epoch 71/150\n",
      "868/868 - 1s - loss: 0.0316 - accuracy: 0.9877 - val_loss: 1.1180 - val_accuracy: 0.9120 - 1s/epoch - 1ms/step\n",
      "Epoch 72/150\n",
      "868/868 - 1s - loss: 0.0285 - accuracy: 0.9880 - val_loss: 1.1296 - val_accuracy: 0.9141 - 1s/epoch - 1ms/step\n",
      "Epoch 73/150\n",
      "868/868 - 1s - loss: 0.0265 - accuracy: 0.9894 - val_loss: 1.1482 - val_accuracy: 0.9123 - 1s/epoch - 1ms/step\n",
      "Epoch 74/150\n",
      "868/868 - 1s - loss: 0.0288 - accuracy: 0.9885 - val_loss: 1.1658 - val_accuracy: 0.9131 - 1s/epoch - 1ms/step\n",
      "Epoch 75/150\n",
      "868/868 - 1s - loss: 0.0264 - accuracy: 0.9894 - val_loss: 1.1674 - val_accuracy: 0.9121 - 1s/epoch - 1ms/step\n",
      "Epoch 76/150\n",
      "868/868 - 1s - loss: 0.0273 - accuracy: 0.9887 - val_loss: 1.2319 - val_accuracy: 0.9119 - 1s/epoch - 1ms/step\n",
      "Epoch 77/150\n",
      "868/868 - 1s - loss: 0.0289 - accuracy: 0.9879 - val_loss: 1.1960 - val_accuracy: 0.9115 - 1s/epoch - 1ms/step\n",
      "Epoch 78/150\n",
      "868/868 - 1s - loss: 0.0269 - accuracy: 0.9892 - val_loss: 1.2369 - val_accuracy: 0.9105 - 1s/epoch - 1ms/step\n",
      "Epoch 79/150\n",
      "868/868 - 1s - loss: 0.0260 - accuracy: 0.9895 - val_loss: 1.1819 - val_accuracy: 0.9080 - 1s/epoch - 1ms/step\n",
      "Epoch 80/150\n",
      "868/868 - 1s - loss: 0.0291 - accuracy: 0.9890 - val_loss: 1.1813 - val_accuracy: 0.9107 - 1s/epoch - 1ms/step\n",
      "Epoch 81/150\n",
      "868/868 - 1s - loss: 0.0266 - accuracy: 0.9898 - val_loss: 1.2053 - val_accuracy: 0.9137 - 1s/epoch - 1ms/step\n",
      "Epoch 82/150\n",
      "868/868 - 1s - loss: 0.0263 - accuracy: 0.9898 - val_loss: 1.1008 - val_accuracy: 0.9093 - 1s/epoch - 1ms/step\n",
      "Epoch 83/150\n",
      "868/868 - 1s - loss: 0.0236 - accuracy: 0.9909 - val_loss: 1.2306 - val_accuracy: 0.9057 - 1s/epoch - 1ms/step\n",
      "Epoch 84/150\n",
      "868/868 - 1s - loss: 0.0244 - accuracy: 0.9905 - val_loss: 1.1648 - val_accuracy: 0.9073 - 1s/epoch - 1ms/step\n",
      "Epoch 85/150\n",
      "868/868 - 1s - loss: 0.0227 - accuracy: 0.9910 - val_loss: 1.3689 - val_accuracy: 0.9139 - 1s/epoch - 1ms/step\n",
      "Epoch 86/150\n",
      "868/868 - 1s - loss: 0.0312 - accuracy: 0.9884 - val_loss: 1.1547 - val_accuracy: 0.9088 - 1s/epoch - 1ms/step\n",
      "Epoch 87/150\n",
      "868/868 - 1s - loss: 0.0246 - accuracy: 0.9901 - val_loss: 1.2055 - val_accuracy: 0.9089 - 1s/epoch - 1ms/step\n",
      "Epoch 88/150\n",
      "868/868 - 1s - loss: 0.0276 - accuracy: 0.9896 - val_loss: 1.1141 - val_accuracy: 0.9121 - 1s/epoch - 1ms/step\n",
      "Epoch 89/150\n",
      "868/868 - 1s - loss: 0.0228 - accuracy: 0.9909 - val_loss: 1.2777 - val_accuracy: 0.9153 - 1s/epoch - 1ms/step\n",
      "Epoch 90/150\n",
      "868/868 - 1s - loss: 0.0254 - accuracy: 0.9895 - val_loss: 1.1698 - val_accuracy: 0.9081 - 1s/epoch - 1ms/step\n",
      "Epoch 91/150\n",
      "868/868 - 1s - loss: 0.0246 - accuracy: 0.9902 - val_loss: 1.1791 - val_accuracy: 0.9102 - 1s/epoch - 1ms/step\n",
      "Epoch 92/150\n",
      "868/868 - 1s - loss: 0.0207 - accuracy: 0.9916 - val_loss: 1.3296 - val_accuracy: 0.9144 - 1s/epoch - 1ms/step\n",
      "Epoch 93/150\n",
      "868/868 - 1s - loss: 0.0251 - accuracy: 0.9902 - val_loss: 1.2301 - val_accuracy: 0.9059 - 1s/epoch - 1ms/step\n",
      "Epoch 94/150\n",
      "868/868 - 1s - loss: 0.0202 - accuracy: 0.9924 - val_loss: 1.3132 - val_accuracy: 0.9141 - 1s/epoch - 1ms/step\n",
      "Epoch 95/150\n",
      "868/868 - 1s - loss: 0.0255 - accuracy: 0.9905 - val_loss: 1.2820 - val_accuracy: 0.9099 - 1s/epoch - 1ms/step\n",
      "Epoch 96/150\n",
      "868/868 - 1s - loss: 0.0200 - accuracy: 0.9923 - val_loss: 1.2787 - val_accuracy: 0.9101 - 1s/epoch - 2ms/step\n",
      "Epoch 97/150\n",
      "868/868 - 1s - loss: 0.0260 - accuracy: 0.9901 - val_loss: 1.2749 - val_accuracy: 0.9103 - 1s/epoch - 2ms/step\n",
      "Epoch 98/150\n",
      "868/868 - 1s - loss: 0.0230 - accuracy: 0.9906 - val_loss: 1.2622 - val_accuracy: 0.9109 - 1s/epoch - 1ms/step\n",
      "Epoch 99/150\n",
      "868/868 - 1s - loss: 0.0194 - accuracy: 0.9923 - val_loss: 1.2910 - val_accuracy: 0.9094 - 1s/epoch - 1ms/step\n",
      "Epoch 100/150\n",
      "868/868 - 1s - loss: 0.0188 - accuracy: 0.9925 - val_loss: 1.3465 - val_accuracy: 0.9101 - 1s/epoch - 1ms/step\n",
      "Epoch 101/150\n",
      "868/868 - 1s - loss: 0.0252 - accuracy: 0.9904 - val_loss: 1.2563 - val_accuracy: 0.9111 - 1s/epoch - 1ms/step\n",
      "Epoch 102/150\n",
      "868/868 - 1s - loss: 0.0221 - accuracy: 0.9915 - val_loss: 1.3315 - val_accuracy: 0.9106 - 1s/epoch - 1ms/step\n",
      "Epoch 103/150\n",
      "868/868 - 1s - loss: 0.0199 - accuracy: 0.9921 - val_loss: 1.3354 - val_accuracy: 0.9136 - 1s/epoch - 1ms/step\n",
      "Epoch 104/150\n",
      "868/868 - 1s - loss: 0.0221 - accuracy: 0.9918 - val_loss: 1.3101 - val_accuracy: 0.9102 - 1s/epoch - 1ms/step\n",
      "Epoch 105/150\n",
      "868/868 - 1s - loss: 0.0208 - accuracy: 0.9916 - val_loss: 1.3759 - val_accuracy: 0.9073 - 1s/epoch - 1ms/step\n",
      "Epoch 106/150\n",
      "868/868 - 1s - loss: 0.0175 - accuracy: 0.9932 - val_loss: 1.4300 - val_accuracy: 0.9115 - 1s/epoch - 1ms/step\n",
      "Epoch 107/150\n",
      "868/868 - 1s - loss: 0.0237 - accuracy: 0.9909 - val_loss: 1.3793 - val_accuracy: 0.9024 - 1s/epoch - 1ms/step\n",
      "Epoch 108/150\n",
      "868/868 - 1s - loss: 0.0211 - accuracy: 0.9923 - val_loss: 1.4408 - val_accuracy: 0.9025 - 1s/epoch - 1ms/step\n",
      "Epoch 109/150\n",
      "868/868 - 1s - loss: 0.0187 - accuracy: 0.9931 - val_loss: 1.3795 - val_accuracy: 0.9106 - 1s/epoch - 1ms/step\n",
      "Epoch 110/150\n",
      "868/868 - 1s - loss: 0.0186 - accuracy: 0.9922 - val_loss: 1.3642 - val_accuracy: 0.9111 - 1s/epoch - 1ms/step\n",
      "Epoch 111/150\n",
      "868/868 - 1s - loss: 0.0241 - accuracy: 0.9911 - val_loss: 1.3485 - val_accuracy: 0.9102 - 1s/epoch - 1ms/step\n",
      "Epoch 112/150\n",
      "868/868 - 1s - loss: 0.0173 - accuracy: 0.9935 - val_loss: 1.3673 - val_accuracy: 0.9132 - 1s/epoch - 1ms/step\n",
      "Epoch 113/150\n",
      "868/868 - 1s - loss: 0.0192 - accuracy: 0.9922 - val_loss: 1.4471 - val_accuracy: 0.9138 - 1s/epoch - 1ms/step\n",
      "Epoch 114/150\n",
      "868/868 - 1s - loss: 0.0227 - accuracy: 0.9915 - val_loss: 1.3464 - val_accuracy: 0.9074 - 1s/epoch - 1ms/step\n",
      "Epoch 115/150\n",
      "868/868 - 1s - loss: 0.0174 - accuracy: 0.9932 - val_loss: 1.4652 - val_accuracy: 0.9099 - 1s/epoch - 1ms/step\n",
      "Epoch 116/150\n",
      "868/868 - 1s - loss: 0.0203 - accuracy: 0.9922 - val_loss: 1.3530 - val_accuracy: 0.9116 - 1s/epoch - 1ms/step\n",
      "Epoch 117/150\n",
      "868/868 - 1s - loss: 0.0210 - accuracy: 0.9919 - val_loss: 1.3057 - val_accuracy: 0.9146 - 1s/epoch - 1ms/step\n",
      "Epoch 118/150\n",
      "868/868 - 1s - loss: 0.0203 - accuracy: 0.9922 - val_loss: 1.3436 - val_accuracy: 0.9058 - 1s/epoch - 1ms/step\n",
      "Epoch 119/150\n",
      "868/868 - 1s - loss: 0.0155 - accuracy: 0.9937 - val_loss: 1.4277 - val_accuracy: 0.9067 - 1s/epoch - 2ms/step\n",
      "Epoch 120/150\n",
      "868/868 - 1s - loss: 0.0166 - accuracy: 0.9934 - val_loss: 1.5445 - val_accuracy: 0.9140 - 1s/epoch - 1ms/step\n",
      "Epoch 121/150\n",
      "868/868 - 1s - loss: 0.0171 - accuracy: 0.9934 - val_loss: 1.4612 - val_accuracy: 0.9118 - 1s/epoch - 1ms/step\n",
      "Epoch 122/150\n",
      "868/868 - 1s - loss: 0.0175 - accuracy: 0.9937 - val_loss: 1.5593 - val_accuracy: 0.9101 - 1s/epoch - 1ms/step\n",
      "Epoch 123/150\n",
      "868/868 - 1s - loss: 0.0198 - accuracy: 0.9925 - val_loss: 1.4767 - val_accuracy: 0.9131 - 1s/epoch - 1ms/step\n",
      "Epoch 124/150\n",
      "868/868 - 1s - loss: 0.0215 - accuracy: 0.9918 - val_loss: 1.4870 - val_accuracy: 0.9152 - 1s/epoch - 1ms/step\n",
      "Epoch 125/150\n",
      "868/868 - 1s - loss: 0.0204 - accuracy: 0.9923 - val_loss: 1.4178 - val_accuracy: 0.9079 - 1s/epoch - 1ms/step\n",
      "Epoch 126/150\n",
      "868/868 - 1s - loss: 0.0170 - accuracy: 0.9933 - val_loss: 1.4843 - val_accuracy: 0.9109 - 1s/epoch - 1ms/step\n",
      "Epoch 127/150\n",
      "868/868 - 1s - loss: 0.0200 - accuracy: 0.9924 - val_loss: 1.4086 - val_accuracy: 0.9093 - 1s/epoch - 1ms/step\n",
      "Epoch 128/150\n",
      "868/868 - 1s - loss: 0.0182 - accuracy: 0.9931 - val_loss: 1.4899 - val_accuracy: 0.9153 - 1s/epoch - 1ms/step\n",
      "Epoch 129/150\n",
      "868/868 - 1s - loss: 0.0164 - accuracy: 0.9937 - val_loss: 1.4955 - val_accuracy: 0.9121 - 1s/epoch - 1ms/step\n",
      "Epoch 130/150\n",
      "868/868 - 1s - loss: 0.0229 - accuracy: 0.9917 - val_loss: 1.4566 - val_accuracy: 0.9135 - 1s/epoch - 1ms/step\n",
      "Epoch 131/150\n",
      "868/868 - 1s - loss: 0.0167 - accuracy: 0.9931 - val_loss: 1.4787 - val_accuracy: 0.9146 - 1s/epoch - 1ms/step\n",
      "Epoch 132/150\n",
      "868/868 - 1s - loss: 0.0160 - accuracy: 0.9936 - val_loss: 1.5324 - val_accuracy: 0.9067 - 1s/epoch - 1ms/step\n",
      "Epoch 133/150\n",
      "868/868 - 1s - loss: 0.0177 - accuracy: 0.9932 - val_loss: 1.4955 - val_accuracy: 0.9094 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150\n",
      "868/868 - 1s - loss: 0.0159 - accuracy: 0.9939 - val_loss: 1.4465 - val_accuracy: 0.9097 - 1s/epoch - 1ms/step\n",
      "Epoch 135/150\n",
      "868/868 - 1s - loss: 0.0150 - accuracy: 0.9939 - val_loss: 1.5984 - val_accuracy: 0.9160 - 1s/epoch - 1ms/step\n",
      "Epoch 136/150\n",
      "868/868 - 1s - loss: 0.0182 - accuracy: 0.9929 - val_loss: 1.5161 - val_accuracy: 0.9084 - 1s/epoch - 1ms/step\n",
      "Epoch 137/150\n",
      "868/868 - 1s - loss: 0.0196 - accuracy: 0.9928 - val_loss: 1.5064 - val_accuracy: 0.9101 - 1s/epoch - 1ms/step\n",
      "Epoch 138/150\n",
      "868/868 - 1s - loss: 0.0145 - accuracy: 0.9940 - val_loss: 1.5491 - val_accuracy: 0.9115 - 1s/epoch - 1ms/step\n",
      "Epoch 139/150\n",
      "868/868 - 1s - loss: 0.0152 - accuracy: 0.9938 - val_loss: 1.5362 - val_accuracy: 0.9133 - 1s/epoch - 1ms/step\n",
      "Epoch 140/150\n",
      "868/868 - 1s - loss: 0.0188 - accuracy: 0.9924 - val_loss: 1.4498 - val_accuracy: 0.9087 - 1s/epoch - 1ms/step\n",
      "Epoch 141/150\n",
      "868/868 - 1s - loss: 0.0168 - accuracy: 0.9935 - val_loss: 1.4885 - val_accuracy: 0.9063 - 1s/epoch - 1ms/step\n",
      "Epoch 142/150\n",
      "868/868 - 1s - loss: 0.0183 - accuracy: 0.9930 - val_loss: 1.4663 - val_accuracy: 0.9120 - 1s/epoch - 1ms/step\n",
      "Epoch 143/150\n",
      "868/868 - 1s - loss: 0.0171 - accuracy: 0.9928 - val_loss: 1.5513 - val_accuracy: 0.9098 - 1s/epoch - 1ms/step\n",
      "Epoch 144/150\n",
      "868/868 - 1s - loss: 0.0127 - accuracy: 0.9950 - val_loss: 1.5625 - val_accuracy: 0.9103 - 1s/epoch - 1ms/step\n",
      "Epoch 145/150\n",
      "868/868 - 1s - loss: 0.0221 - accuracy: 0.9922 - val_loss: 1.4950 - val_accuracy: 0.9141 - 1s/epoch - 1ms/step\n",
      "Epoch 146/150\n",
      "868/868 - 1s - loss: 0.0131 - accuracy: 0.9946 - val_loss: 1.5800 - val_accuracy: 0.9075 - 1s/epoch - 1ms/step\n",
      "Epoch 147/150\n",
      "868/868 - 1s - loss: 0.0169 - accuracy: 0.9938 - val_loss: 1.5141 - val_accuracy: 0.9138 - 1s/epoch - 1ms/step\n",
      "Epoch 148/150\n",
      "868/868 - 1s - loss: 0.0150 - accuracy: 0.9939 - val_loss: 1.4878 - val_accuracy: 0.9120 - 1s/epoch - 1ms/step\n",
      "Epoch 149/150\n",
      "868/868 - 1s - loss: 0.0188 - accuracy: 0.9928 - val_loss: 1.4581 - val_accuracy: 0.9083 - 1s/epoch - 1ms/step\n",
      "Epoch 150/150\n",
      "868/868 - 1s - loss: 0.0162 - accuracy: 0.9939 - val_loss: 1.5465 - val_accuracy: 0.9075 - 1s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_padded, y_train,\n",
    "                    validation_data = (valid_padded, y_test),\n",
    "                    epochs = 150,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c25ced",
   "metadata": {},
   "source": [
    "Ta s·∫Ω d√πng M·∫°ng t√≠ch ch·∫≠p 1 chi·ªÅu v·ªõi `MaxPooling1D` v·ªõi hy v·ªçng s·∫Ω c·∫£i thi·ªán accuracy ·ªü t·∫≠p test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44b37c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "868/868 - 8s - loss: 0.2428 - accuracy: 0.9022 - val_loss: 0.2043 - val_accuracy: 0.9225 - 8s/epoch - 9ms/step\n",
      "Epoch 2/150\n",
      "868/868 - 8s - loss: 0.1711 - accuracy: 0.9357 - val_loss: 0.1861 - val_accuracy: 0.9286 - 8s/epoch - 9ms/step\n",
      "Epoch 3/150\n",
      "868/868 - 7s - loss: 0.1467 - accuracy: 0.9448 - val_loss: 0.1987 - val_accuracy: 0.9273 - 7s/epoch - 8ms/step\n",
      "Epoch 4/150\n",
      "868/868 - 7s - loss: 0.1213 - accuracy: 0.9544 - val_loss: 0.1922 - val_accuracy: 0.9279 - 7s/epoch - 8ms/step\n",
      "Epoch 5/150\n",
      "868/868 - 7s - loss: 0.0941 - accuracy: 0.9649 - val_loss: 0.2287 - val_accuracy: 0.9268 - 7s/epoch - 8ms/step\n",
      "Epoch 6/150\n",
      "868/868 - 7s - loss: 0.0722 - accuracy: 0.9713 - val_loss: 0.2804 - val_accuracy: 0.9222 - 7s/epoch - 8ms/step\n",
      "Epoch 7/150\n",
      "868/868 - 7s - loss: 0.0564 - accuracy: 0.9777 - val_loss: 0.3151 - val_accuracy: 0.9193 - 7s/epoch - 8ms/step\n",
      "Epoch 8/150\n",
      "868/868 - 7s - loss: 0.0464 - accuracy: 0.9823 - val_loss: 0.3648 - val_accuracy: 0.9206 - 7s/epoch - 8ms/step\n",
      "Epoch 9/150\n",
      "868/868 - 7s - loss: 0.0420 - accuracy: 0.9848 - val_loss: 0.3682 - val_accuracy: 0.9247 - 7s/epoch - 8ms/step\n",
      "Epoch 10/150\n",
      "868/868 - 7s - loss: 0.0371 - accuracy: 0.9862 - val_loss: 0.3764 - val_accuracy: 0.9240 - 7s/epoch - 8ms/step\n",
      "Epoch 11/150\n",
      "868/868 - 7s - loss: 0.0321 - accuracy: 0.9877 - val_loss: 0.4587 - val_accuracy: 0.9139 - 7s/epoch - 8ms/step\n",
      "Epoch 12/150\n",
      "868/868 - 7s - loss: 0.0316 - accuracy: 0.9886 - val_loss: 0.4416 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 13/150\n",
      "868/868 - 7s - loss: 0.0276 - accuracy: 0.9898 - val_loss: 0.4906 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 14/150\n",
      "868/868 - 7s - loss: 0.0263 - accuracy: 0.9898 - val_loss: 0.4917 - val_accuracy: 0.9192 - 7s/epoch - 8ms/step\n",
      "Epoch 15/150\n",
      "868/868 - 7s - loss: 0.0246 - accuracy: 0.9906 - val_loss: 0.5232 - val_accuracy: 0.9231 - 7s/epoch - 8ms/step\n",
      "Epoch 16/150\n",
      "868/868 - 7s - loss: 0.0250 - accuracy: 0.9900 - val_loss: 0.5021 - val_accuracy: 0.9207 - 7s/epoch - 8ms/step\n",
      "Epoch 17/150\n",
      "868/868 - 7s - loss: 0.0244 - accuracy: 0.9908 - val_loss: 0.5003 - val_accuracy: 0.9204 - 7s/epoch - 8ms/step\n",
      "Epoch 18/150\n",
      "868/868 - 7s - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.5102 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 19/150\n",
      "868/868 - 7s - loss: 0.0243 - accuracy: 0.9904 - val_loss: 0.5547 - val_accuracy: 0.9246 - 7s/epoch - 8ms/step\n",
      "Epoch 20/150\n",
      "868/868 - 7s - loss: 0.0200 - accuracy: 0.9926 - val_loss: 0.5760 - val_accuracy: 0.9215 - 7s/epoch - 8ms/step\n",
      "Epoch 21/150\n",
      "868/868 - 7s - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.5659 - val_accuracy: 0.9208 - 7s/epoch - 8ms/step\n",
      "Epoch 22/150\n",
      "868/868 - 7s - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.5713 - val_accuracy: 0.9170 - 7s/epoch - 8ms/step\n",
      "Epoch 23/150\n",
      "868/868 - 7s - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.5861 - val_accuracy: 0.9172 - 7s/epoch - 8ms/step\n",
      "Epoch 24/150\n",
      "868/868 - 7s - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.6207 - val_accuracy: 0.9220 - 7s/epoch - 8ms/step\n",
      "Epoch 25/150\n",
      "868/868 - 7s - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.6026 - val_accuracy: 0.9173 - 7s/epoch - 8ms/step\n",
      "Epoch 26/150\n",
      "868/868 - 7s - loss: 0.0163 - accuracy: 0.9934 - val_loss: 0.6154 - val_accuracy: 0.9183 - 7s/epoch - 8ms/step\n",
      "Epoch 27/150\n",
      "868/868 - 7s - loss: 0.0163 - accuracy: 0.9935 - val_loss: 0.6179 - val_accuracy: 0.9201 - 7s/epoch - 8ms/step\n",
      "Epoch 28/150\n",
      "868/868 - 7s - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.5875 - val_accuracy: 0.9173 - 7s/epoch - 8ms/step\n",
      "Epoch 29/150\n",
      "868/868 - 7s - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.6402 - val_accuracy: 0.9162 - 7s/epoch - 8ms/step\n",
      "Epoch 30/150\n",
      "868/868 - 7s - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.6138 - val_accuracy: 0.9162 - 7s/epoch - 8ms/step\n",
      "Epoch 31/150\n",
      "868/868 - 7s - loss: 0.0160 - accuracy: 0.9941 - val_loss: 0.5898 - val_accuracy: 0.9191 - 7s/epoch - 8ms/step\n",
      "Epoch 32/150\n",
      "868/868 - 7s - loss: 0.0150 - accuracy: 0.9941 - val_loss: 0.6076 - val_accuracy: 0.9216 - 7s/epoch - 8ms/step\n",
      "Epoch 33/150\n",
      "868/868 - 7s - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.6565 - val_accuracy: 0.9197 - 7s/epoch - 8ms/step\n",
      "Epoch 34/150\n",
      "868/868 - 7s - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.7670 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 35/150\n",
      "868/868 - 7s - loss: 0.0170 - accuracy: 0.9932 - val_loss: 0.5719 - val_accuracy: 0.9180 - 7s/epoch - 8ms/step\n",
      "Epoch 36/150\n",
      "868/868 - 7s - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.6780 - val_accuracy: 0.9200 - 7s/epoch - 8ms/step\n",
      "Epoch 37/150\n",
      "868/868 - 7s - loss: 0.0108 - accuracy: 0.9956 - val_loss: 0.7864 - val_accuracy: 0.9211 - 7s/epoch - 8ms/step\n",
      "Epoch 38/150\n",
      "868/868 - 7s - loss: 0.0138 - accuracy: 0.9949 - val_loss: 0.6651 - val_accuracy: 0.9215 - 7s/epoch - 8ms/step\n",
      "Epoch 39/150\n",
      "868/868 - 7s - loss: 0.0145 - accuracy: 0.9941 - val_loss: 0.6198 - val_accuracy: 0.9194 - 7s/epoch - 8ms/step\n",
      "Epoch 40/150\n",
      "868/868 - 7s - loss: 0.0123 - accuracy: 0.9951 - val_loss: 0.6401 - val_accuracy: 0.9195 - 7s/epoch - 8ms/step\n",
      "Epoch 41/150\n",
      "868/868 - 7s - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.6959 - val_accuracy: 0.9179 - 7s/epoch - 8ms/step\n",
      "Epoch 42/150\n",
      "868/868 - 7s - loss: 0.0118 - accuracy: 0.9952 - val_loss: 0.7671 - val_accuracy: 0.9190 - 7s/epoch - 8ms/step\n",
      "Epoch 43/150\n",
      "868/868 - 7s - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.7006 - val_accuracy: 0.9201 - 7s/epoch - 8ms/step\n",
      "Epoch 44/150\n",
      "868/868 - 7s - loss: 0.0134 - accuracy: 0.9948 - val_loss: 0.7009 - val_accuracy: 0.9198 - 7s/epoch - 8ms/step\n",
      "Epoch 45/150\n",
      "868/868 - 7s - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.7161 - val_accuracy: 0.9192 - 7s/epoch - 8ms/step\n",
      "Epoch 46/150\n",
      "868/868 - 7s - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.7323 - val_accuracy: 0.9190 - 7s/epoch - 8ms/step\n",
      "Epoch 47/150\n",
      "868/868 - 7s - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.7845 - val_accuracy: 0.9210 - 7s/epoch - 8ms/step\n",
      "Epoch 48/150\n",
      "868/868 - 7s - loss: 0.0100 - accuracy: 0.9960 - val_loss: 0.8017 - val_accuracy: 0.9187 - 7s/epoch - 8ms/step\n",
      "Epoch 49/150\n",
      "868/868 - 7s - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.7339 - val_accuracy: 0.9228 - 7s/epoch - 8ms/step\n",
      "Epoch 50/150\n",
      "868/868 - 7s - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.8104 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 51/150\n",
      "868/868 - 7s - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.7272 - val_accuracy: 0.9210 - 7s/epoch - 8ms/step\n",
      "Epoch 52/150\n",
      "868/868 - 7s - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.7174 - val_accuracy: 0.9211 - 7s/epoch - 8ms/step\n",
      "Epoch 53/150\n",
      "868/868 - 7s - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.7281 - val_accuracy: 0.9236 - 7s/epoch - 8ms/step\n",
      "Epoch 54/150\n",
      "868/868 - 7s - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.7668 - val_accuracy: 0.9230 - 7s/epoch - 8ms/step\n",
      "Epoch 55/150\n",
      "868/868 - 7s - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.7261 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 56/150\n",
      "868/868 - 7s - loss: 0.0108 - accuracy: 0.9956 - val_loss: 0.7943 - val_accuracy: 0.9200 - 7s/epoch - 8ms/step\n",
      "Epoch 57/150\n",
      "868/868 - 7s - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.8473 - val_accuracy: 0.9196 - 7s/epoch - 8ms/step\n",
      "Epoch 58/150\n",
      "868/868 - 7s - loss: 0.0106 - accuracy: 0.9960 - val_loss: 0.8319 - val_accuracy: 0.9200 - 7s/epoch - 8ms/step\n",
      "Epoch 59/150\n",
      "868/868 - 7s - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.9900 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 60/150\n",
      "868/868 - 7s - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.7245 - val_accuracy: 0.9196 - 7s/epoch - 8ms/step\n",
      "Epoch 61/150\n",
      "868/868 - 7s - loss: 0.0103 - accuracy: 0.9960 - val_loss: 0.8340 - val_accuracy: 0.9204 - 7s/epoch - 8ms/step\n",
      "Epoch 62/150\n",
      "868/868 - 7s - loss: 0.0095 - accuracy: 0.9959 - val_loss: 0.9065 - val_accuracy: 0.9218 - 7s/epoch - 8ms/step\n",
      "Epoch 63/150\n",
      "868/868 - 7s - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.7537 - val_accuracy: 0.9199 - 7s/epoch - 8ms/step\n",
      "Epoch 64/150\n",
      "868/868 - 7s - loss: 0.0094 - accuracy: 0.9961 - val_loss: 0.8554 - val_accuracy: 0.9196 - 7s/epoch - 8ms/step\n",
      "Epoch 65/150\n",
      "868/868 - 7s - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.9068 - val_accuracy: 0.9194 - 7s/epoch - 8ms/step\n",
      "Epoch 66/150\n",
      "868/868 - 7s - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.8241 - val_accuracy: 0.9197 - 7s/epoch - 8ms/step\n",
      "Epoch 67/150\n",
      "868/868 - 7s - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.7317 - val_accuracy: 0.9183 - 7s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150\n",
      "868/868 - 7s - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.7429 - val_accuracy: 0.9192 - 7s/epoch - 8ms/step\n",
      "Epoch 69/150\n",
      "868/868 - 7s - loss: 0.0085 - accuracy: 0.9966 - val_loss: 0.7557 - val_accuracy: 0.9188 - 7s/epoch - 8ms/step\n",
      "Epoch 70/150\n",
      "868/868 - 7s - loss: 0.0088 - accuracy: 0.9961 - val_loss: 0.8276 - val_accuracy: 0.9215 - 7s/epoch - 8ms/step\n",
      "Epoch 71/150\n",
      "868/868 - 7s - loss: 0.0084 - accuracy: 0.9965 - val_loss: 0.9054 - val_accuracy: 0.9209 - 7s/epoch - 8ms/step\n",
      "Epoch 72/150\n",
      "868/868 - 7s - loss: 0.0102 - accuracy: 0.9961 - val_loss: 0.8688 - val_accuracy: 0.9200 - 7s/epoch - 8ms/step\n",
      "Epoch 73/150\n",
      "868/868 - 7s - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.7855 - val_accuracy: 0.9165 - 7s/epoch - 8ms/step\n",
      "Epoch 74/150\n",
      "868/868 - 7s - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.9057 - val_accuracy: 0.9180 - 7s/epoch - 8ms/step\n",
      "Epoch 75/150\n",
      "868/868 - 7s - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.9637 - val_accuracy: 0.9182 - 7s/epoch - 8ms/step\n",
      "Epoch 76/150\n",
      "868/868 - 7s - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.8366 - val_accuracy: 0.9190 - 7s/epoch - 8ms/step\n",
      "Epoch 77/150\n",
      "868/868 - 7s - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.8404 - val_accuracy: 0.9189 - 7s/epoch - 8ms/step\n",
      "Epoch 78/150\n",
      "868/868 - 7s - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.7856 - val_accuracy: 0.9200 - 7s/epoch - 8ms/step\n",
      "Epoch 79/150\n",
      "868/868 - 7s - loss: 0.0081 - accuracy: 0.9966 - val_loss: 0.7963 - val_accuracy: 0.9184 - 7s/epoch - 8ms/step\n",
      "Epoch 80/150\n",
      "868/868 - 7s - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.9761 - val_accuracy: 0.9199 - 7s/epoch - 8ms/step\n",
      "Epoch 81/150\n",
      "868/868 - 7s - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.8323 - val_accuracy: 0.9203 - 7s/epoch - 8ms/step\n",
      "Epoch 82/150\n",
      "868/868 - 7s - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.9460 - val_accuracy: 0.9227 - 7s/epoch - 8ms/step\n",
      "Epoch 83/150\n",
      "868/868 - 7s - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.8681 - val_accuracy: 0.9210 - 7s/epoch - 8ms/step\n",
      "Epoch 84/150\n",
      "868/868 - 7s - loss: 0.0092 - accuracy: 0.9964 - val_loss: 0.8703 - val_accuracy: 0.9189 - 7s/epoch - 8ms/step\n",
      "Epoch 85/150\n",
      "868/868 - 7s - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.8044 - val_accuracy: 0.9216 - 7s/epoch - 8ms/step\n",
      "Epoch 86/150\n",
      "868/868 - 7s - loss: 0.0082 - accuracy: 0.9965 - val_loss: 0.8520 - val_accuracy: 0.9174 - 7s/epoch - 8ms/step\n",
      "Epoch 87/150\n",
      "868/868 - 7s - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.8582 - val_accuracy: 0.9208 - 7s/epoch - 8ms/step\n",
      "Epoch 88/150\n",
      "868/868 - 7s - loss: 0.0083 - accuracy: 0.9967 - val_loss: 0.8652 - val_accuracy: 0.9211 - 7s/epoch - 8ms/step\n",
      "Epoch 89/150\n",
      "868/868 - 7s - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.8336 - val_accuracy: 0.9196 - 7s/epoch - 8ms/step\n",
      "Epoch 90/150\n",
      "868/868 - 7s - loss: 0.0082 - accuracy: 0.9964 - val_loss: 0.7990 - val_accuracy: 0.9171 - 7s/epoch - 8ms/step\n",
      "Epoch 91/150\n",
      "868/868 - 7s - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.9620 - val_accuracy: 0.9214 - 7s/epoch - 8ms/step\n",
      "Epoch 92/150\n",
      "868/868 - 7s - loss: 0.0079 - accuracy: 0.9969 - val_loss: 0.9844 - val_accuracy: 0.9217 - 7s/epoch - 8ms/step\n",
      "Epoch 93/150\n",
      "868/868 - 7s - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.9488 - val_accuracy: 0.9204 - 7s/epoch - 8ms/step\n",
      "Epoch 94/150\n",
      "868/868 - 7s - loss: 0.0080 - accuracy: 0.9967 - val_loss: 1.0492 - val_accuracy: 0.9226 - 7s/epoch - 8ms/step\n",
      "Epoch 95/150\n",
      "868/868 - 7s - loss: 0.0084 - accuracy: 0.9966 - val_loss: 0.8767 - val_accuracy: 0.9213 - 7s/epoch - 8ms/step\n",
      "Epoch 96/150\n",
      "868/868 - 7s - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.8824 - val_accuracy: 0.9206 - 7s/epoch - 8ms/step\n",
      "Epoch 97/150\n",
      "868/868 - 7s - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.9342 - val_accuracy: 0.9218 - 7s/epoch - 8ms/step\n",
      "Epoch 98/150\n",
      "868/868 - 7s - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.9500 - val_accuracy: 0.9210 - 7s/epoch - 8ms/step\n",
      "Epoch 99/150\n",
      "868/868 - 7s - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.9906 - val_accuracy: 0.9216 - 7s/epoch - 8ms/step\n",
      "Epoch 100/150\n",
      "868/868 - 7s - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.9952 - val_accuracy: 0.9215 - 7s/epoch - 8ms/step\n",
      "Epoch 101/150\n",
      "868/868 - 7s - loss: 0.0074 - accuracy: 0.9969 - val_loss: 1.0720 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 102/150\n",
      "868/868 - 7s - loss: 0.0096 - accuracy: 0.9964 - val_loss: 0.8918 - val_accuracy: 0.9223 - 7s/epoch - 8ms/step\n",
      "Epoch 103/150\n",
      "868/868 - 7s - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.8328 - val_accuracy: 0.9217 - 7s/epoch - 8ms/step\n",
      "Epoch 104/150\n",
      "868/868 - 7s - loss: 0.0080 - accuracy: 0.9965 - val_loss: 0.8923 - val_accuracy: 0.9194 - 7s/epoch - 8ms/step\n",
      "Epoch 105/150\n",
      "868/868 - 7s - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.9559 - val_accuracy: 0.9197 - 7s/epoch - 8ms/step\n",
      "Epoch 106/150\n",
      "868/868 - 7s - loss: 0.0072 - accuracy: 0.9971 - val_loss: 1.0040 - val_accuracy: 0.9226 - 7s/epoch - 8ms/step\n",
      "Epoch 107/150\n",
      "868/868 - 7s - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.9805 - val_accuracy: 0.9238 - 7s/epoch - 8ms/step\n",
      "Epoch 108/150\n",
      "868/868 - 7s - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.9999 - val_accuracy: 0.9220 - 7s/epoch - 8ms/step\n",
      "Epoch 109/150\n",
      "868/868 - 7s - loss: 0.0071 - accuracy: 0.9970 - val_loss: 1.0618 - val_accuracy: 0.9226 - 7s/epoch - 8ms/step\n",
      "Epoch 110/150\n",
      "868/868 - 7s - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.8196 - val_accuracy: 0.9186 - 7s/epoch - 8ms/step\n",
      "Epoch 111/150\n",
      "868/868 - 7s - loss: 0.0083 - accuracy: 0.9967 - val_loss: 0.8097 - val_accuracy: 0.9205 - 7s/epoch - 8ms/step\n",
      "Epoch 112/150\n",
      "868/868 - 7s - loss: 0.0082 - accuracy: 0.9964 - val_loss: 0.9849 - val_accuracy: 0.9211 - 7s/epoch - 8ms/step\n",
      "Epoch 113/150\n",
      "868/868 - 7s - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.8656 - val_accuracy: 0.9196 - 7s/epoch - 8ms/step\n",
      "Epoch 114/150\n",
      "868/868 - 7s - loss: 0.0072 - accuracy: 0.9968 - val_loss: 0.9419 - val_accuracy: 0.9231 - 7s/epoch - 8ms/step\n",
      "Epoch 115/150\n",
      "868/868 - 7s - loss: 0.0097 - accuracy: 0.9962 - val_loss: 0.8767 - val_accuracy: 0.9242 - 7s/epoch - 8ms/step\n",
      "Epoch 116/150\n",
      "868/868 - 7s - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.8165 - val_accuracy: 0.9215 - 7s/epoch - 8ms/step\n",
      "Epoch 117/150\n",
      "868/868 - 7s - loss: 0.0088 - accuracy: 0.9964 - val_loss: 0.8235 - val_accuracy: 0.9231 - 7s/epoch - 8ms/step\n",
      "Epoch 118/150\n",
      "868/868 - 7s - loss: 0.0074 - accuracy: 0.9967 - val_loss: 0.9540 - val_accuracy: 0.9233 - 7s/epoch - 8ms/step\n",
      "Epoch 119/150\n",
      "868/868 - 7s - loss: 0.0067 - accuracy: 0.9971 - val_loss: 0.9752 - val_accuracy: 0.9225 - 7s/epoch - 8ms/step\n",
      "Epoch 120/150\n",
      "868/868 - 7s - loss: 0.0077 - accuracy: 0.9969 - val_loss: 0.9631 - val_accuracy: 0.9220 - 7s/epoch - 8ms/step\n",
      "Epoch 121/150\n",
      "868/868 - 7s - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.9764 - val_accuracy: 0.9226 - 7s/epoch - 8ms/step\n",
      "Epoch 122/150\n",
      "868/868 - 7s - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.9643 - val_accuracy: 0.9204 - 7s/epoch - 8ms/step\n",
      "Epoch 123/150\n",
      "868/868 - 7s - loss: 0.0076 - accuracy: 0.9969 - val_loss: 0.9997 - val_accuracy: 0.9211 - 7s/epoch - 8ms/step\n",
      "Epoch 124/150\n",
      "868/868 - 7s - loss: 0.0079 - accuracy: 0.9967 - val_loss: 0.9807 - val_accuracy: 0.9201 - 7s/epoch - 8ms/step\n",
      "Epoch 125/150\n",
      "868/868 - 7s - loss: 0.0081 - accuracy: 0.9966 - val_loss: 0.8783 - val_accuracy: 0.9207 - 7s/epoch - 8ms/step\n",
      "Epoch 126/150\n",
      "868/868 - 7s - loss: 0.0061 - accuracy: 0.9974 - val_loss: 1.0952 - val_accuracy: 0.9208 - 7s/epoch - 8ms/step\n",
      "Epoch 127/150\n",
      "868/868 - 7s - loss: 0.0070 - accuracy: 0.9971 - val_loss: 1.0705 - val_accuracy: 0.9220 - 7s/epoch - 8ms/step\n",
      "Epoch 128/150\n",
      "868/868 - 7s - loss: 0.0069 - accuracy: 0.9972 - val_loss: 1.0315 - val_accuracy: 0.9203 - 7s/epoch - 8ms/step\n",
      "Epoch 129/150\n",
      "868/868 - 7s - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.9848 - val_accuracy: 0.9220 - 7s/epoch - 8ms/step\n",
      "Epoch 130/150\n",
      "868/868 - 7s - loss: 0.0066 - accuracy: 0.9974 - val_loss: 1.0923 - val_accuracy: 0.9217 - 7s/epoch - 8ms/step\n",
      "Epoch 131/150\n",
      "868/868 - 7s - loss: 0.0079 - accuracy: 0.9970 - val_loss: 1.0778 - val_accuracy: 0.9229 - 7s/epoch - 8ms/step\n",
      "Epoch 132/150\n",
      "868/868 - 7s - loss: 0.0075 - accuracy: 0.9968 - val_loss: 1.0052 - val_accuracy: 0.9223 - 7s/epoch - 8ms/step\n",
      "Epoch 133/150\n",
      "868/868 - 7s - loss: 0.0067 - accuracy: 0.9972 - val_loss: 1.0415 - val_accuracy: 0.9194 - 7s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150\n",
      "868/868 - 7s - loss: 0.0081 - accuracy: 0.9968 - val_loss: 1.0042 - val_accuracy: 0.9212 - 7s/epoch - 8ms/step\n",
      "Epoch 135/150\n",
      "868/868 - 7s - loss: 0.0070 - accuracy: 0.9971 - val_loss: 1.0769 - val_accuracy: 0.9235 - 7s/epoch - 8ms/step\n",
      "Epoch 136/150\n",
      "868/868 - 7s - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.9652 - val_accuracy: 0.9217 - 7s/epoch - 8ms/step\n",
      "Epoch 137/150\n",
      "868/868 - 7s - loss: 0.0070 - accuracy: 0.9970 - val_loss: 1.0846 - val_accuracy: 0.9221 - 7s/epoch - 8ms/step\n",
      "Epoch 138/150\n",
      "868/868 - 7s - loss: 0.0069 - accuracy: 0.9970 - val_loss: 1.1022 - val_accuracy: 0.9239 - 7s/epoch - 8ms/step\n",
      "Epoch 139/150\n",
      "868/868 - 7s - loss: 0.0082 - accuracy: 0.9967 - val_loss: 1.0593 - val_accuracy: 0.9234 - 7s/epoch - 8ms/step\n",
      "Epoch 140/150\n",
      "868/868 - 7s - loss: 0.0063 - accuracy: 0.9974 - val_loss: 1.0534 - val_accuracy: 0.9217 - 7s/epoch - 9ms/step\n",
      "Epoch 141/150\n",
      "868/868 - 7s - loss: 0.0067 - accuracy: 0.9972 - val_loss: 1.1050 - val_accuracy: 0.9220 - 7s/epoch - 8ms/step\n",
      "Epoch 142/150\n",
      "868/868 - 8s - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.9414 - val_accuracy: 0.9227 - 8s/epoch - 9ms/step\n",
      "Epoch 143/150\n",
      "868/868 - 7s - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.9113 - val_accuracy: 0.9214 - 7s/epoch - 8ms/step\n",
      "Epoch 144/150\n",
      "868/868 - 7s - loss: 0.0068 - accuracy: 0.9973 - val_loss: 1.0371 - val_accuracy: 0.9222 - 7s/epoch - 8ms/step\n",
      "Epoch 145/150\n",
      "868/868 - 8s - loss: 0.0068 - accuracy: 0.9972 - val_loss: 1.0055 - val_accuracy: 0.9217 - 8s/epoch - 9ms/step\n",
      "Epoch 146/150\n",
      "868/868 - 7s - loss: 0.0076 - accuracy: 0.9970 - val_loss: 1.1837 - val_accuracy: 0.9234 - 7s/epoch - 9ms/step\n",
      "Epoch 147/150\n",
      "868/868 - 8s - loss: 0.0079 - accuracy: 0.9966 - val_loss: 1.0862 - val_accuracy: 0.9223 - 8s/epoch - 9ms/step\n",
      "Epoch 148/150\n",
      "868/868 - 7s - loss: 0.0073 - accuracy: 0.9972 - val_loss: 1.1314 - val_accuracy: 0.9219 - 7s/epoch - 8ms/step\n",
      "Epoch 149/150\n",
      "868/868 - 7s - loss: 0.0063 - accuracy: 0.9972 - val_loss: 1.2013 - val_accuracy: 0.9247 - 7s/epoch - 8ms/step\n",
      "Epoch 150/150\n",
      "868/868 - 7s - loss: 0.0065 - accuracy: 0.9974 - val_loss: 1.1168 - val_accuracy: 0.9220 - 7s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.Conv1D(32, 3, activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size = 2, strides = 1),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_padded, y_train,\n",
    "                    validation_data = (valid_padded, y_test),\n",
    "                    epochs = 150,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f3d89",
   "metadata": {},
   "source": [
    "ƒê·ªô ch√≠nh x√°c ·ªü t·∫≠p ki·ªÉm tra ƒë√£ c·∫£i thi·ªán h∆°n so v·ªõi m√¥ h√¨nh tr∆∞·ªõc.\n",
    "\n",
    "\n",
    "Ta s·∫Ω ƒëi·ªÅu chu·∫©n m√¥ h√¨nh v·ªõi m·ªôt s·ªë thay ƒë·ªïi ·ªü h√†m k√≠ch ho·∫°t v√† kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "548532ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "868/868 - 14s - loss: 0.2249 - accuracy: 0.9099 - val_loss: 0.1783 - val_accuracy: 0.9332 - 14s/epoch - 16ms/step\n",
      "Epoch 2/150\n",
      "868/868 - 13s - loss: 0.1642 - accuracy: 0.9358 - val_loss: 0.1763 - val_accuracy: 0.9331 - 13s/epoch - 15ms/step\n",
      "Epoch 3/150\n",
      "868/868 - 12s - loss: 0.1284 - accuracy: 0.9500 - val_loss: 0.1879 - val_accuracy: 0.9300 - 12s/epoch - 14ms/step\n",
      "Epoch 4/150\n",
      "868/868 - 12s - loss: 0.0844 - accuracy: 0.9672 - val_loss: 0.2468 - val_accuracy: 0.9225 - 12s/epoch - 14ms/step\n",
      "Epoch 5/150\n",
      "868/868 - 13s - loss: 0.0542 - accuracy: 0.9795 - val_loss: 0.3011 - val_accuracy: 0.9199 - 13s/epoch - 15ms/step\n",
      "Epoch 6/150\n",
      "868/868 - 13s - loss: 0.0423 - accuracy: 0.9844 - val_loss: 0.3450 - val_accuracy: 0.9246 - 13s/epoch - 14ms/step\n",
      "Epoch 7/150\n",
      "868/868 - 13s - loss: 0.0371 - accuracy: 0.9853 - val_loss: 0.3536 - val_accuracy: 0.9208 - 13s/epoch - 15ms/step\n",
      "Epoch 8/150\n",
      "868/868 - 13s - loss: 0.0306 - accuracy: 0.9885 - val_loss: 0.3908 - val_accuracy: 0.9195 - 13s/epoch - 15ms/step\n",
      "Epoch 9/150\n",
      "868/868 - 12s - loss: 0.0247 - accuracy: 0.9903 - val_loss: 0.4602 - val_accuracy: 0.9202 - 12s/epoch - 14ms/step\n",
      "Epoch 10/150\n",
      "868/868 - 13s - loss: 0.0255 - accuracy: 0.9901 - val_loss: 0.4371 - val_accuracy: 0.9200 - 13s/epoch - 15ms/step\n",
      "Epoch 11/150\n",
      "868/868 - 12s - loss: 0.0217 - accuracy: 0.9918 - val_loss: 0.4461 - val_accuracy: 0.9194 - 12s/epoch - 14ms/step\n",
      "Epoch 12/150\n",
      "868/868 - 13s - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.5071 - val_accuracy: 0.9231 - 13s/epoch - 14ms/step\n",
      "Epoch 13/150\n",
      "868/868 - 12s - loss: 0.0196 - accuracy: 0.9925 - val_loss: 0.4473 - val_accuracy: 0.9199 - 12s/epoch - 14ms/step\n",
      "Epoch 14/150\n",
      "868/868 - 12s - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.5103 - val_accuracy: 0.9189 - 12s/epoch - 14ms/step\n",
      "Epoch 15/150\n",
      "868/868 - 12s - loss: 0.0204 - accuracy: 0.9924 - val_loss: 0.4999 - val_accuracy: 0.9164 - 12s/epoch - 14ms/step\n",
      "Epoch 16/150\n",
      "868/868 - 12s - loss: 0.0169 - accuracy: 0.9929 - val_loss: 0.5209 - val_accuracy: 0.9172 - 12s/epoch - 14ms/step\n",
      "Epoch 17/150\n",
      "868/868 - 13s - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.4825 - val_accuracy: 0.9226 - 13s/epoch - 15ms/step\n",
      "Epoch 18/150\n",
      "868/868 - 13s - loss: 0.0163 - accuracy: 0.9934 - val_loss: 0.5465 - val_accuracy: 0.9199 - 13s/epoch - 14ms/step\n",
      "Epoch 19/150\n",
      "868/868 - 13s - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.5662 - val_accuracy: 0.9224 - 13s/epoch - 14ms/step\n",
      "Epoch 20/150\n",
      "868/868 - 13s - loss: 0.0163 - accuracy: 0.9941 - val_loss: 0.6243 - val_accuracy: 0.9253 - 13s/epoch - 15ms/step\n",
      "Epoch 21/150\n",
      "868/868 - 13s - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.6377 - val_accuracy: 0.9203 - 13s/epoch - 15ms/step\n",
      "Epoch 22/150\n",
      "868/868 - 13s - loss: 0.0145 - accuracy: 0.9943 - val_loss: 0.5717 - val_accuracy: 0.9137 - 13s/epoch - 15ms/step\n",
      "Epoch 23/150\n",
      "868/868 - 13s - loss: 0.0154 - accuracy: 0.9937 - val_loss: 0.5466 - val_accuracy: 0.9212 - 13s/epoch - 15ms/step\n",
      "Epoch 24/150\n",
      "868/868 - 13s - loss: 0.0150 - accuracy: 0.9941 - val_loss: 0.5347 - val_accuracy: 0.9191 - 13s/epoch - 15ms/step\n",
      "Epoch 25/150\n",
      "868/868 - 13s - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.6410 - val_accuracy: 0.9224 - 13s/epoch - 15ms/step\n",
      "Epoch 26/150\n",
      "868/868 - 13s - loss: 0.0123 - accuracy: 0.9949 - val_loss: 0.6913 - val_accuracy: 0.9191 - 13s/epoch - 15ms/step\n",
      "Epoch 27/150\n",
      "868/868 - 13s - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.6479 - val_accuracy: 0.9206 - 13s/epoch - 15ms/step\n",
      "Epoch 28/150\n",
      "868/868 - 13s - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.6170 - val_accuracy: 0.9183 - 13s/epoch - 15ms/step\n",
      "Epoch 29/150\n",
      "868/868 - 13s - loss: 0.0136 - accuracy: 0.9943 - val_loss: 0.6291 - val_accuracy: 0.9162 - 13s/epoch - 14ms/step\n",
      "Epoch 30/150\n",
      "868/868 - 12s - loss: 0.0122 - accuracy: 0.9950 - val_loss: 0.6286 - val_accuracy: 0.9139 - 12s/epoch - 14ms/step\n",
      "Epoch 31/150\n",
      "868/868 - 13s - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.6905 - val_accuracy: 0.9213 - 13s/epoch - 15ms/step\n",
      "Epoch 32/150\n",
      "868/868 - 13s - loss: 0.0117 - accuracy: 0.9955 - val_loss: 0.6806 - val_accuracy: 0.9168 - 13s/epoch - 15ms/step\n",
      "Epoch 33/150\n",
      "868/868 - 13s - loss: 0.0115 - accuracy: 0.9956 - val_loss: 0.6681 - val_accuracy: 0.9210 - 13s/epoch - 15ms/step\n",
      "Epoch 34/150\n",
      "868/868 - 13s - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.5774 - val_accuracy: 0.9220 - 13s/epoch - 14ms/step\n",
      "Epoch 35/150\n",
      "868/868 - 13s - loss: 0.0112 - accuracy: 0.9955 - val_loss: 0.6698 - val_accuracy: 0.9150 - 13s/epoch - 14ms/step\n",
      "Epoch 36/150\n",
      "868/868 - 13s - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.6805 - val_accuracy: 0.9191 - 13s/epoch - 15ms/step\n",
      "Epoch 37/150\n",
      "868/868 - 13s - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.7602 - val_accuracy: 0.9216 - 13s/epoch - 15ms/step\n",
      "Epoch 38/150\n",
      "868/868 - 13s - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.7671 - val_accuracy: 0.9187 - 13s/epoch - 15ms/step\n",
      "Epoch 39/150\n",
      "868/868 - 13s - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.6616 - val_accuracy: 0.9179 - 13s/epoch - 15ms/step\n",
      "Epoch 40/150\n",
      "868/868 - 13s - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.9135 - val_accuracy: 0.9179 - 13s/epoch - 15ms/step\n",
      "Epoch 41/150\n",
      "868/868 - 13s - loss: 0.0095 - accuracy: 0.9961 - val_loss: 0.7998 - val_accuracy: 0.9186 - 13s/epoch - 15ms/step\n",
      "Epoch 42/150\n",
      "868/868 - 13s - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.7817 - val_accuracy: 0.9196 - 13s/epoch - 15ms/step\n",
      "Epoch 43/150\n",
      "868/868 - 13s - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.7926 - val_accuracy: 0.9164 - 13s/epoch - 15ms/step\n",
      "Epoch 44/150\n",
      "868/868 - 13s - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.7755 - val_accuracy: 0.9194 - 13s/epoch - 15ms/step\n",
      "Epoch 45/150\n",
      "868/868 - 13s - loss: 0.0099 - accuracy: 0.9961 - val_loss: 0.8488 - val_accuracy: 0.9190 - 13s/epoch - 15ms/step\n",
      "Epoch 46/150\n",
      "868/868 - 13s - loss: 0.0098 - accuracy: 0.9959 - val_loss: 0.7570 - val_accuracy: 0.9149 - 13s/epoch - 15ms/step\n",
      "Epoch 47/150\n",
      "868/868 - 13s - loss: 0.0092 - accuracy: 0.9964 - val_loss: 0.7484 - val_accuracy: 0.9217 - 13s/epoch - 15ms/step\n",
      "Epoch 48/150\n",
      "868/868 - 13s - loss: 0.0098 - accuracy: 0.9961 - val_loss: 0.7769 - val_accuracy: 0.9161 - 13s/epoch - 15ms/step\n",
      "Epoch 49/150\n",
      "868/868 - 13s - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.8359 - val_accuracy: 0.9136 - 13s/epoch - 15ms/step\n",
      "Epoch 50/150\n",
      "868/868 - 13s - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.9029 - val_accuracy: 0.9180 - 13s/epoch - 15ms/step\n",
      "Epoch 51/150\n",
      "868/868 - 13s - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.9727 - val_accuracy: 0.9202 - 13s/epoch - 15ms/step\n",
      "Epoch 52/150\n",
      "868/868 - 13s - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.7947 - val_accuracy: 0.9213 - 13s/epoch - 15ms/step\n",
      "Epoch 53/150\n",
      "868/868 - 13s - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.7690 - val_accuracy: 0.9178 - 13s/epoch - 15ms/step\n",
      "Epoch 54/150\n",
      "868/868 - 13s - loss: 0.0086 - accuracy: 0.9964 - val_loss: 0.8501 - val_accuracy: 0.9189 - 13s/epoch - 15ms/step\n",
      "Epoch 55/150\n",
      "868/868 - 13s - loss: 0.0099 - accuracy: 0.9961 - val_loss: 0.7885 - val_accuracy: 0.9213 - 13s/epoch - 15ms/step\n",
      "Epoch 56/150\n",
      "868/868 - 13s - loss: 0.0085 - accuracy: 0.9966 - val_loss: 0.8362 - val_accuracy: 0.9125 - 13s/epoch - 15ms/step\n",
      "Epoch 57/150\n",
      "868/868 - 13s - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.8087 - val_accuracy: 0.9185 - 13s/epoch - 15ms/step\n",
      "Epoch 58/150\n",
      "868/868 - 13s - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.9358 - val_accuracy: 0.9196 - 13s/epoch - 15ms/step\n",
      "Epoch 59/150\n",
      "868/868 - 13s - loss: 0.0083 - accuracy: 0.9968 - val_loss: 1.0179 - val_accuracy: 0.9199 - 13s/epoch - 15ms/step\n",
      "Epoch 60/150\n",
      "868/868 - 13s - loss: 0.0090 - accuracy: 0.9962 - val_loss: 0.9398 - val_accuracy: 0.9162 - 13s/epoch - 15ms/step\n",
      "Epoch 61/150\n",
      "868/868 - 13s - loss: 0.0072 - accuracy: 0.9969 - val_loss: 1.0266 - val_accuracy: 0.9194 - 13s/epoch - 15ms/step\n",
      "Epoch 62/150\n",
      "868/868 - 12s - loss: 0.0079 - accuracy: 0.9966 - val_loss: 0.9201 - val_accuracy: 0.9141 - 12s/epoch - 14ms/step\n",
      "Epoch 63/150\n",
      "868/868 - 12s - loss: 0.0067 - accuracy: 0.9972 - val_loss: 1.0785 - val_accuracy: 0.9158 - 12s/epoch - 14ms/step\n",
      "Epoch 64/150\n",
      "868/868 - 13s - loss: 0.0089 - accuracy: 0.9964 - val_loss: 0.8359 - val_accuracy: 0.9148 - 13s/epoch - 14ms/step\n",
      "Epoch 65/150\n",
      "868/868 - 13s - loss: 0.0086 - accuracy: 0.9961 - val_loss: 0.9887 - val_accuracy: 0.9193 - 13s/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150\n",
      "868/868 - 14s - loss: 0.0075 - accuracy: 0.9971 - val_loss: 1.0777 - val_accuracy: 0.9170 - 14s/epoch - 16ms/step\n",
      "Epoch 67/150\n",
      "868/868 - 14s - loss: 0.0085 - accuracy: 0.9967 - val_loss: 1.0119 - val_accuracy: 0.9200 - 14s/epoch - 16ms/step\n",
      "Epoch 68/150\n",
      "868/868 - 14s - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.9083 - val_accuracy: 0.9192 - 14s/epoch - 16ms/step\n",
      "Epoch 69/150\n",
      "868/868 - 13s - loss: 0.0074 - accuracy: 0.9969 - val_loss: 0.9952 - val_accuracy: 0.9195 - 13s/epoch - 15ms/step\n",
      "Epoch 70/150\n",
      "868/868 - 13s - loss: 0.0075 - accuracy: 0.9970 - val_loss: 1.1263 - val_accuracy: 0.9163 - 13s/epoch - 15ms/step\n",
      "Epoch 71/150\n",
      "868/868 - 13s - loss: 0.0083 - accuracy: 0.9965 - val_loss: 0.9636 - val_accuracy: 0.9166 - 13s/epoch - 14ms/step\n",
      "Epoch 72/150\n",
      "868/868 - 13s - loss: 0.0064 - accuracy: 0.9972 - val_loss: 1.1119 - val_accuracy: 0.9171 - 13s/epoch - 15ms/step\n",
      "Epoch 73/150\n",
      "868/868 - 13s - loss: 0.0085 - accuracy: 0.9966 - val_loss: 0.9239 - val_accuracy: 0.9193 - 13s/epoch - 15ms/step\n",
      "Epoch 74/150\n",
      "868/868 - 12s - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.8603 - val_accuracy: 0.9205 - 12s/epoch - 14ms/step\n",
      "Epoch 75/150\n",
      "868/868 - 12s - loss: 0.0068 - accuracy: 0.9972 - val_loss: 1.0770 - val_accuracy: 0.9198 - 12s/epoch - 14ms/step\n",
      "Epoch 76/150\n",
      "868/868 - 12s - loss: 0.0067 - accuracy: 0.9970 - val_loss: 1.0106 - val_accuracy: 0.9177 - 12s/epoch - 14ms/step\n",
      "Epoch 77/150\n",
      "868/868 - 13s - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.7675 - val_accuracy: 0.9182 - 13s/epoch - 15ms/step\n",
      "Epoch 78/150\n",
      "868/868 - 12s - loss: 0.0065 - accuracy: 0.9975 - val_loss: 1.0729 - val_accuracy: 0.9201 - 12s/epoch - 14ms/step\n",
      "Epoch 79/150\n",
      "868/868 - 13s - loss: 0.0066 - accuracy: 0.9973 - val_loss: 1.0939 - val_accuracy: 0.9167 - 13s/epoch - 14ms/step\n",
      "Epoch 80/150\n",
      "868/868 - 12s - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.9225 - val_accuracy: 0.9141 - 12s/epoch - 14ms/step\n",
      "Epoch 81/150\n",
      "868/868 - 13s - loss: 0.0073 - accuracy: 0.9968 - val_loss: 1.0489 - val_accuracy: 0.9189 - 13s/epoch - 15ms/step\n",
      "Epoch 82/150\n",
      "868/868 - 14s - loss: 0.0063 - accuracy: 0.9972 - val_loss: 1.1166 - val_accuracy: 0.9183 - 14s/epoch - 16ms/step\n",
      "Epoch 83/150\n",
      "868/868 - 14s - loss: 0.0073 - accuracy: 0.9970 - val_loss: 1.0111 - val_accuracy: 0.9176 - 14s/epoch - 16ms/step\n",
      "Epoch 84/150\n",
      "868/868 - 14s - loss: 0.0061 - accuracy: 0.9974 - val_loss: 1.2245 - val_accuracy: 0.9175 - 14s/epoch - 16ms/step\n",
      "Epoch 85/150\n",
      "868/868 - 13s - loss: 0.0061 - accuracy: 0.9972 - val_loss: 1.3137 - val_accuracy: 0.9170 - 13s/epoch - 15ms/step\n",
      "Epoch 86/150\n",
      "868/868 - 13s - loss: 0.0069 - accuracy: 0.9971 - val_loss: 1.1108 - val_accuracy: 0.9193 - 13s/epoch - 15ms/step\n",
      "Epoch 87/150\n",
      "868/868 - 13s - loss: 0.0075 - accuracy: 0.9970 - val_loss: 1.0874 - val_accuracy: 0.9173 - 13s/epoch - 15ms/step\n",
      "Epoch 88/150\n",
      "868/868 - 13s - loss: 0.0065 - accuracy: 0.9970 - val_loss: 1.1931 - val_accuracy: 0.9173 - 13s/epoch - 15ms/step\n",
      "Epoch 89/150\n",
      "868/868 - 13s - loss: 0.0075 - accuracy: 0.9967 - val_loss: 1.1606 - val_accuracy: 0.9157 - 13s/epoch - 15ms/step\n",
      "Epoch 90/150\n",
      "868/868 - 13s - loss: 0.0071 - accuracy: 0.9972 - val_loss: 1.1880 - val_accuracy: 0.9184 - 13s/epoch - 15ms/step\n",
      "Epoch 91/150\n",
      "868/868 - 13s - loss: 0.0068 - accuracy: 0.9969 - val_loss: 1.1456 - val_accuracy: 0.9179 - 13s/epoch - 15ms/step\n",
      "Epoch 92/150\n",
      "868/868 - 13s - loss: 0.0070 - accuracy: 0.9972 - val_loss: 1.1064 - val_accuracy: 0.9174 - 13s/epoch - 15ms/step\n",
      "Epoch 93/150\n",
      "868/868 - 13s - loss: 0.0050 - accuracy: 0.9979 - val_loss: 1.5012 - val_accuracy: 0.9187 - 13s/epoch - 15ms/step\n",
      "Epoch 94/150\n",
      "868/868 - 13s - loss: 0.0081 - accuracy: 0.9968 - val_loss: 1.0835 - val_accuracy: 0.9162 - 13s/epoch - 15ms/step\n",
      "Epoch 95/150\n",
      "868/868 - 13s - loss: 0.0065 - accuracy: 0.9972 - val_loss: 1.2039 - val_accuracy: 0.9192 - 13s/epoch - 15ms/step\n",
      "Epoch 96/150\n",
      "868/868 - 13s - loss: 0.0069 - accuracy: 0.9972 - val_loss: 1.1228 - val_accuracy: 0.9168 - 13s/epoch - 15ms/step\n",
      "Epoch 97/150\n",
      "868/868 - 13s - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.0852 - val_accuracy: 0.9183 - 13s/epoch - 15ms/step\n",
      "Epoch 98/150\n",
      "868/868 - 14s - loss: 0.0058 - accuracy: 0.9973 - val_loss: 1.3346 - val_accuracy: 0.9186 - 14s/epoch - 16ms/step\n",
      "Epoch 99/150\n",
      "868/868 - 14s - loss: 0.0065 - accuracy: 0.9973 - val_loss: 1.2219 - val_accuracy: 0.9185 - 14s/epoch - 16ms/step\n",
      "Epoch 100/150\n",
      "868/868 - 13s - loss: 0.0072 - accuracy: 0.9970 - val_loss: 1.2232 - val_accuracy: 0.9224 - 13s/epoch - 15ms/step\n",
      "Epoch 101/150\n",
      "868/868 - 13s - loss: 0.0061 - accuracy: 0.9973 - val_loss: 1.1832 - val_accuracy: 0.9180 - 13s/epoch - 15ms/step\n",
      "Epoch 102/150\n",
      "868/868 - 13s - loss: 0.0061 - accuracy: 0.9973 - val_loss: 1.4258 - val_accuracy: 0.9197 - 13s/epoch - 14ms/step\n",
      "Epoch 103/150\n",
      "868/868 - 12s - loss: 0.0059 - accuracy: 0.9973 - val_loss: 1.4406 - val_accuracy: 0.9172 - 12s/epoch - 14ms/step\n",
      "Epoch 104/150\n",
      "868/868 - 13s - loss: 0.0075 - accuracy: 0.9971 - val_loss: 1.0475 - val_accuracy: 0.9175 - 13s/epoch - 14ms/step\n",
      "Epoch 105/150\n",
      "868/868 - 13s - loss: 0.0073 - accuracy: 0.9970 - val_loss: 0.9994 - val_accuracy: 0.9168 - 13s/epoch - 15ms/step\n",
      "Epoch 106/150\n",
      "868/868 - 12s - loss: 0.0059 - accuracy: 0.9977 - val_loss: 1.2316 - val_accuracy: 0.9198 - 12s/epoch - 14ms/step\n",
      "Epoch 107/150\n",
      "868/868 - 12s - loss: 0.0060 - accuracy: 0.9973 - val_loss: 1.3673 - val_accuracy: 0.9200 - 12s/epoch - 14ms/step\n",
      "Epoch 108/150\n",
      "868/868 - 13s - loss: 0.0061 - accuracy: 0.9975 - val_loss: 1.5557 - val_accuracy: 0.9158 - 13s/epoch - 14ms/step\n",
      "Epoch 109/150\n",
      "868/868 - 12s - loss: 0.0078 - accuracy: 0.9970 - val_loss: 1.2400 - val_accuracy: 0.9171 - 12s/epoch - 14ms/step\n",
      "Epoch 110/150\n",
      "868/868 - 12s - loss: 0.0057 - accuracy: 0.9974 - val_loss: 1.6447 - val_accuracy: 0.9178 - 12s/epoch - 14ms/step\n",
      "Epoch 111/150\n",
      "868/868 - 13s - loss: 0.0060 - accuracy: 0.9972 - val_loss: 1.5618 - val_accuracy: 0.9123 - 13s/epoch - 15ms/step\n",
      "Epoch 112/150\n",
      "868/868 - 12s - loss: 0.0057 - accuracy: 0.9974 - val_loss: 1.8358 - val_accuracy: 0.9162 - 12s/epoch - 14ms/step\n",
      "Epoch 113/150\n",
      "868/868 - 13s - loss: 0.0053 - accuracy: 0.9977 - val_loss: 1.5406 - val_accuracy: 0.9120 - 13s/epoch - 14ms/step\n",
      "Epoch 114/150\n",
      "868/868 - 13s - loss: 0.0068 - accuracy: 0.9971 - val_loss: 1.4191 - val_accuracy: 0.9177 - 13s/epoch - 15ms/step\n",
      "Epoch 115/150\n",
      "868/868 - 13s - loss: 0.0061 - accuracy: 0.9971 - val_loss: 1.4919 - val_accuracy: 0.9168 - 13s/epoch - 15ms/step\n",
      "Epoch 116/150\n",
      "868/868 - 13s - loss: 0.0068 - accuracy: 0.9973 - val_loss: 1.3142 - val_accuracy: 0.9153 - 13s/epoch - 15ms/step\n",
      "Epoch 117/150\n",
      "868/868 - 14s - loss: 0.0057 - accuracy: 0.9975 - val_loss: 1.6991 - val_accuracy: 0.9131 - 14s/epoch - 16ms/step\n",
      "Epoch 118/150\n",
      "868/868 - 13s - loss: 0.0074 - accuracy: 0.9969 - val_loss: 1.6044 - val_accuracy: 0.9168 - 13s/epoch - 16ms/step\n",
      "Epoch 119/150\n",
      "868/868 - 13s - loss: 0.0062 - accuracy: 0.9975 - val_loss: 1.4137 - val_accuracy: 0.9165 - 13s/epoch - 15ms/step\n",
      "Epoch 120/150\n",
      "868/868 - 14s - loss: 0.0065 - accuracy: 0.9973 - val_loss: 1.4634 - val_accuracy: 0.9177 - 14s/epoch - 16ms/step\n",
      "Epoch 121/150\n",
      "868/868 - 13s - loss: 0.0056 - accuracy: 0.9976 - val_loss: 1.6505 - val_accuracy: 0.9169 - 13s/epoch - 14ms/step\n",
      "Epoch 122/150\n",
      "868/868 - 12s - loss: 0.0077 - accuracy: 0.9969 - val_loss: 1.5924 - val_accuracy: 0.9171 - 12s/epoch - 14ms/step\n",
      "Epoch 123/150\n",
      "868/868 - 12s - loss: 0.0054 - accuracy: 0.9975 - val_loss: 1.6500 - val_accuracy: 0.9144 - 12s/epoch - 14ms/step\n",
      "Epoch 124/150\n",
      "868/868 - 13s - loss: 0.0070 - accuracy: 0.9975 - val_loss: 1.2771 - val_accuracy: 0.9152 - 13s/epoch - 14ms/step\n",
      "Epoch 125/150\n",
      "868/868 - 13s - loss: 0.0070 - accuracy: 0.9971 - val_loss: 1.2684 - val_accuracy: 0.9116 - 13s/epoch - 15ms/step\n",
      "Epoch 126/150\n",
      "868/868 - 12s - loss: 0.0052 - accuracy: 0.9978 - val_loss: 1.6483 - val_accuracy: 0.9129 - 12s/epoch - 14ms/step\n",
      "Epoch 127/150\n",
      "868/868 - 12s - loss: 0.0052 - accuracy: 0.9977 - val_loss: 1.8626 - val_accuracy: 0.9157 - 12s/epoch - 14ms/step\n",
      "Epoch 128/150\n",
      "868/868 - 12s - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.6065 - val_accuracy: 0.9150 - 12s/epoch - 14ms/step\n",
      "Epoch 129/150\n",
      "868/868 - 12s - loss: 0.0060 - accuracy: 0.9973 - val_loss: 1.6426 - val_accuracy: 0.9164 - 12s/epoch - 14ms/step\n",
      "Epoch 130/150\n",
      "868/868 - 12s - loss: 0.0055 - accuracy: 0.9977 - val_loss: 1.5284 - val_accuracy: 0.9188 - 12s/epoch - 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/150\n",
      "868/868 - 12s - loss: 0.0051 - accuracy: 0.9976 - val_loss: 1.7616 - val_accuracy: 0.9166 - 12s/epoch - 14ms/step\n",
      "Epoch 132/150\n",
      "868/868 - 12s - loss: 0.0070 - accuracy: 0.9972 - val_loss: 1.2354 - val_accuracy: 0.9178 - 12s/epoch - 14ms/step\n",
      "Epoch 133/150\n",
      "868/868 - 12s - loss: 0.0062 - accuracy: 0.9974 - val_loss: 1.4341 - val_accuracy: 0.9177 - 12s/epoch - 14ms/step\n",
      "Epoch 134/150\n",
      "868/868 - 13s - loss: 0.0060 - accuracy: 0.9973 - val_loss: 1.3642 - val_accuracy: 0.9125 - 13s/epoch - 14ms/step\n",
      "Epoch 135/150\n",
      "868/868 - 13s - loss: 0.0060 - accuracy: 0.9973 - val_loss: 1.5355 - val_accuracy: 0.9090 - 13s/epoch - 15ms/step\n",
      "Epoch 136/150\n",
      "868/868 - 12s - loss: 0.0068 - accuracy: 0.9973 - val_loss: 1.2618 - val_accuracy: 0.9163 - 12s/epoch - 14ms/step\n",
      "Epoch 137/150\n",
      "868/868 - 12s - loss: 0.0052 - accuracy: 0.9976 - val_loss: 1.6951 - val_accuracy: 0.9152 - 12s/epoch - 14ms/step\n",
      "Epoch 138/150\n",
      "868/868 - 12s - loss: 0.0055 - accuracy: 0.9975 - val_loss: 1.8126 - val_accuracy: 0.9115 - 12s/epoch - 14ms/step\n",
      "Epoch 139/150\n",
      "868/868 - 12s - loss: 0.0053 - accuracy: 0.9976 - val_loss: 1.4764 - val_accuracy: 0.9122 - 12s/epoch - 14ms/step\n",
      "Epoch 140/150\n",
      "868/868 - 13s - loss: 0.0062 - accuracy: 0.9976 - val_loss: 1.4988 - val_accuracy: 0.9158 - 13s/epoch - 15ms/step\n",
      "Epoch 141/150\n",
      "868/868 - 14s - loss: 0.0065 - accuracy: 0.9974 - val_loss: 1.1267 - val_accuracy: 0.9114 - 14s/epoch - 16ms/step\n",
      "Epoch 142/150\n",
      "868/868 - 12s - loss: 0.0055 - accuracy: 0.9976 - val_loss: 1.5337 - val_accuracy: 0.9157 - 12s/epoch - 14ms/step\n",
      "Epoch 143/150\n",
      "868/868 - 12s - loss: 0.0050 - accuracy: 0.9978 - val_loss: 1.9108 - val_accuracy: 0.9148 - 12s/epoch - 14ms/step\n",
      "Epoch 144/150\n",
      "868/868 - 12s - loss: 0.0057 - accuracy: 0.9977 - val_loss: 1.8781 - val_accuracy: 0.9156 - 12s/epoch - 14ms/step\n",
      "Epoch 145/150\n",
      "868/868 - 12s - loss: 0.0056 - accuracy: 0.9977 - val_loss: 1.8165 - val_accuracy: 0.9110 - 12s/epoch - 14ms/step\n",
      "Epoch 146/150\n",
      "868/868 - 12s - loss: 0.0063 - accuracy: 0.9975 - val_loss: 1.4519 - val_accuracy: 0.9165 - 12s/epoch - 14ms/step\n",
      "Epoch 147/150\n",
      "868/868 - 12s - loss: 0.0071 - accuracy: 0.9971 - val_loss: 1.2107 - val_accuracy: 0.9146 - 12s/epoch - 14ms/step\n",
      "Epoch 148/150\n",
      "868/868 - 12s - loss: 0.0055 - accuracy: 0.9977 - val_loss: 1.3916 - val_accuracy: 0.9171 - 12s/epoch - 14ms/step\n",
      "Epoch 149/150\n",
      "868/868 - 12s - loss: 0.0050 - accuracy: 0.9976 - val_loss: 1.6496 - val_accuracy: 0.9165 - 12s/epoch - 14ms/step\n",
      "Epoch 150/150\n",
      "868/868 - 12s - loss: 0.0051 - accuracy: 0.9976 - val_loss: 1.6222 - val_accuracy: 0.9138 - 12s/epoch - 14ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size = 2, strides = 1),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    tf.keras.layers.Dense(16, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_padded, y_train,\n",
    "                    validation_data = (valid_padded, y_test),\n",
    "                    epochs = 150,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "85e3a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75      1975\n",
      "           1       0.94      0.96      0.95      9917\n",
      "\n",
      "    accuracy                           0.92     11892\n",
      "   macro avg       0.87      0.84      0.85     11892\n",
      "weighted avg       0.92      0.92      0.92     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "yhat = model.predict(valid_padded)\n",
    "yhat = np.round(yhat).reshape(-1)\n",
    "\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5b780",
   "metadata": {},
   "source": [
    "Ta s·∫Ω ph√¢n lo·∫°i v·ªõi `LSTM` 2 chi·ªÅu v√† l·ªõp _fully connected_ c√≥ ƒëi·ªÅu chu·∫©n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "babe57df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "868/868 - 39s - loss: 0.2317 - accuracy: 0.9108 - val_loss: 0.1840 - val_accuracy: 0.9312 - 39s/epoch - 45ms/step\n",
      "Epoch 2/150\n",
      "868/868 - 40s - loss: 0.1794 - accuracy: 0.9329 - val_loss: 0.1855 - val_accuracy: 0.9276 - 40s/epoch - 46ms/step\n",
      "Epoch 3/150\n",
      "868/868 - 43s - loss: 0.1637 - accuracy: 0.9383 - val_loss: 0.1859 - val_accuracy: 0.9309 - 43s/epoch - 50ms/step\n",
      "Epoch 4/150\n",
      "868/868 - 39s - loss: 0.1479 - accuracy: 0.9440 - val_loss: 0.1890 - val_accuracy: 0.9303 - 39s/epoch - 45ms/step\n",
      "Epoch 5/150\n",
      "868/868 - 39s - loss: 0.1379 - accuracy: 0.9477 - val_loss: 0.1934 - val_accuracy: 0.9287 - 39s/epoch - 45ms/step\n",
      "Epoch 6/150\n",
      "868/868 - 39s - loss: 0.1271 - accuracy: 0.9527 - val_loss: 0.1982 - val_accuracy: 0.9260 - 39s/epoch - 45ms/step\n",
      "Epoch 7/150\n",
      "868/868 - 39s - loss: 0.1175 - accuracy: 0.9555 - val_loss: 0.2087 - val_accuracy: 0.9235 - 39s/epoch - 45ms/step\n",
      "Epoch 8/150\n",
      "868/868 - 40s - loss: 0.1051 - accuracy: 0.9602 - val_loss: 0.2372 - val_accuracy: 0.9255 - 40s/epoch - 46ms/step\n",
      "Epoch 9/150\n",
      "868/868 - 40s - loss: 0.0972 - accuracy: 0.9634 - val_loss: 0.2571 - val_accuracy: 0.9206 - 40s/epoch - 46ms/step\n",
      "Epoch 10/150\n",
      "868/868 - 39s - loss: 0.0934 - accuracy: 0.9656 - val_loss: 0.2476 - val_accuracy: 0.9210 - 39s/epoch - 45ms/step\n",
      "Epoch 11/150\n",
      "868/868 - 40s - loss: 0.0842 - accuracy: 0.9699 - val_loss: 0.2561 - val_accuracy: 0.9168 - 40s/epoch - 47ms/step\n",
      "Epoch 12/150\n",
      "868/868 - 38s - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.2752 - val_accuracy: 0.9199 - 38s/epoch - 44ms/step\n",
      "Epoch 13/150\n",
      "868/868 - 38s - loss: 0.0637 - accuracy: 0.9781 - val_loss: 0.3137 - val_accuracy: 0.9166 - 38s/epoch - 43ms/step\n",
      "Epoch 14/150\n",
      "868/868 - 39s - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.3449 - val_accuracy: 0.9177 - 39s/epoch - 45ms/step\n",
      "Epoch 15/150\n",
      "868/868 - 39s - loss: 0.0574 - accuracy: 0.9792 - val_loss: 0.3395 - val_accuracy: 0.9130 - 39s/epoch - 45ms/step\n",
      "Epoch 16/150\n",
      "868/868 - 38s - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.3719 - val_accuracy: 0.9183 - 38s/epoch - 44ms/step\n",
      "Epoch 17/150\n",
      "868/868 - 39s - loss: 0.0437 - accuracy: 0.9846 - val_loss: 0.3909 - val_accuracy: 0.9148 - 39s/epoch - 45ms/step\n",
      "Epoch 18/150\n",
      "868/868 - 38s - loss: 0.0441 - accuracy: 0.9842 - val_loss: 0.4098 - val_accuracy: 0.9183 - 38s/epoch - 44ms/step\n",
      "Epoch 19/150\n",
      "868/868 - 38s - loss: 0.0383 - accuracy: 0.9875 - val_loss: 0.4321 - val_accuracy: 0.9126 - 38s/epoch - 44ms/step\n",
      "Epoch 20/150\n",
      "868/868 - 38s - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.5011 - val_accuracy: 0.9137 - 38s/epoch - 44ms/step\n",
      "Epoch 21/150\n",
      "868/868 - 38s - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.5033 - val_accuracy: 0.9115 - 38s/epoch - 44ms/step\n",
      "Epoch 22/150\n",
      "868/868 - 38s - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.4906 - val_accuracy: 0.9012 - 38s/epoch - 44ms/step\n",
      "Epoch 23/150\n",
      "868/868 - 38s - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.4864 - val_accuracy: 0.9108 - 38s/epoch - 44ms/step\n",
      "Epoch 24/150\n",
      "868/868 - 38s - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.4906 - val_accuracy: 0.9143 - 38s/epoch - 44ms/step\n",
      "Epoch 25/150\n",
      "868/868 - 39s - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.4829 - val_accuracy: 0.9112 - 39s/epoch - 44ms/step\n",
      "Epoch 26/150\n",
      "868/868 - 40s - loss: 0.0398 - accuracy: 0.9868 - val_loss: 0.4728 - val_accuracy: 0.9129 - 40s/epoch - 46ms/step\n",
      "Epoch 27/150\n",
      "868/868 - 45s - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.5825 - val_accuracy: 0.9109 - 45s/epoch - 52ms/step\n",
      "Epoch 28/150\n",
      "868/868 - 41s - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.6424 - val_accuracy: 0.9113 - 41s/epoch - 47ms/step\n",
      "Epoch 29/150\n",
      "868/868 - 38s - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.6397 - val_accuracy: 0.9142 - 38s/epoch - 44ms/step\n",
      "Epoch 30/150\n",
      "868/868 - 38s - loss: 0.0230 - accuracy: 0.9922 - val_loss: 0.5441 - val_accuracy: 0.9128 - 38s/epoch - 44ms/step\n",
      "Epoch 31/150\n",
      "868/868 - 43s - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.5955 - val_accuracy: 0.9140 - 43s/epoch - 50ms/step\n",
      "Epoch 32/150\n",
      "868/868 - 45s - loss: 0.0144 - accuracy: 0.9948 - val_loss: 0.7012 - val_accuracy: 0.9109 - 45s/epoch - 52ms/step\n",
      "Epoch 33/150\n",
      "868/868 - 40s - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.6812 - val_accuracy: 0.9129 - 40s/epoch - 47ms/step\n",
      "Epoch 34/150\n",
      "868/868 - 42s - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.5188 - val_accuracy: 0.9077 - 42s/epoch - 49ms/step\n",
      "Epoch 35/150\n",
      "868/868 - 42s - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.5835 - val_accuracy: 0.9120 - 42s/epoch - 49ms/step\n",
      "Epoch 36/150\n",
      "868/868 - 41s - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.5657 - val_accuracy: 0.9084 - 41s/epoch - 48ms/step\n",
      "Epoch 37/150\n",
      "868/868 - 41s - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.6599 - val_accuracy: 0.9114 - 41s/epoch - 48ms/step\n",
      "Epoch 38/150\n",
      "868/868 - 42s - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.6752 - val_accuracy: 0.9108 - 42s/epoch - 48ms/step\n",
      "Epoch 39/150\n",
      "868/868 - 43s - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.6182 - val_accuracy: 0.9117 - 43s/epoch - 49ms/step\n",
      "Epoch 40/150\n",
      "868/868 - 43s - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.6603 - val_accuracy: 0.9045 - 43s/epoch - 49ms/step\n",
      "Epoch 41/150\n",
      "868/868 - 43s - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.5846 - val_accuracy: 0.9104 - 43s/epoch - 50ms/step\n",
      "Epoch 42/150\n",
      "868/868 - 44s - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.6384 - val_accuracy: 0.9106 - 44s/epoch - 51ms/step\n",
      "Epoch 43/150\n",
      "868/868 - 45s - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.6675 - val_accuracy: 0.9169 - 45s/epoch - 52ms/step\n",
      "Epoch 44/150\n",
      "868/868 - 41s - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.6716 - val_accuracy: 0.8980 - 41s/epoch - 48ms/step\n",
      "Epoch 45/150\n",
      "868/868 - 42s - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.6736 - val_accuracy: 0.9113 - 42s/epoch - 49ms/step\n",
      "Epoch 46/150\n",
      "868/868 - 43s - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.6748 - val_accuracy: 0.9013 - 43s/epoch - 49ms/step\n",
      "Epoch 47/150\n",
      "868/868 - 43s - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.6778 - val_accuracy: 0.9094 - 43s/epoch - 50ms/step\n",
      "Epoch 48/150\n",
      "868/868 - 42s - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.6783 - val_accuracy: 0.9074 - 42s/epoch - 48ms/step\n",
      "Epoch 49/150\n",
      "868/868 - 43s - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.6115 - val_accuracy: 0.9074 - 43s/epoch - 50ms/step\n",
      "Epoch 50/150\n",
      "868/868 - 42s - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.6466 - val_accuracy: 0.9057 - 42s/epoch - 48ms/step\n",
      "Epoch 51/150\n",
      "868/868 - 42s - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.6435 - val_accuracy: 0.9161 - 42s/epoch - 48ms/step\n",
      "Epoch 52/150\n",
      "868/868 - 43s - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.5274 - val_accuracy: 0.9099 - 43s/epoch - 49ms/step\n",
      "Epoch 53/150\n",
      "868/868 - 51s - loss: 0.0079 - accuracy: 0.9968 - val_loss: 0.6403 - val_accuracy: 0.9114 - 51s/epoch - 58ms/step\n",
      "Epoch 54/150\n",
      "868/868 - 41s - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.6719 - val_accuracy: 0.9105 - 41s/epoch - 47ms/step\n",
      "Epoch 55/150\n",
      "868/868 - 43s - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.6715 - val_accuracy: 0.9121 - 43s/epoch - 49ms/step\n",
      "Epoch 56/150\n",
      "868/868 - 43s - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.6780 - val_accuracy: 0.9127 - 43s/epoch - 49ms/step\n",
      "Epoch 57/150\n",
      "868/868 - 43s - loss: 0.0070 - accuracy: 0.9969 - val_loss: 0.7005 - val_accuracy: 0.9128 - 43s/epoch - 50ms/step\n",
      "Epoch 58/150\n",
      "868/868 - 43s - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.5883 - val_accuracy: 0.9110 - 43s/epoch - 50ms/step\n",
      "Epoch 59/150\n",
      "868/868 - 44s - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.6492 - val_accuracy: 0.9063 - 44s/epoch - 50ms/step\n",
      "Epoch 60/150\n",
      "868/868 - 44s - loss: 0.0074 - accuracy: 0.9969 - val_loss: 0.6699 - val_accuracy: 0.9094 - 44s/epoch - 50ms/step\n",
      "Epoch 61/150\n",
      "868/868 - 42s - loss: 0.0119 - accuracy: 0.9955 - val_loss: 0.6152 - val_accuracy: 0.9071 - 42s/epoch - 49ms/step\n",
      "Epoch 62/150\n",
      "868/868 - 42s - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.6639 - val_accuracy: 0.9104 - 42s/epoch - 49ms/step\n",
      "Epoch 63/150\n",
      "868/868 - 43s - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.6857 - val_accuracy: 0.9078 - 43s/epoch - 49ms/step\n",
      "Epoch 64/150\n",
      "868/868 - 42s - loss: 0.0077 - accuracy: 0.9965 - val_loss: 0.7153 - val_accuracy: 0.9089 - 42s/epoch - 48ms/step\n",
      "Epoch 65/150\n",
      "868/868 - 43s - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.7392 - val_accuracy: 0.9098 - 43s/epoch - 49ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150\n",
      "868/868 - 42s - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.6914 - val_accuracy: 0.9101 - 42s/epoch - 48ms/step\n",
      "Epoch 67/150\n",
      "868/868 - 43s - loss: 0.0103 - accuracy: 0.9960 - val_loss: 0.6339 - val_accuracy: 0.9106 - 43s/epoch - 49ms/step\n",
      "Epoch 68/150\n",
      "868/868 - 42s - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.5901 - val_accuracy: 0.9114 - 42s/epoch - 48ms/step\n",
      "Epoch 69/150\n",
      "868/868 - 43s - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.6500 - val_accuracy: 0.9125 - 43s/epoch - 49ms/step\n",
      "Epoch 70/150\n",
      "868/868 - 42s - loss: 0.0074 - accuracy: 0.9970 - val_loss: 0.6826 - val_accuracy: 0.9030 - 42s/epoch - 48ms/step\n",
      "Epoch 71/150\n",
      "868/868 - 43s - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.6703 - val_accuracy: 0.9094 - 43s/epoch - 49ms/step\n",
      "Epoch 72/150\n",
      "868/868 - 43s - loss: 0.0071 - accuracy: 0.9972 - val_loss: 0.7067 - val_accuracy: 0.9087 - 43s/epoch - 49ms/step\n",
      "Epoch 73/150\n",
      "868/868 - 44s - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.6097 - val_accuracy: 0.9112 - 44s/epoch - 50ms/step\n",
      "Epoch 74/150\n",
      "868/868 - 42s - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.6277 - val_accuracy: 0.9120 - 42s/epoch - 49ms/step\n",
      "Epoch 75/150\n",
      "868/868 - 43s - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.6106 - val_accuracy: 0.9057 - 43s/epoch - 50ms/step\n",
      "Epoch 76/150\n",
      "868/868 - 43s - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.6340 - val_accuracy: 0.9128 - 43s/epoch - 49ms/step\n",
      "Epoch 77/150\n",
      "868/868 - 45s - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.6558 - val_accuracy: 0.9136 - 45s/epoch - 52ms/step\n",
      "Epoch 78/150\n",
      "868/868 - 42s - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.6842 - val_accuracy: 0.9098 - 42s/epoch - 48ms/step\n",
      "Epoch 79/150\n",
      "868/868 - 44s - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.6384 - val_accuracy: 0.9147 - 44s/epoch - 50ms/step\n",
      "Epoch 80/150\n",
      "868/868 - 45s - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.6722 - val_accuracy: 0.9115 - 45s/epoch - 52ms/step\n",
      "Epoch 81/150\n",
      "868/868 - 43s - loss: 0.0063 - accuracy: 0.9973 - val_loss: 0.6736 - val_accuracy: 0.9133 - 43s/epoch - 50ms/step\n",
      "Epoch 82/150\n",
      "868/868 - 44s - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.6825 - val_accuracy: 0.9146 - 44s/epoch - 51ms/step\n",
      "Epoch 83/150\n",
      "868/868 - 43s - loss: 0.0065 - accuracy: 0.9971 - val_loss: 0.6906 - val_accuracy: 0.9149 - 43s/epoch - 49ms/step\n",
      "Epoch 84/150\n",
      "868/868 - 43s - loss: 0.0064 - accuracy: 0.9971 - val_loss: 0.6811 - val_accuracy: 0.9158 - 43s/epoch - 50ms/step\n",
      "Epoch 85/150\n",
      "868/868 - 45s - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.5715 - val_accuracy: 0.9059 - 45s/epoch - 52ms/step\n",
      "Epoch 86/150\n",
      "868/868 - 57s - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.5682 - val_accuracy: 0.9069 - 57s/epoch - 66ms/step\n",
      "Epoch 87/150\n",
      "868/868 - 43s - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.6816 - val_accuracy: 0.9144 - 43s/epoch - 49ms/step\n",
      "Epoch 88/150\n",
      "868/868 - 48s - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.7078 - val_accuracy: 0.9159 - 48s/epoch - 56ms/step\n",
      "Epoch 89/150\n",
      "868/868 - 57s - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.7166 - val_accuracy: 0.9129 - 57s/epoch - 66ms/step\n",
      "Epoch 90/150\n",
      "868/868 - 42s - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.7229 - val_accuracy: 0.9151 - 42s/epoch - 48ms/step\n",
      "Epoch 91/150\n",
      "868/868 - 45s - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.7198 - val_accuracy: 0.9143 - 45s/epoch - 52ms/step\n",
      "Epoch 92/150\n",
      "868/868 - 42s - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.7034 - val_accuracy: 0.9142 - 42s/epoch - 49ms/step\n",
      "Epoch 93/150\n",
      "868/868 - 44s - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.6895 - val_accuracy: 0.9096 - 44s/epoch - 50ms/step\n",
      "Epoch 94/150\n",
      "868/868 - 46s - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.5813 - val_accuracy: 0.9122 - 46s/epoch - 53ms/step\n",
      "Epoch 95/150\n",
      "868/868 - 43s - loss: 0.0061 - accuracy: 0.9973 - val_loss: 0.6509 - val_accuracy: 0.9077 - 43s/epoch - 49ms/step\n",
      "Epoch 96/150\n",
      "868/868 - 43s - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.7139 - val_accuracy: 0.9134 - 43s/epoch - 50ms/step\n",
      "Epoch 97/150\n",
      "868/868 - 43s - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.7089 - val_accuracy: 0.9112 - 43s/epoch - 49ms/step\n",
      "Epoch 98/150\n",
      "868/868 - 42s - loss: 0.0054 - accuracy: 0.9976 - val_loss: 0.7224 - val_accuracy: 0.9127 - 42s/epoch - 49ms/step\n",
      "Epoch 99/150\n",
      "868/868 - 47s - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.6794 - val_accuracy: 0.9141 - 47s/epoch - 54ms/step\n",
      "Epoch 100/150\n",
      "868/868 - 44s - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.7108 - val_accuracy: 0.9143 - 44s/epoch - 51ms/step\n",
      "Epoch 101/150\n",
      "868/868 - 46s - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5352 - val_accuracy: 0.9120 - 46s/epoch - 53ms/step\n",
      "Epoch 102/150\n",
      "868/868 - 47s - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.5811 - val_accuracy: 0.9116 - 47s/epoch - 54ms/step\n",
      "Epoch 103/150\n",
      "868/868 - 42s - loss: 0.0061 - accuracy: 0.9975 - val_loss: 0.6501 - val_accuracy: 0.9160 - 42s/epoch - 49ms/step\n",
      "Epoch 104/150\n",
      "868/868 - 40s - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.6754 - val_accuracy: 0.9146 - 40s/epoch - 46ms/step\n",
      "Epoch 105/150\n",
      "868/868 - 40s - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.6991 - val_accuracy: 0.9157 - 40s/epoch - 46ms/step\n",
      "Epoch 106/150\n",
      "868/868 - 42s - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.6930 - val_accuracy: 0.9115 - 42s/epoch - 49ms/step\n",
      "Epoch 107/150\n",
      "868/868 - 45s - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.6717 - val_accuracy: 0.9162 - 45s/epoch - 51ms/step\n",
      "Epoch 108/150\n",
      "868/868 - 41s - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.6909 - val_accuracy: 0.9164 - 41s/epoch - 47ms/step\n",
      "Epoch 109/150\n",
      "868/868 - 40s - loss: 0.0056 - accuracy: 0.9974 - val_loss: 0.6775 - val_accuracy: 0.9170 - 40s/epoch - 46ms/step\n",
      "Epoch 110/150\n",
      "868/868 - 41s - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.5257 - val_accuracy: 0.9122 - 41s/epoch - 47ms/step\n",
      "Epoch 111/150\n",
      "868/868 - 44s - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.5669 - val_accuracy: 0.9143 - 44s/epoch - 51ms/step\n",
      "Epoch 112/150\n",
      "868/868 - 49s - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.5901 - val_accuracy: 0.9136 - 49s/epoch - 57ms/step\n",
      "Epoch 113/150\n",
      "868/868 - 40s - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.6656 - val_accuracy: 0.9139 - 40s/epoch - 46ms/step\n",
      "Epoch 114/150\n",
      "868/868 - 41s - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.7120 - val_accuracy: 0.9115 - 41s/epoch - 47ms/step\n",
      "Epoch 115/150\n",
      "868/868 - 43s - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.7209 - val_accuracy: 0.9135 - 43s/epoch - 49ms/step\n",
      "Epoch 116/150\n",
      "868/868 - 45s - loss: 0.0054 - accuracy: 0.9978 - val_loss: 0.7049 - val_accuracy: 0.9149 - 45s/epoch - 52ms/step\n",
      "Epoch 117/150\n",
      "868/868 - 41s - loss: 0.0052 - accuracy: 0.9977 - val_loss: 0.6987 - val_accuracy: 0.9150 - 41s/epoch - 48ms/step\n",
      "Epoch 118/150\n",
      "868/868 - 42s - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.7159 - val_accuracy: 0.9130 - 42s/epoch - 48ms/step\n",
      "Epoch 119/150\n",
      "868/868 - 40s - loss: 0.0105 - accuracy: 0.9961 - val_loss: 0.5726 - val_accuracy: 0.9153 - 40s/epoch - 46ms/step\n",
      "Epoch 120/150\n",
      "868/868 - 43s - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.5673 - val_accuracy: 0.9118 - 43s/epoch - 50ms/step\n",
      "Epoch 121/150\n",
      "868/868 - 46s - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.6667 - val_accuracy: 0.9158 - 46s/epoch - 52ms/step\n",
      "Epoch 122/150\n",
      "868/868 - 43s - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.7066 - val_accuracy: 0.9140 - 43s/epoch - 49ms/step\n",
      "Epoch 123/150\n",
      "868/868 - 40s - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.7325 - val_accuracy: 0.9176 - 40s/epoch - 46ms/step\n",
      "Epoch 124/150\n",
      "868/868 - 41s - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.7252 - val_accuracy: 0.9163 - 41s/epoch - 47ms/step\n",
      "Epoch 125/150\n",
      "868/868 - 41s - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.7336 - val_accuracy: 0.9157 - 41s/epoch - 47ms/step\n",
      "Epoch 126/150\n",
      "868/868 - 41s - loss: 0.0052 - accuracy: 0.9975 - val_loss: 0.6981 - val_accuracy: 0.9162 - 41s/epoch - 47ms/step\n",
      "Epoch 127/150\n",
      "868/868 - 42s - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.6878 - val_accuracy: 0.9124 - 42s/epoch - 49ms/step\n",
      "Epoch 128/150\n",
      "868/868 - 46s - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.5834 - val_accuracy: 0.9136 - 46s/epoch - 53ms/step\n",
      "Epoch 129/150\n",
      "868/868 - 44s - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.5363 - val_accuracy: 0.9123 - 44s/epoch - 50ms/step\n",
      "Epoch 130/150\n",
      "868/868 - 43s - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.6594 - val_accuracy: 0.9118 - 43s/epoch - 49ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/150\n",
      "868/868 - 43s - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.7135 - val_accuracy: 0.9112 - 43s/epoch - 49ms/step\n",
      "Epoch 132/150\n",
      "868/868 - 44s - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.6892 - val_accuracy: 0.9124 - 44s/epoch - 51ms/step\n",
      "Epoch 133/150\n",
      "868/868 - 42s - loss: 0.0070 - accuracy: 0.9971 - val_loss: 0.6354 - val_accuracy: 0.9100 - 42s/epoch - 48ms/step\n",
      "Epoch 134/150\n",
      "868/868 - 42s - loss: 0.0067 - accuracy: 0.9973 - val_loss: 0.6901 - val_accuracy: 0.9088 - 42s/epoch - 48ms/step\n",
      "Epoch 135/150\n",
      "868/868 - 43s - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.6617 - val_accuracy: 0.9152 - 43s/epoch - 49ms/step\n",
      "Epoch 136/150\n",
      "868/868 - 44s - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6709 - val_accuracy: 0.9147 - 44s/epoch - 51ms/step\n",
      "Epoch 137/150\n",
      "868/868 - 45s - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.6990 - val_accuracy: 0.9141 - 45s/epoch - 52ms/step\n",
      "Epoch 138/150\n",
      "868/868 - 48s - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.7025 - val_accuracy: 0.9152 - 48s/epoch - 56ms/step\n",
      "Epoch 139/150\n",
      "868/868 - 45s - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.7015 - val_accuracy: 0.9166 - 45s/epoch - 52ms/step\n",
      "Epoch 140/150\n",
      "868/868 - 46s - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.6928 - val_accuracy: 0.9173 - 46s/epoch - 53ms/step\n",
      "Epoch 141/150\n",
      "868/868 - 46s - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.6849 - val_accuracy: 0.9126 - 46s/epoch - 53ms/step\n",
      "Epoch 142/150\n",
      "868/868 - 48s - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.6784 - val_accuracy: 0.9146 - 48s/epoch - 55ms/step\n",
      "Epoch 143/150\n",
      "868/868 - 48s - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.5666 - val_accuracy: 0.9115 - 48s/epoch - 55ms/step\n",
      "Epoch 144/150\n",
      "868/868 - 46s - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.5885 - val_accuracy: 0.9145 - 46s/epoch - 53ms/step\n",
      "Epoch 145/150\n",
      "868/868 - 47s - loss: 0.0054 - accuracy: 0.9975 - val_loss: 0.6954 - val_accuracy: 0.9116 - 47s/epoch - 54ms/step\n",
      "Epoch 146/150\n",
      "868/868 - 45s - loss: 0.0065 - accuracy: 0.9975 - val_loss: 0.6549 - val_accuracy: 0.9136 - 45s/epoch - 52ms/step\n",
      "Epoch 147/150\n",
      "868/868 - 46s - loss: 0.0048 - accuracy: 0.9978 - val_loss: 0.7116 - val_accuracy: 0.9138 - 46s/epoch - 53ms/step\n",
      "Epoch 148/150\n",
      "868/868 - 46s - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.7121 - val_accuracy: 0.9150 - 46s/epoch - 53ms/step\n",
      "Epoch 149/150\n",
      "868/868 - 48s - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.7060 - val_accuracy: 0.9129 - 48s/epoch - 55ms/step\n",
      "Epoch 150/150\n",
      "868/868 - 45s - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.6998 - val_accuracy: 0.9118 - 45s/epoch - 52ms/step\n"
     ]
    }
   ],
   "source": [
    "model_lstm = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(32, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model_lstm.fit(train_padded, y_train,\n",
    "                    validation_data = (valid_padded, y_test),\n",
    "                    epochs = 150,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11c59f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "868/868 - 10s - loss: 0.2408 - accuracy: 0.9034 - val_loss: 0.1777 - val_accuracy: 0.9330 - 10s/epoch - 11ms/step\n",
      "Epoch 2/150\n",
      "868/868 - 8s - loss: 0.1737 - accuracy: 0.9337 - val_loss: 0.1756 - val_accuracy: 0.9328 - 8s/epoch - 9ms/step\n",
      "Epoch 3/150\n",
      "868/868 - 8s - loss: 0.1549 - accuracy: 0.9400 - val_loss: 0.1809 - val_accuracy: 0.9324 - 8s/epoch - 9ms/step\n",
      "Epoch 4/150\n",
      "868/868 - 8s - loss: 0.1347 - accuracy: 0.9479 - val_loss: 0.1854 - val_accuracy: 0.9326 - 8s/epoch - 9ms/step\n",
      "Epoch 5/150\n",
      "868/868 - 8s - loss: 0.1151 - accuracy: 0.9546 - val_loss: 0.2084 - val_accuracy: 0.9304 - 8s/epoch - 9ms/step\n",
      "Epoch 6/150\n",
      "868/868 - 8s - loss: 0.0968 - accuracy: 0.9612 - val_loss: 0.2240 - val_accuracy: 0.9252 - 8s/epoch - 9ms/step\n",
      "Epoch 7/150\n",
      "868/868 - 8s - loss: 0.0847 - accuracy: 0.9678 - val_loss: 0.2497 - val_accuracy: 0.9269 - 8s/epoch - 9ms/step\n",
      "Epoch 8/150\n",
      "868/868 - 8s - loss: 0.0763 - accuracy: 0.9716 - val_loss: 0.2542 - val_accuracy: 0.9248 - 8s/epoch - 9ms/step\n",
      "Epoch 9/150\n",
      "868/868 - 8s - loss: 0.0678 - accuracy: 0.9737 - val_loss: 0.2767 - val_accuracy: 0.9247 - 8s/epoch - 9ms/step\n",
      "Epoch 10/150\n",
      "868/868 - 8s - loss: 0.0605 - accuracy: 0.9759 - val_loss: 0.2761 - val_accuracy: 0.9224 - 8s/epoch - 9ms/step\n",
      "Epoch 11/150\n",
      "868/868 - 7s - loss: 0.0596 - accuracy: 0.9768 - val_loss: 0.2878 - val_accuracy: 0.9252 - 7s/epoch - 9ms/step\n",
      "Epoch 12/150\n",
      "868/868 - 7s - loss: 0.0515 - accuracy: 0.9809 - val_loss: 0.3563 - val_accuracy: 0.9239 - 7s/epoch - 9ms/step\n",
      "Epoch 13/150\n",
      "868/868 - 8s - loss: 0.0502 - accuracy: 0.9804 - val_loss: 0.3368 - val_accuracy: 0.9237 - 8s/epoch - 9ms/step\n",
      "Epoch 14/150\n",
      "868/868 - 8s - loss: 0.0479 - accuracy: 0.9817 - val_loss: 0.3588 - val_accuracy: 0.9212 - 8s/epoch - 9ms/step\n",
      "Epoch 15/150\n",
      "868/868 - 8s - loss: 0.0448 - accuracy: 0.9821 - val_loss: 0.3587 - val_accuracy: 0.9227 - 8s/epoch - 9ms/step\n",
      "Epoch 16/150\n",
      "868/868 - 7s - loss: 0.0452 - accuracy: 0.9815 - val_loss: 0.3551 - val_accuracy: 0.9223 - 7s/epoch - 9ms/step\n",
      "Epoch 17/150\n",
      "868/868 - 7s - loss: 0.0422 - accuracy: 0.9839 - val_loss: 0.3457 - val_accuracy: 0.9229 - 7s/epoch - 9ms/step\n",
      "Epoch 18/150\n",
      "868/868 - 8s - loss: 0.0402 - accuracy: 0.9840 - val_loss: 0.3546 - val_accuracy: 0.9209 - 8s/epoch - 9ms/step\n",
      "Epoch 19/150\n",
      "868/868 - 7s - loss: 0.0415 - accuracy: 0.9840 - val_loss: 0.3635 - val_accuracy: 0.9209 - 7s/epoch - 9ms/step\n",
      "Epoch 20/150\n",
      "868/868 - 7s - loss: 0.0382 - accuracy: 0.9857 - val_loss: 0.3634 - val_accuracy: 0.9221 - 7s/epoch - 9ms/step\n",
      "Epoch 21/150\n",
      "868/868 - 7s - loss: 0.0384 - accuracy: 0.9856 - val_loss: 0.3595 - val_accuracy: 0.9229 - 7s/epoch - 9ms/step\n",
      "Epoch 22/150\n",
      "868/868 - 7s - loss: 0.0374 - accuracy: 0.9854 - val_loss: 0.3945 - val_accuracy: 0.9222 - 7s/epoch - 9ms/step\n",
      "Epoch 23/150\n",
      "868/868 - 7s - loss: 0.0357 - accuracy: 0.9862 - val_loss: 0.3661 - val_accuracy: 0.9218 - 7s/epoch - 9ms/step\n",
      "Epoch 24/150\n",
      "868/868 - 7s - loss: 0.0329 - accuracy: 0.9872 - val_loss: 0.4110 - val_accuracy: 0.9208 - 7s/epoch - 9ms/step\n",
      "Epoch 25/150\n",
      "868/868 - 7s - loss: 0.0330 - accuracy: 0.9866 - val_loss: 0.4162 - val_accuracy: 0.9222 - 7s/epoch - 9ms/step\n",
      "Epoch 26/150\n",
      "868/868 - 7s - loss: 0.0334 - accuracy: 0.9876 - val_loss: 0.3858 - val_accuracy: 0.9224 - 7s/epoch - 9ms/step\n",
      "Epoch 27/150\n",
      "868/868 - 8s - loss: 0.0339 - accuracy: 0.9871 - val_loss: 0.4145 - val_accuracy: 0.9203 - 8s/epoch - 9ms/step\n",
      "Epoch 28/150\n",
      "868/868 - 7s - loss: 0.0326 - accuracy: 0.9877 - val_loss: 0.4167 - val_accuracy: 0.9216 - 7s/epoch - 9ms/step\n",
      "Epoch 29/150\n",
      "868/868 - 7s - loss: 0.0316 - accuracy: 0.9881 - val_loss: 0.4084 - val_accuracy: 0.9222 - 7s/epoch - 9ms/step\n",
      "Epoch 30/150\n",
      "868/868 - 8s - loss: 0.0303 - accuracy: 0.9880 - val_loss: 0.4300 - val_accuracy: 0.9205 - 8s/epoch - 9ms/step\n",
      "Epoch 31/150\n",
      "868/868 - 8s - loss: 0.0310 - accuracy: 0.9881 - val_loss: 0.4165 - val_accuracy: 0.9224 - 8s/epoch - 9ms/step\n",
      "Epoch 32/150\n",
      "868/868 - 8s - loss: 0.0292 - accuracy: 0.9889 - val_loss: 0.4190 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 33/150\n",
      "868/868 - 8s - loss: 0.0274 - accuracy: 0.9899 - val_loss: 0.4034 - val_accuracy: 0.9241 - 8s/epoch - 9ms/step\n",
      "Epoch 34/150\n",
      "868/868 - 8s - loss: 0.0290 - accuracy: 0.9888 - val_loss: 0.4007 - val_accuracy: 0.9231 - 8s/epoch - 9ms/step\n",
      "Epoch 35/150\n",
      "868/868 - 8s - loss: 0.0283 - accuracy: 0.9892 - val_loss: 0.4373 - val_accuracy: 0.9204 - 8s/epoch - 9ms/step\n",
      "Epoch 36/150\n",
      "868/868 - 8s - loss: 0.0267 - accuracy: 0.9895 - val_loss: 0.4334 - val_accuracy: 0.9234 - 8s/epoch - 9ms/step\n",
      "Epoch 37/150\n",
      "868/868 - 8s - loss: 0.0290 - accuracy: 0.9896 - val_loss: 0.4046 - val_accuracy: 0.9234 - 8s/epoch - 9ms/step\n",
      "Epoch 38/150\n",
      "868/868 - 8s - loss: 0.0248 - accuracy: 0.9901 - val_loss: 0.4480 - val_accuracy: 0.9226 - 8s/epoch - 9ms/step\n",
      "Epoch 39/150\n",
      "868/868 - 8s - loss: 0.0260 - accuracy: 0.9901 - val_loss: 0.4236 - val_accuracy: 0.9214 - 8s/epoch - 9ms/step\n",
      "Epoch 40/150\n",
      "868/868 - 8s - loss: 0.0256 - accuracy: 0.9899 - val_loss: 0.4266 - val_accuracy: 0.9242 - 8s/epoch - 9ms/step\n",
      "Epoch 41/150\n",
      "868/868 - 8s - loss: 0.0237 - accuracy: 0.9909 - val_loss: 0.4202 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 42/150\n",
      "868/868 - 8s - loss: 0.0233 - accuracy: 0.9909 - val_loss: 0.4330 - val_accuracy: 0.9232 - 8s/epoch - 9ms/step\n",
      "Epoch 43/150\n",
      "868/868 - 8s - loss: 0.0265 - accuracy: 0.9895 - val_loss: 0.4649 - val_accuracy: 0.9227 - 8s/epoch - 9ms/step\n",
      "Epoch 44/150\n",
      "868/868 - 8s - loss: 0.0261 - accuracy: 0.9901 - val_loss: 0.4176 - val_accuracy: 0.9226 - 8s/epoch - 9ms/step\n",
      "Epoch 45/150\n",
      "868/868 - 8s - loss: 0.0272 - accuracy: 0.9892 - val_loss: 0.4343 - val_accuracy: 0.9206 - 8s/epoch - 9ms/step\n",
      "Epoch 46/150\n",
      "868/868 - 8s - loss: 0.0236 - accuracy: 0.9911 - val_loss: 0.4812 - val_accuracy: 0.9228 - 8s/epoch - 9ms/step\n",
      "Epoch 47/150\n",
      "868/868 - 9s - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.4757 - val_accuracy: 0.9234 - 9s/epoch - 11ms/step\n",
      "Epoch 48/150\n",
      "868/868 - 10s - loss: 0.0225 - accuracy: 0.9908 - val_loss: 0.4756 - val_accuracy: 0.9221 - 10s/epoch - 11ms/step\n",
      "Epoch 49/150\n",
      "868/868 - 10s - loss: 0.0221 - accuracy: 0.9916 - val_loss: 0.5345 - val_accuracy: 0.9226 - 10s/epoch - 11ms/step\n",
      "Epoch 50/150\n",
      "868/868 - 9s - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.4442 - val_accuracy: 0.9221 - 9s/epoch - 10ms/step\n",
      "Epoch 51/150\n",
      "868/868 - 8s - loss: 0.0230 - accuracy: 0.9905 - val_loss: 0.4846 - val_accuracy: 0.9230 - 8s/epoch - 10ms/step\n",
      "Epoch 52/150\n",
      "868/868 - 8s - loss: 0.0245 - accuracy: 0.9902 - val_loss: 0.4954 - val_accuracy: 0.9221 - 8s/epoch - 9ms/step\n",
      "Epoch 53/150\n",
      "868/868 - 8s - loss: 0.0223 - accuracy: 0.9915 - val_loss: 0.4741 - val_accuracy: 0.9198 - 8s/epoch - 9ms/step\n",
      "Epoch 54/150\n",
      "868/868 - 8s - loss: 0.0227 - accuracy: 0.9911 - val_loss: 0.4721 - val_accuracy: 0.9215 - 8s/epoch - 9ms/step\n",
      "Epoch 55/150\n",
      "868/868 - 8s - loss: 0.0208 - accuracy: 0.9920 - val_loss: 0.4547 - val_accuracy: 0.9215 - 8s/epoch - 9ms/step\n",
      "Epoch 56/150\n",
      "868/868 - 8s - loss: 0.0206 - accuracy: 0.9919 - val_loss: 0.4961 - val_accuracy: 0.9194 - 8s/epoch - 9ms/step\n",
      "Epoch 57/150\n",
      "868/868 - 8s - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.4523 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 58/150\n",
      "868/868 - 8s - loss: 0.0201 - accuracy: 0.9923 - val_loss: 0.5003 - val_accuracy: 0.9212 - 8s/epoch - 9ms/step\n",
      "Epoch 59/150\n",
      "868/868 - 8s - loss: 0.0187 - accuracy: 0.9925 - val_loss: 0.5397 - val_accuracy: 0.9212 - 8s/epoch - 9ms/step\n",
      "Epoch 60/150\n",
      "868/868 - 8s - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.4690 - val_accuracy: 0.9235 - 8s/epoch - 9ms/step\n",
      "Epoch 61/150\n",
      "868/868 - 8s - loss: 0.0200 - accuracy: 0.9917 - val_loss: 0.5228 - val_accuracy: 0.9209 - 8s/epoch - 9ms/step\n",
      "Epoch 62/150\n",
      "868/868 - 8s - loss: 0.0199 - accuracy: 0.9923 - val_loss: 0.5056 - val_accuracy: 0.9242 - 8s/epoch - 9ms/step\n",
      "Epoch 63/150\n",
      "868/868 - 8s - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.5012 - val_accuracy: 0.9249 - 8s/epoch - 9ms/step\n",
      "Epoch 64/150\n",
      "868/868 - 8s - loss: 0.0207 - accuracy: 0.9920 - val_loss: 0.4824 - val_accuracy: 0.9238 - 8s/epoch - 9ms/step\n",
      "Epoch 65/150\n",
      "868/868 - 8s - loss: 0.0214 - accuracy: 0.9915 - val_loss: 0.4720 - val_accuracy: 0.9226 - 8s/epoch - 9ms/step\n",
      "Epoch 66/150\n",
      "868/868 - 8s - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.4977 - val_accuracy: 0.9212 - 8s/epoch - 10ms/step\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868/868 - 8s - loss: 0.0179 - accuracy: 0.9929 - val_loss: 0.5850 - val_accuracy: 0.9232 - 8s/epoch - 9ms/step\n",
      "Epoch 68/150\n",
      "868/868 - 8s - loss: 0.0202 - accuracy: 0.9924 - val_loss: 0.5433 - val_accuracy: 0.9240 - 8s/epoch - 9ms/step\n",
      "Epoch 69/150\n",
      "868/868 - 8s - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.5290 - val_accuracy: 0.9248 - 8s/epoch - 9ms/step\n",
      "Epoch 70/150\n",
      "868/868 - 8s - loss: 0.0178 - accuracy: 0.9930 - val_loss: 0.4664 - val_accuracy: 0.9230 - 8s/epoch - 9ms/step\n",
      "Epoch 71/150\n",
      "868/868 - 8s - loss: 0.0207 - accuracy: 0.9920 - val_loss: 0.5061 - val_accuracy: 0.9231 - 8s/epoch - 9ms/step\n",
      "Epoch 72/150\n",
      "868/868 - 8s - loss: 0.0187 - accuracy: 0.9924 - val_loss: 0.5613 - val_accuracy: 0.9223 - 8s/epoch - 9ms/step\n",
      "Epoch 73/150\n",
      "868/868 - 8s - loss: 0.0180 - accuracy: 0.9931 - val_loss: 0.5314 - val_accuracy: 0.9246 - 8s/epoch - 9ms/step\n",
      "Epoch 74/150\n",
      "868/868 - 8s - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.5522 - val_accuracy: 0.9235 - 8s/epoch - 9ms/step\n",
      "Epoch 75/150\n",
      "868/868 - 9s - loss: 0.0192 - accuracy: 0.9920 - val_loss: 0.5407 - val_accuracy: 0.9242 - 9s/epoch - 10ms/step\n",
      "Epoch 76/150\n",
      "868/868 - 9s - loss: 0.0193 - accuracy: 0.9926 - val_loss: 0.4956 - val_accuracy: 0.9226 - 9s/epoch - 11ms/step\n",
      "Epoch 77/150\n",
      "868/868 - 8s - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.5273 - val_accuracy: 0.9232 - 8s/epoch - 10ms/step\n",
      "Epoch 78/150\n",
      "868/868 - 8s - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.5316 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 79/150\n",
      "868/868 - 8s - loss: 0.0189 - accuracy: 0.9924 - val_loss: 0.5921 - val_accuracy: 0.9225 - 8s/epoch - 9ms/step\n",
      "Epoch 80/150\n",
      "868/868 - 8s - loss: 0.0181 - accuracy: 0.9931 - val_loss: 0.5492 - val_accuracy: 0.9225 - 8s/epoch - 9ms/step\n",
      "Epoch 81/150\n",
      "868/868 - 8s - loss: 0.0180 - accuracy: 0.9928 - val_loss: 0.5480 - val_accuracy: 0.9223 - 8s/epoch - 9ms/step\n",
      "Epoch 82/150\n",
      "868/868 - 8s - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.5469 - val_accuracy: 0.9214 - 8s/epoch - 9ms/step\n",
      "Epoch 83/150\n",
      "868/868 - 8s - loss: 0.0178 - accuracy: 0.9933 - val_loss: 0.5090 - val_accuracy: 0.9218 - 8s/epoch - 9ms/step\n",
      "Epoch 84/150\n",
      "868/868 - 8s - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.5214 - val_accuracy: 0.9222 - 8s/epoch - 9ms/step\n",
      "Epoch 85/150\n",
      "868/868 - 8s - loss: 0.0169 - accuracy: 0.9935 - val_loss: 0.5599 - val_accuracy: 0.9219 - 8s/epoch - 9ms/step\n",
      "Epoch 86/150\n",
      "868/868 - 8s - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.5264 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 87/150\n",
      "868/868 - 8s - loss: 0.0174 - accuracy: 0.9929 - val_loss: 0.5426 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 88/150\n",
      "868/868 - 8s - loss: 0.0181 - accuracy: 0.9930 - val_loss: 0.5076 - val_accuracy: 0.9203 - 8s/epoch - 9ms/step\n",
      "Epoch 89/150\n",
      "868/868 - 8s - loss: 0.0180 - accuracy: 0.9934 - val_loss: 0.5254 - val_accuracy: 0.9214 - 8s/epoch - 9ms/step\n",
      "Epoch 90/150\n",
      "868/868 - 8s - loss: 0.0167 - accuracy: 0.9933 - val_loss: 0.5138 - val_accuracy: 0.9209 - 8s/epoch - 9ms/step\n",
      "Epoch 91/150\n",
      "868/868 - 8s - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.5901 - val_accuracy: 0.9195 - 8s/epoch - 9ms/step\n",
      "Epoch 92/150\n",
      "868/868 - 8s - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.5474 - val_accuracy: 0.9210 - 8s/epoch - 9ms/step\n",
      "Epoch 93/150\n",
      "868/868 - 8s - loss: 0.0164 - accuracy: 0.9935 - val_loss: 0.5684 - val_accuracy: 0.9208 - 8s/epoch - 9ms/step\n",
      "Epoch 94/150\n",
      "868/868 - 8s - loss: 0.0174 - accuracy: 0.9932 - val_loss: 0.5446 - val_accuracy: 0.9231 - 8s/epoch - 9ms/step\n",
      "Epoch 95/150\n",
      "868/868 - 8s - loss: 0.0181 - accuracy: 0.9926 - val_loss: 0.5711 - val_accuracy: 0.9221 - 8s/epoch - 10ms/step\n",
      "Epoch 96/150\n",
      "868/868 - 8s - loss: 0.0179 - accuracy: 0.9930 - val_loss: 0.5830 - val_accuracy: 0.9229 - 8s/epoch - 9ms/step\n",
      "Epoch 97/150\n",
      "868/868 - 8s - loss: 0.0162 - accuracy: 0.9936 - val_loss: 0.5517 - val_accuracy: 0.9228 - 8s/epoch - 9ms/step\n",
      "Epoch 98/150\n",
      "868/868 - 8s - loss: 0.0171 - accuracy: 0.9934 - val_loss: 0.5453 - val_accuracy: 0.9215 - 8s/epoch - 9ms/step\n",
      "Epoch 99/150\n",
      "868/868 - 8s - loss: 0.0161 - accuracy: 0.9935 - val_loss: 0.5745 - val_accuracy: 0.9218 - 8s/epoch - 9ms/step\n",
      "Epoch 100/150\n",
      "868/868 - 8s - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.5363 - val_accuracy: 0.9187 - 8s/epoch - 9ms/step\n",
      "Epoch 101/150\n",
      "868/868 - 8s - loss: 0.0159 - accuracy: 0.9938 - val_loss: 0.5543 - val_accuracy: 0.9210 - 8s/epoch - 9ms/step\n",
      "Epoch 102/150\n",
      "868/868 - 8s - loss: 0.0174 - accuracy: 0.9932 - val_loss: 0.5230 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 103/150\n",
      "868/868 - 8s - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.5289 - val_accuracy: 0.9223 - 8s/epoch - 9ms/step\n",
      "Epoch 104/150\n",
      "868/868 - 8s - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.5708 - val_accuracy: 0.9220 - 8s/epoch - 9ms/step\n",
      "Epoch 105/150\n",
      "868/868 - 8s - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.5475 - val_accuracy: 0.9230 - 8s/epoch - 9ms/step\n",
      "Epoch 106/150\n",
      "868/868 - 8s - loss: 0.0172 - accuracy: 0.9930 - val_loss: 0.5457 - val_accuracy: 0.9221 - 8s/epoch - 9ms/step\n",
      "Epoch 107/150\n",
      "868/868 - 7s - loss: 0.0147 - accuracy: 0.9941 - val_loss: 0.6264 - val_accuracy: 0.9236 - 7s/epoch - 9ms/step\n",
      "Epoch 108/150\n",
      "868/868 - 8s - loss: 0.0153 - accuracy: 0.9938 - val_loss: 0.5711 - val_accuracy: 0.9227 - 8s/epoch - 9ms/step\n",
      "Epoch 109/150\n",
      "868/868 - 7s - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.5642 - val_accuracy: 0.9230 - 7s/epoch - 9ms/step\n",
      "Epoch 110/150\n",
      "868/868 - 8s - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.6124 - val_accuracy: 0.9219 - 8s/epoch - 9ms/step\n",
      "Epoch 111/150\n",
      "868/868 - 7s - loss: 0.0155 - accuracy: 0.9938 - val_loss: 0.5798 - val_accuracy: 0.9241 - 7s/epoch - 9ms/step\n",
      "Epoch 112/150\n",
      "868/868 - 8s - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.5578 - val_accuracy: 0.9238 - 8s/epoch - 9ms/step\n",
      "Epoch 113/150\n",
      "868/868 - 8s - loss: 0.0143 - accuracy: 0.9940 - val_loss: 0.6123 - val_accuracy: 0.9226 - 8s/epoch - 9ms/step\n",
      "Epoch 114/150\n",
      "868/868 - 8s - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.6071 - val_accuracy: 0.9242 - 8s/epoch - 9ms/step\n",
      "Epoch 115/150\n",
      "868/868 - 8s - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.5636 - val_accuracy: 0.9257 - 8s/epoch - 9ms/step\n",
      "Epoch 116/150\n",
      "868/868 - 8s - loss: 0.0147 - accuracy: 0.9940 - val_loss: 0.6323 - val_accuracy: 0.9218 - 8s/epoch - 9ms/step\n",
      "Epoch 117/150\n",
      "868/868 - 8s - loss: 0.0149 - accuracy: 0.9944 - val_loss: 0.5913 - val_accuracy: 0.9246 - 8s/epoch - 9ms/step\n",
      "Epoch 118/150\n",
      "868/868 - 8s - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.5091 - val_accuracy: 0.9227 - 8s/epoch - 9ms/step\n",
      "Epoch 119/150\n",
      "868/868 - 8s - loss: 0.0140 - accuracy: 0.9944 - val_loss: 0.5677 - val_accuracy: 0.9252 - 8s/epoch - 9ms/step\n",
      "Epoch 120/150\n",
      "868/868 - 8s - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.6095 - val_accuracy: 0.9253 - 8s/epoch - 9ms/step\n",
      "Epoch 121/150\n",
      "868/868 - 8s - loss: 0.0128 - accuracy: 0.9946 - val_loss: 0.6594 - val_accuracy: 0.9236 - 8s/epoch - 9ms/step\n",
      "Epoch 122/150\n",
      "868/868 - 8s - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.5902 - val_accuracy: 0.9239 - 8s/epoch - 9ms/step\n",
      "Epoch 123/150\n",
      "868/868 - 8s - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.5780 - val_accuracy: 0.9233 - 8s/epoch - 9ms/step\n",
      "Epoch 124/150\n",
      "868/868 - 8s - loss: 0.0149 - accuracy: 0.9940 - val_loss: 0.5503 - val_accuracy: 0.9235 - 8s/epoch - 9ms/step\n",
      "Epoch 125/150\n",
      "868/868 - 8s - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.5589 - val_accuracy: 0.9227 - 8s/epoch - 9ms/step\n",
      "Epoch 126/150\n",
      "868/868 - 7s - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.5748 - val_accuracy: 0.9228 - 7s/epoch - 9ms/step\n",
      "Epoch 127/150\n",
      "868/868 - 8s - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.6375 - val_accuracy: 0.9230 - 8s/epoch - 9ms/step\n",
      "Epoch 128/150\n",
      "868/868 - 8s - loss: 0.0134 - accuracy: 0.9946 - val_loss: 0.6524 - val_accuracy: 0.9225 - 8s/epoch - 9ms/step\n",
      "Epoch 129/150\n",
      "868/868 - 8s - loss: 0.0136 - accuracy: 0.9946 - val_loss: 0.6732 - val_accuracy: 0.9227 - 8s/epoch - 9ms/step\n",
      "Epoch 130/150\n",
      "868/868 - 8s - loss: 0.0136 - accuracy: 0.9945 - val_loss: 0.6328 - val_accuracy: 0.9219 - 8s/epoch - 9ms/step\n",
      "Epoch 131/150\n",
      "868/868 - 7s - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.6105 - val_accuracy: 0.9231 - 7s/epoch - 9ms/step\n",
      "Epoch 132/150\n",
      "868/868 - 7s - loss: 0.0151 - accuracy: 0.9938 - val_loss: 0.5931 - val_accuracy: 0.9247 - 7s/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "868/868 - 8s - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.5907 - val_accuracy: 0.9245 - 8s/epoch - 9ms/step\n",
      "Epoch 134/150\n",
      "868/868 - 8s - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.5624 - val_accuracy: 0.9239 - 8s/epoch - 9ms/step\n",
      "Epoch 135/150\n",
      "868/868 - 8s - loss: 0.0136 - accuracy: 0.9944 - val_loss: 0.6109 - val_accuracy: 0.9236 - 8s/epoch - 9ms/step\n",
      "Epoch 136/150\n",
      "868/868 - 8s - loss: 0.0128 - accuracy: 0.9948 - val_loss: 0.7503 - val_accuracy: 0.9221 - 8s/epoch - 9ms/step\n",
      "Epoch 137/150\n",
      "868/868 - 8s - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.6023 - val_accuracy: 0.9257 - 8s/epoch - 9ms/step\n",
      "Epoch 138/150\n",
      "868/868 - 8s - loss: 0.0147 - accuracy: 0.9943 - val_loss: 0.6104 - val_accuracy: 0.9242 - 8s/epoch - 9ms/step\n",
      "Epoch 139/150\n",
      "868/868 - 8s - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.5597 - val_accuracy: 0.9236 - 8s/epoch - 9ms/step\n",
      "Epoch 140/150\n",
      "868/868 - 8s - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.5946 - val_accuracy: 0.9237 - 8s/epoch - 9ms/step\n",
      "Epoch 141/150\n",
      "868/868 - 8s - loss: 0.0138 - accuracy: 0.9943 - val_loss: 0.6554 - val_accuracy: 0.9242 - 8s/epoch - 9ms/step\n",
      "Epoch 142/150\n",
      "868/868 - 8s - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.5470 - val_accuracy: 0.9245 - 8s/epoch - 9ms/step\n",
      "Epoch 143/150\n",
      "868/868 - 8s - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.6138 - val_accuracy: 0.9234 - 8s/epoch - 9ms/step\n",
      "Epoch 144/150\n",
      "868/868 - 8s - loss: 0.0135 - accuracy: 0.9946 - val_loss: 0.5889 - val_accuracy: 0.9211 - 8s/epoch - 9ms/step\n",
      "Epoch 145/150\n",
      "868/868 - 8s - loss: 0.0132 - accuracy: 0.9947 - val_loss: 0.6394 - val_accuracy: 0.9216 - 8s/epoch - 9ms/step\n",
      "Epoch 146/150\n",
      "868/868 - 8s - loss: 0.0134 - accuracy: 0.9948 - val_loss: 0.6949 - val_accuracy: 0.9232 - 8s/epoch - 9ms/step\n",
      "Epoch 147/150\n",
      "868/868 - 8s - loss: 0.0119 - accuracy: 0.9951 - val_loss: 0.7594 - val_accuracy: 0.9215 - 8s/epoch - 9ms/step\n",
      "Epoch 148/150\n",
      "868/868 - 8s - loss: 0.0138 - accuracy: 0.9946 - val_loss: 0.7150 - val_accuracy: 0.9223 - 8s/epoch - 9ms/step\n",
      "Epoch 149/150\n",
      "868/868 - 8s - loss: 0.0128 - accuracy: 0.9948 - val_loss: 0.7065 - val_accuracy: 0.9242 - 8s/epoch - 9ms/step\n",
      "Epoch 150/150\n",
      "868/868 - 8s - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.7629 - val_accuracy: 0.9232 - 8s/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.Conv1D(32, 3, activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size = 2, strides = 1),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(24, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    tf.keras.layers.Dense(16, activation = 'elu', kernel_initializer = 'he_normal'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_padded, y_train,\n",
    "                    validation_data = (valid_padded, y_test),\n",
    "                    epochs = 150,\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53376040",
   "metadata": {},
   "source": [
    "- Nh·∫≠n x√©t:\n",
    "\n",
    "    M√¥ h√¨nh m·∫°ng neural v·ªõi l·ªõp `Conv1D` v√† `MaxPooling1D` k√®m ƒëi·ªÅu chu·∫©n cho hi·ªáu su·∫•t kh√° t·ªët v√† th·ªùi gian nhanh h∆°n c√°c m√¥ h√¨nh c√≤n l·∫°i, k·ªÉ c·∫£ `Voting Classifier` ph√≠a tr√™n.\n",
    "    \n",
    "    ƒê·ªÅ xu·∫•t l·ª±a ch·ªçn m√¥ h√¨nh m·∫°ng neural v·ªõi l·ªõp `Conv1D` v√† `MaxPooling1D` k√®m ƒëi·ªÅu chu·∫©n ƒë·ªÉ l∆∞u m√¥ h√¨nh v√† d·ª± ƒëo√°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "63a82c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1975\n",
      "           1       0.95      0.96      0.95      9917\n",
      "\n",
      "    accuracy                           0.92     11892\n",
      "   macro avg       0.87      0.84      0.86     11892\n",
      "weighted avg       0.92      0.92      0.92     11892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(valid_padded)\n",
    "yhat = np.round(yhat).reshape(-1)\n",
    "\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5fcd35d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved !!!\n"
     ]
    }
   ],
   "source": [
    "model.save('Foody_review_analysis.h5')\n",
    "print('Saved !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "21905589",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['ƒë·ªì ƒÉn t·∫°m t√†m nh∆∞ng nh√¢n vi√™n th√°i ƒë·ªô l·ªìi l√µm, ƒë√∫ng l√† m·ªôt l·∫ßn v√† m√£i m√£i', \n",
    "        'qu√°n d·ªü b√† c·ªë m√† review ·∫£o tung ch·∫£o',\n",
    "        'C√≥ ngon g√¨ ƒë√¢u m√† review cao ng·∫•t ng∆∞·ªüng',\n",
    "        'Nguy√™n li·ªáu c≈© ƒë·ªÉ l√¢u ng√†y',\n",
    "        'Qu√°n x·∫≠p x·ªá, n√≥ng b·ª©c l√†m ƒÉn m·∫•t c·∫£ ngon',\n",
    "        'Ch∆∞a n√≥i ƒë·∫øn ƒë·ªì ƒÉn c√≥ ngon hay kh√¥ng, qu√°n s√°t b·ªù s√¥ng m√† ch·ªâ x√†i ƒë√®n c·∫ßy, ƒëi v·ªõi anh ng∆∞·ªùi eo c·∫£ bu·ªïi c·ª© g√£i s·ªìn s·ªôt m·∫•t h·∫øt c·∫£ h√¨nh ·∫£nh duy√™n ƒë√°nh, thanh l·ªãch c·ªßa m·ªã',\n",
    "        'ƒê·ªì ƒÉn kh√¥ng ngon ƒë∆∞·ª£c c√°i anh ch·ªß qu√°n ƒë·∫πp trai nh∆∞ng anh l·∫°i c√≥ v·ª£',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f17da7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = 'ƒë·ªì ƒÉn t·∫°m t√†m nh∆∞ng nh√¢n vi√™n th√°i ƒë·ªô l·ªìi l√µm, ƒë√∫ng l√† m·ªôt l·∫ßn v√† m√£i m√£i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d914bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = fc.clean_text(text, emoji_dict, teen_dict, wrong_lst, stopwords_lst)\n",
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f8ce00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "proceed_text = [fc.clean_text(x, emoji_dict, teen_dict, wrong_lst, stopwords_lst) for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "752a4c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ƒë·ªì t·∫°m t√†m nh√¢n vi√™n th√°i ƒë·ªô l·ªìi l√µm m√£i m√£i.',\n",
       " 'qu√°n d·ªü c·ªë review ·∫£o ch·∫£o.',\n",
       " 'review ng·∫•t ng∆∞·ªüng.',\n",
       " 'nguy√™n li·ªáu c≈© ng√†y.',\n",
       " 'qu√°n x·∫≠p x·ªá n√≥ng .',\n",
       " 'ƒë·ªì kh√¥ng qu√°n s√°t b·ªù s√¥ng x√†i ƒë√®n c·∫ßy g√£i s·ªìn s·ªôt h√¨nh ·∫£nh duy√™n ƒë√°nh l·ªãch m·ªã.',\n",
       " 'ƒë·ªì kh√¥ng ch·ªß qu√°n ƒë·∫πp v·ª£.']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proceed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee15e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(text):\n",
    "    new_sequence = tokenizer.texts_to_sequences(text)\n",
    "    new_padded = pad_sequences(new_sequence,\n",
    "                               padding = padding_type,\n",
    "                               truncating = trunc_type,\n",
    "                               maxlen = max_length)\n",
    "    return new_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2d765dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = predict_review(proceed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5fdac9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(new_text), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "872dce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cv = cv.transform(pd.Series(data = text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3703f87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_modified.predict(review_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7f68943d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb_clf.fit(X_train_cv, y_train)\n",
    "xgb_clf.predict(review_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1fd8277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# class ReplaceByAvg(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, list_col):\n",
    "#         self.list_col = list_col\n",
    "#     def fit(self, X, y = None):\n",
    "#         return self\n",
    "#     def transform(self, df):\n",
    "#         X = df.copy()\n",
    "#         for col in self.list_col:\n",
    "#             X.loc[X[col] == 0, col] = round(X[col].mean(), 2)\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2a3dfca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ng√£i heo v·ªõi heo thi·ªáttttt üê∑üê∑üê∑\\nü§§ü§§ b√∫n nem ch·∫£ g√¨ g√¨ c·ªßa Qu·∫£ng - bao ngon, bao th∆°m, bao no ü§§ü§§\\n qu√°n n√†y ·ªü tr·∫ßn vƒÉn kh√©o .K·∫ø s√≤ ·ªëc 99. Qu√°n qu·∫£ng. M√¨nh ƒÉn r·∫•t v·ª´a mi·ªáng. Th·ªãt n∆∞·ªõng m·ªÅm. N∆∞·ªõc ch·∫•m v·ª´a ƒÉn. Do m√¨nh ko th√≠ch ƒÉn d·∫ßu m·ª° nh√¨u n√™n ch·∫£ gi√≤ r√°n n√≥ m√¨nh ƒÉn ko nh√¨u. Nh∆∞ng ko ng·∫•y. M·ªói kh√∫c ch·∫£ ƒë·ªÅu c√≥ t√¥m nguy√™n con. Nh∆∞ng n·∫øu l·ªôt v·ªè t√¥m h·∫£ b·ªè v√†o ch·∫£ gi√≤ th√¨ ·ªïn h∆°n. üòå']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [data['review_text'][4]]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "30fac780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_text = predict_review(a)\n",
    "np.argmax(model.predict(pred_text), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e37efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db74ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
